"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[1477],{10:function(n){n.exports=JSON.parse('{"blogPosts":[{"id":"ces-2022-review","metadata":{"permalink":"/blog/ces-2022-review","source":"@site/blog/2022-02-17-ces-2022-review/index.mdx","title":"CES 2022\uc5d0 \ucc38\uc11d\ud55c \ub9c8\uc778\uc988\ub7a9, AI Human","description":"Brain\ud300\uc744 \ub300\ud45c\ud558\uc5ec CES 2022 \ucc38\uc11d\ud55c \ud6c4\uae30\ub97c \uc804\ub2ec\ub4dc\ub9ac\uace0, AI Human \uad00\ub828\ud55c Brain\ud300\uc758 \uc5f0\uad6c\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2022-02-17T00:00:00.000Z","formattedDate":"February 17, 2022","tags":[{"label":"news","permalink":"/blog/tags/news"}],"readingTime":17.645,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Scientist (Vision, Head)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"ces-2022-review","title":"CES 2022\uc5d0 \ucc38\uc11d\ud55c \ub9c8\uc778\uc988\ub7a9, AI Human","description":"Brain\ud300\uc744 \ub300\ud45c\ud558\uc5ec CES 2022 \ucc38\uc11d\ud55c \ud6c4\uae30\ub97c \uc804\ub2ec\ub4dc\ub9ac\uace0, AI Human \uad00\ub828\ud55c Brain\ud300\uc758 \uc5f0\uad6c\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/mindslab_default.png","authors":"hkyu","tags":["news"]},"nextItem":{"title":"VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech","permalink":"/blog/vits"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figVegasStart from \'./image/figure1_vegas.jpeg\';\\nimport figCes from \'./image/figure2_ces.png\';\\nimport figBooth from \'./image/figure3_booth.png\';\\nimport figVegasEnd from \'./image/figure4_vegas.png\';\\n\\n\\n\\n\\n<img className={styles.figCenter} src={figVegasStart} alt=\\"figure1_vegas\\" />\\n\\n\\n\\n## Brain Team at CES 2022 \\n\\n\uc548\ub155\ud558\uc138\uc694! \ub9c8\uc778\uc988\ub7a9 Brain\ud300 Vision \ud30c\ud2b8 \uc5f0\uad6c\uc6d0 \uc1a1\ud615\uaddc\uc785\ub2c8\ub2e4.  \\n\uc9c0\ub09c 1\uc6d4 5\uc77c\ubd80\ud130 7\uc77c\uae4c\uc9c0 3\uc77c\ub3d9\uc548 \ubbf8\uad6d \ub77c\uc2a4\ubca0\uac00\uc2a4\uc5d0\uc11c \uc138\uacc4 \ucd5c\uace0 \uac00\uc804 \ubc15\ub78c\ud68c\uc778 CES 2022\uac00 \uc5f4\ub838\uc2b5\ub2c8\ub2e4. 2\ub144\ub9cc\uc5d0 \uc624\ud504\ub77c\uc778\uc73c\ub85c \ub2e4\uc2dc \ub3cc\uc544\uc628 \uc774\ubc88 CES 2022\uc5d0\ub294 \uc624\ubbf8\ud06c\ub860\uc774 \ud655\uc0b0\ub418\uba74\uc11c \ud3c9\ub144 \ub300\ube44 \ub9ce\uc740 \uc778\uc6d0\uc774 \ucc38\uc11d\ud558\uc9c0\ub294 \uc54a\uc558\uc9c0\ub9cc, \uc6cc\ub099 \ud070 \ubc15\ub78c\ud68c\uc5ec\uc11c \uadf8\ub7f0\uc9c0 \uadf8 \uaddc\ubaa8\ub294 \ub300\ub2e8\ud588\uc2b5\ub2c8\ub2e4.  \\n\ub9c8\uc778\uc988\ub7a9\uc740 \uc774\ubc88 CES 2022\uc5d0\uc11c \uad6d\ub0b4 \uc740\ud589\uacfc \ud568\uaed8 \uad6c\ud604\ud558\uc5ec \ud604\uc7ac \uc0c1\uc6a9\uc5d0 \ub3c4\uc785\ub41c AI Banker\ub97c \uc804\uc2dc\ud588\uc2b5\ub2c8\ub2e4. \uc800\ub294 \uc774\ubc88\uc5d0 \uae30\uc220 \uc124\uba85\uc744 \uc704\ud574 CES \ucd9c\uc7a5\uae38\uc5d0 \ub3d9\ud589\ud588\ub294\ub370\uc694. \ubc15\ub78c\ud68c\uc778\ub9cc\ud07c \uc5f0\uad6c\uc790\ub4e4\uc774 \uc911\uc2ec\uc774 \ub418\ub294 \ub525\ub7ec\ub2dd/\uba38\uc2e0\ub7ec\ub2dd \ud559\ud68c\uc640\ub294 \uc644\uc804\ud788 \ub2e4\ub978 \ubd84\uc704\uae30\uc9c0\ub9cc, \ud22c\uc790\uc790\ub4e4\uacfc \ubc14\uc774\uc5b4, \uc77c\ubc18 \ucc38\uc11d\uc790\ub4e4\uc774 \ucc38\uc11d\ud558\ub294 \uc790\ub9ac\uc774\ub2e4 \ubcf4\ub2c8\uae4c \ub9e4\uc758 \ub208\uc73c\ub85c \uae30\ub2a5 \ud558\ub098\ud558\ub098\uc5d0 \ub300\ud574 \uc5ec\ucb64\ubcf4\uc2dc\ub294 \ubd84\ub4e4\uc774 \ub354\uc6b1 \ub9ce\uc544 \uac1c\uc778\uc801\uc73c\ub85c \ub17c\ubb38 \ubc1c\ud45c\ud558\ub294 \uac83\ubcf4\ub2e4 \ub354 \uc5b4\ub824\uc6e0\uc2b5\ub2c8\ub2e4(\ub2e4\ub140\uc624\ub2c8\uae4c \uc0b4\uc774 2kg \ube60\uc84c\uc5b4\uc694 \u314e\u314e;).  \\n\uc774\ubc88 \ud3ec\uc2a4\ud2b8\uc5d0\uc11c\ub294 CES 2022\uc5d0\uc11c\uc758 \ubd84\uc704\uae30\ub97c \uac04\uc811\uc801\uc73c\ub85c\ub098\ub9c8 \uc804\ub2ec\ub4dc\ub9ac\uace0, \uc774\ubc88\uc5d0 AI Human\uc5d0 \ub3c4\uc785\ub41c \uae30\uc220\ub4e4\uc5d0 \ub300\ud574 \uc124\uba85\ub4dc\ub9ac\uaca0\uc2b5\ub2c8\ub2e4. \uc774\ubc88 \uae00\uc740 \uae30\uc220 \ube14\ub85c\uadf8\uc774\uae30\ub294 \ud558\ub098, \uae30\uc220\uc801\uc778 \ub0b4\uc6a9\uc744 \ub2e4\ub8e8\uae30\ubcf4\ub2e4\ub294 \ub525\ub7ec\ub2dd\uc73c\ub85c \ud574\uacb0\ud55c Task\uac00 \uc5b4\ub5a4 \uac83\uc774\uc5c8\ub294\uc9c0\ub97c \ub9d0\uc500\ub4dc\ub9ac\ub824\uace0 \ud569\ub2c8\ub2e4 :smile:\\n\\n<img className={styles.figCenter} src={figCes} alt=\\"figure2_ces\\" />\\n\\n\\n### CES 2022\\n\\nCES\ub294 \ub77c\uc2a4\ubca0\uac00\uc2a4 \uc804\uc5ed\uc5d0 \uac78\uccd0 3\uac1c\uc758 \uc804\uc2dc\uad00(Tech East, Tech West, Tech South)\uc5d0\uc11c \uc9c4\ud589\ub429\ub2c8\ub2e4. \uadf8 \uc911 \ub300\uaddc\ubaa8 \ubd80\uc2a4\uac00 \uc8fc\ub85c \uc790\ub9ac\uc7a1\ub294 Tech East\ub9cc \ud574\ub3c4 \ucf54\uc5d1\uc2a4 \uc804\uc2dc\uad00 \uaddc\ubaa8\uc758 3\ubc30 \uc774\uc0c1\uc758 \ud06c\uae30\ub97c \uc790\ub791\ud569\ub2c8\ub2e4. \ud2b9\ud788, \uc774\ubc88\uc5d0 \uacf5\uac1c\ud55c [Vegas Loop](https://www.boringcompany.com/vegas-loop)\ub3c4 Tech East \ub0b4\uc758 West Hall\uacfc Central Hall\uc744 \uc774\uc5b4\uc8fc\ub294\ub370, \uadf8\ub9cc\ud07c \ub2e8\uc77c \uc5d1\uc2a4\ud3ec \uc790\uccb4\ub3c4 \ucc28\ub97c \ud0c0\uace0 \ub2e4\ub140\ub3c4 \ub420 \uc815\ub3c4\ub85c \uadf8 \uaddc\ubaa8\uac00 \ud07d\ub2c8\ub2e4. \uc5d1\uc2a4\ud3ec \uac01\uac01\uc5d0 \uc804\uc2dc\ud55c \uac83\ub4e4\uc774 \ubaa8\ub450 \uc758\ubbf8\uac00 \uc788\uc9c0\ub9cc, \uc544\ubb34\ub798\ub3c4 Tech East\uc640 Tech West\uc758 \uc804\uc2dc\uad00 \uaddc\ubaa8\uac00 \ud07d\ub2c8\ub2e4. \uc774\ubc88 CES 2022\uc5d0\uc11c \ub9c8\uc778\uc988\ub7a9\uc740 Tech West\uc758 Eureka Hall\uc5d0 \uc790\ub9ac \uc7a1\uc558\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figBooth} alt=\\"figure3_booth\\" />\\n\\n\\n### \ub9c8\uc778\uc988\ub7a9\uc758 AI Banker\\n\\n\uc774\ubc88 AI Banker\ub294 \uad6d\ub0b4 \ubaa8 \uc740\ud589\uc5d0 \uc774\ubbf8 \uc0c1\uc6a9\uc73c\ub85c \ub3c4\uc785\uc774 \ub418\uc5b4 \uc788\ub294 \uae30\uae30\ub85c, \ucee8\uc2dc\uc5b4\uc9c0 \uae30\uae30\uc640 \ub514\uc9c0\ud138\ub370\uc2a4\ud06c \ub450 \uc885\ub958\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \uc6b0\ub9ac\uac00 \ubcf4\ud1b5 \uc740\ud589\uc744 \uac00\uba74 \uc740\ud589 \ucc3d\uad6c \uc548\ub0b4\uc640 \ud568\uaed8 \ubc88\ud638\ud45c\ub97c \ubf51\ub294\ub370\uc694. AI Banker \ucee8\uc2dc\uc5b4\uc9c0\uac00 \ubc88\ud638\ud45c \ucd9c\ub825\uacfc \ub354\ubd88\uc5b4 \ud574\ub2f9 \uc9c0\uc810\uc5d0 \ub300\ud55c \uc548\ub0b4 \ub4f1\uc758 \uc5c5\ubb34\ub97c \ub300\uc2e0\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0 AI Banker\uac00 \ud0d1\uc7ac\ub41c \ub514\uc9c0\ud138\ub370\uc2a4\ud06c\ub294 \uc740\ud589 \ucc3d\uad6c\uc758 \uc704\uce58\uc5d0\uc11c \uc2e4\uc81c \uc740\ud589\uc744 \ubc29\ubb38\ud558\uc5ec \ud558\ub294 \uc5c5\ubb34\ub4e4\uc744 \ub300\uc2e0\ud558\uc5ec \uc9c4\ud589\ud560 \uc218 \uc788\ub3c4\ub85d \uad6c\uc131\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ub9c8\uc778\uc988\ub7a9\uc740 \uc774\ubc88 AI Banker\uc5d0 \ub3c4\uc785\ub41c \uc778\uacf5 \uc778\uac04\uc5d0 \ub300\ud574 \uc74c\uc131 \uc0dd\uc131(TTS, Text-To-Speech) \uae30\uc220\uacfc \uc5bc\uad74 \uc0dd\uc131(STF, Speech-To-Face) \uae30\uc220\uc744 \uad6c\ud604\ud568\uacfc \ub3d9\uc2dc\uc5d0 AI Banker \ub0b4 \uc5ec\ub7ec \uae30\ub2a5\ub4e4\uc5d0 \ub300\ud55c \uac1c\ubc1c\uc744 \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574, \ubc1c\ud654\ud560 \ud2b9\uc815 \ud14d\uc2a4\ud2b8\uac00 \uc815\ud574\uc9c0\uba74, \uc774\ub97c \ubc1c\ud654\ud558\ub294 \uc778\uacf5 \uc778\uac04 \uc601\uc0c1\uc744 \ubb34\uad81\ubb34\uc9c4\ud558\uac8c \ub9cc\ub4e4\uc5b4\ub0bc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, AI Banker \ucee8\uc2dc\uc5b4\uc9c0\ub294 GPU\uac00 \ub0b4\uc7a5\ub41c Windows PC\uc5d0\uc11c \ub3d9\uc791\ud558\ub294\ub370, TTS\uc640 STF \ub450 \uc5d4\uc9c4\uc774 \uc11c\ubc84\ub97c \ud1b5\ud558\uc9c0 \uc54a\uace0\ub3c4 Windows PC \ub0b4\uc5d0\uc11c \uc0dd\uc131\ub420 \uc218 \uc788\ub3c4\ub85d \uad6c\ud604\uc744 \uc9c4\ud589\ud588\uace0, 10\ucd08 \uc601\uc0c1\uc744 \uc0dd\uc131\ud558\ub294 \ub370\uc5d0 5\ucd08\uac00 \uc18c\uc694\ub418\ub294 \uc18d\ub3c4\ub97c \uc790\ub791\ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\\n\uc774\ubc88 AI Banker\ub294 \uc55e\uc11c \ub9d0\uc500\ub4dc\ub838\ub4ef\uc774 \uc774\ubbf8 \uad6d\ub0b4 \uc77c\ubd80 \uc9c0\uc810\uc5d0\uc11c \uc0c1\uc6a9\uc73c\ub85c \ub3c4\uc785\uc774 \ub418\uc5b4 \uc788\uc5b4, \ud574\ub2f9 \uc9c0\uc810\uc5d0 \uac00\uc154\uc11c \ud655\uc778\ud558\uc2e4 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uc778\uacf5 \uc778\uac04\uc774 \uc0c1\uc6a9\uc5d0 \ub3c4\uc785\ub418\uc5b4 \uc2e4\uc81c \uc791\ub3d9\ud558\ub294 \uc0ac\ub840\uac00 \ub9ce\uc9c0 \uc54a\ub2e4\ubcf4\ub2c8 \uc774 \ubd80\ubd84\ub9cc \ud574\ub3c4 \uc774\ubbf8 CES 2022\uc5d0\uc11c \ud070 \uc784\ud329\ud2b8\ub97c \ubd88\ub7ec\uc62c \ubc95 \ud588\ub294\ub370\uc694. \uc0ac\uc2e4 \uc5ec\uae30\uc5d0 \ub354\ud558\uc5ec \uae30\uc874 \uae30\uae30\uc5d0\uc11c \ud655\uc778\ud560 \uc218\ub294 \uc5c6\uc9c0\ub9cc, CES 2022\uc5d0\uc11c \ucc98\uc74c\uc73c\ub85c \uacf5\uac1c\ud55c \uae30\uc220\uc774 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n\ubc14\ub85c \uc601\uc5b4, \uc911\uad6d\uc5b4, \uc77c\ubcf8\uc5b4\ub97c \ud558\uc9c0 \ubabb\ud558\ub294 \uc0ac\ub78c\ub3c4 \ubcf8\uc778\uc758 \ubaa9\uc18c\ub9ac\ub85c 4\uac1c\uad6d\uc5b4\ub97c \ud560 \uc218 \uc788\uac8c \ub9cc\ub4dc\ub294, \ub2e4\uad6d\uc5b4(Multilingual) TTS \ubc0f STF \uae30\uc220\uc785\ub2c8\ub2e4.\\n\\n## \uae30\uc220 \uc18c\uac1c\\n\\n### Multilingual VITS\\n\\nMultilingual TTS \ub77c\ub294 \ud45c\ud604\uc740 \uc5ec\ub7ec \uc5b8\uc5b4\uc758 \uc74c\uc131\uc744 \uc0dd\uc131\ud558\ub294 \uae30\uc220\uc744 \ub9d0\ud558\ub294\ub370\uc694. \ud574\ub2f9 \ubc1c\ud654\uc790\uac00 \uc6d0\ub798 \ub2e4\uad6d\uc5b4\uac00 \uac00\ub2a5\ud55c \uc0ac\ub78c\uc774\uc5ec\uc11c \ub370\uc774\ud130 \uc790\uccb4\ub97c \uc5ec\ub7ec \uc5b8\uc5b4 \uc74c\uc131\uc73c\ub85c \uad6c\uc131\ud558\uc5ec \ud559\uc2b5\uc2dc\ud0a4\ub294 \uac83\ub3c4 Multilingual TTS\uc5d0 \ud3ec\ud568\ub429\ub2c8\ub2e4. \ub9c8\uc778\uc988\ub7a9 Multilingual TTS\ub294 **\ud2b9\uc815 \ubc1c\ud654\uc790\uc758 \ud55c\uad6d\uc5b4 \uc74c\uc131 \ub370\uc774\ud130\ub9cc\uc744 \uac00\uc9c0\uace0**, \ud574\ub2f9 \ubc1c\ud654\uc790\uc758 \ubaa9\uc18c\ub9ac \ud2b9\uc131\uc744 \uc0b4\ub824 \ud55c\uad6d\uc5b4\ub294 \ubb3c\ub860, \uc601\uc5b4, \uc911\uad6d\uc5b4, \uc77c\ubcf8\uc5b4\uae4c\uc9c0 \ubc1c\ud654\ud560 \uc218 \uc788\uac8c \ub9cc\ub4dc\ub294 \uae30\uc220\uc785\ub2c8\ub2e4. \uc774\ub294 \uc138\ubd80\uc801\uc73c\ub85c Cross-lingual TTS\ub85c\ub3c4 \ubd88\ub9ac\ub294\ub370, \uc544\uc9c1 \ud559\uacc4\uc5d0\uc11c\ub3c4 \uad49\uc7a5\ud788 \uc5b4\ub824\uc6b4 \ubb38\uc81c\ub85c \uaf3d\uace0 \uc788\uc2b5\ub2c8\ub2e4.  \\n\ubc29\uc2dd\uc744 \uc870\uae08 \ub354 \uc124\uba85\ub4dc\ub9ac\uc790\uba74, \uac01 \uc5b8\uc5b4(\ud55c\uad6d\uc5b4, \uc911\uad6d\uc5b4, \uc77c\ubcf8\uc5b4, \uc601\uc5b4)\uc5d0 \ub300\ud574 \uc5ec\ub7ec \ud654\uc790\ub85c\ubd80\ud130 TTS \ub370\uc774\ud130\ub97c \uad6c\ucd95\ud55c \ub2e4\uc74c, \uc774\ub97c \uac00\uc9c0\uace0 1\ucc28 \ud559\uc2b5(Baseline)\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4. \uc774\ud6c4 \uae30\uc874 TTS \ubaa8\ub378\uc5d0 Regularization \ubc29\ubc95\uc744 \uac00\ubbf8\ud558\uc5ec \uc5b8\uc5b4 \uc870\uac74\uc5d0 \ub9de\ucd94\uc5b4 \uc74c\uc131\uc774 \ud569\uc131\ub418\ub3c4\ub85d \ucd94\uac00 \ud559\uc2b5\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc778 Fine-tuning\uacfc \uc720\uc0ac\ud558\ub2e4\uace0 \ub290\ub07c\uc2e4 \uc218 \uc788\uc73c\ub098, \uc774 \uacfc\uc815\uc5d0\uc11c loss function\uc5d0 regluarization term\uc774 \ud558\ub098 \ub354 \ucd94\uac00\ub41c\ub2e4\ub294 \uc810, \uadf8\ub9ac\uace0 \uc774\ub97c \uc801\uc6a9\ud588\uc744 \ub54c \uc5ec\ub7ec \uc5b8\uc5b4\ub97c \uc18c\ud654\ud560 \uc218 \uc788\uac8c\ub054 robustness\ub97c \ud655\ubcf4\ud558\uace0 \uc788\ub294 TTS \ubaa8\ub378\uc774\uc5b4\uc57c \ud55c\ub2e4\ub294 \uc810\uc5d0\uc11c \uacb0\ucf54 \uc27d\uac8c \ucc3e\uc744 \uc218 \uc788\ub294 \ubc29\ubc95\uc740 \uc544\ub2d9\ub2c8\ub2e4. \uc774 \ubc29\ubc95\uc744 \ud1b5\ud574 \uc6d0\ub798 \ud55c\uad6d\uc5b4\ubc16\uc5d0 \ud558\uc9c0 \ubabb\ud558\ub294 \ubd84\ub4e4\ub3c4 \uc601\uc5b4, \uc77c\ubcf8\uc5b4, \uc911\uad6d\uc5b4\ub97c \ubc1c\ud654\ud558\ub294 \uc601\uc0c1\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4.\\n\\n### Speech-To-Face (STF)\\n\\nCES\uc5d0 \uc804\uc2dc\ud55c AI Human\uc5d0\uc11c \ubcf4\ub294 \uc5bc\uad74\uc740 \uc21c\uc218\ud558\uac8c \ub525\ub7ec\ub2dd \ubaa8\ub378\ub85c \uc0dd\uc131\ub41c \uc5bc\uad74 \uadf8\ub300\ub85c\uc785\ub2c8\ub2e4. \uc5bc\uad74 \uc0dd\uc131 \ubaa8\ub378\uc740 \uc800\ub97c \ud3ec\ud568\ud558\uc5ec Brain\ud300 AI Face \ud504\ub85c\uc81d\ud2b8 \uc5f0\uad6c\uc6d0\ubd84\ub4e4\uacfc \ud568\uaed8 \uc790\uccb4\uc801\uc73c\ub85c \uac1c\ubc1c\ud55c \uc54c\uace0\ub9ac\uc998\uc744 \uae30\ubc18\uc73c\ub85c \uad6c\ucd95\ub418\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\uc77c\ubc18\uc801\uc73c\ub85c \ud559\uacc4\uc5d0\uc11c\ub294 Talking Head Generation \uc774\ub77c\ub294 \uc774\ub984\uc73c\ub85c\ub3c4 Task\ub97c \ubd80\ub974\uace4 \ud569\ub2c8\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \uc5f0\uad6c\uc5d0\uc11c \uc9d1\uc911\ud558\ub294 \ubd80\ubd84\uc740 Any-Face, Any-Speaker (Unconstrained) \ubaa8\ub378\ub85c\uc11c, \ud559\uc2b5 \ub370\uc774\ud130\uc5d0 \uc5c6\ub294 \uc5bc\uad74\uc5d0 \ub300\ud574 \ud559\uc2b5 \ub370\uc774\ud130\uc5d0 \uc5c6\ub294 \ud1a4\uc744 \uac00\uc9c4 \ubaa9\uc18c\ub9ac\uc5d0 \ub300\ud574 \uc601\uc0c1\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \uc18c\ud654\ud558\ub824\uace0 \ud569\ub2c8\ub2e4. \ub300\uc2e0 \ud2b9\uc815 \uc778\ubb3c\uc5d0 \ub300\ud574 \ud559\uc2b5\uc744 \uc9c4\ud589\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc5d0, \uc77c\ubc18\uc801\uc73c\ub85c \ud654\uc9c8\uc774 \ub0ae\uace0(\uc0dd\uc131\ud558\ub294 \uc601\uc5ed\uc758 \ud55c \ubcc0\uc774 256 \ud53d\uc140\ubcf4\ub2e4 \uc801\uc2b5\ub2c8\ub2e4), \uc785\ubaa8\uc591 \uc6c0\uc9c1\uc784\uc774 \ubd80\uc790\uc5f0\uc2a4\ub7ec\uc6b4 \uacbd\uc6b0\uac00 \ub9ce\uc2b5\ub2c8\ub2e4. \ud2b9\ud788, \uc5ec\ub7ec \ub17c\ubb38\uc5d0\uc11c \\"\uc601\uc5b4 \ub370\uc774\ud130\ub85c \ud559\uc2b5\uc744 \ud574\ub3c4 \uc5b4\ub290 \uc5b8\uc5b4\ub4e0 \uc601\uc0c1\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\ub2e4\\"\uace0 \uc8fc\uc7a5\ud558\ub294\ub370\uc694. \uc2e4\uc81c\ub85c \uc601\uc0c1\uc744 \ub9cc\ub4e4\uc5b4 \ubcf4\uba74, \ud55c\uad6d\uc5b4 \uc74c\uc131\uc5d0 \ub300\ud574\uc11c\ub294 \uc785\ubaa8\uc591\uc774 \uc798 \ub9de\uc9c0 \uc54a\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \\n\ub9c8\uc778\uc988\ub7a9 \uc5bc\uad74 \uc0dd\uc131 \uc5d4\uc9c4\uc740 \ud2b9\uc815 \uc778\ubb3c\uc758 \ub370\uc774\ud130\ub97c \uae30\uc900\uc73c\ub85c \ud559\uc2b5\uc744 \ud558\uc5ec $512 \\\\times 512$ \ud06c\uae30\uc758 \uc5bc\uad74 \uc601\uc0c1\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4. \uadf8\ub9ac\uace0 Multilingual TTS\uac00 \uc788\uae30 \ub54c\ubb38\uc5d0, \ud574\ub2f9 \uc778\ubb3c\uc774 \ud55c\uad6d\uc5b4\ubfd0\ub9cc \uc544\ub2c8\ub77c, \uc601\uc5b4, \uc77c\ubcf8\uc5b4, \uc911\uad6d\uc5b4\ub97c \ubc1c\ud654\ud558\ub294 \uc601\uc0c1\ub3c4 \ub9cc\ub4e4 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4. \uc7ac\ubc0c\ub294 \uc810\uc740 \ud55c\uad6d\uc5b4\ub97c \uae30\uc900\uc73c\ub85c \ud559\uc2b5\ud560 \uacbd\uc6b0, \ud55c\uad6d\uc5b4\uc5d0\uc11c \ubc1c\uc0dd\ud558\ub294 \ubc1c\uc74c \uc870\ud569\uc774 \uc601\uc5b4\ubcf4\ub2e4 \ub2e4\uc591\ud558\uace0 \ud559\uc2b5\ud55c \ub370\uc774\ud130 \uc5ed\uc2dc \ub2e8\uc77c \ud654\uc790\uc758 \uc74c\uc131 \ud1a4\uc774\uae30 \ub54c\ubb38\uc5d0, \ub2e4\ub978 \uc5b8\uc5b4\ub85c \uc0dd\uc131\ud55c \uc74c\uc131\uc5d0 \ub300\ud574\uc11c\ub3c4 \uc785\ubaa8\uc591\uc774 \uc798 \ub9de\uc2b5\ub2c8\ub2e4.  \\n\\n### Inference Speed\\n\\n\ub525\ub7ec\ub2dd \uae30\ubc18 \uc0dd\uc131 \ubaa8\ub378(Generative Model)\uc744 \uc2e4\uc81c \uc11c\ube44\uc2a4\ud560 \ub54c\ub294 \uc0dd\uc131\ud558\ub294 \uc74c\uc131\uacfc \uc601\uc0c1\uc758 \ud004\ub9ac\ud2f0\ub3c4 \uc911\uc694\ud558\uc9c0\ub9cc, \ubaa8\ub378\uc5d0 \uc18c\ubaa8\ub418\ub294 \uc790\uc6d0\uacfc \uc18d\ub3c4\ub3c4 \uc911\uc694\ud569\ub2c8\ub2e4. \ud2b9\ud788, \uc601\uc0c1\uc744 \uc0dd\uc131\ud558\ub294 Task\uc5d0\uc11c\ub294 \ucd08\ub2f9 \uba87 \uc7a5(FPS, Frames Per Second)\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\ub294 \uc9c0\uc5d0 \ub530\ub77c \uadf8 \uc4f0\uc784\uc0c8\uac00 \ub2ec\ub77c\uc9d1\ub2c8\ub2e4. 25FPS \uc601\uc0c1\uc744 \ub9cc\ub4dc\ub294 \ub370 25FPS\ubcf4\ub2e4 \ube60\ub974\ub2e4\uba74, \uc774\ub294 \uc2e4\uc2dc\uac04 \uc2a4\ud2b8\ub9ac\ubc0d\ub3c4 \uac00\ub2a5\ud55c \uc218\uc900\uc785\ub2c8\ub2e4. \ubc18\ub300\ub85c \uc774\ubcf4\ub2e4 \ub290\ub9ac\ub2e4\uba74, \uc601\uc0c1\uc744 \ubbf8\ub9ac \uc0dd\uc131\ud574\ub193\uace0 \uce90\uc2f1\ud574\uc11c \uc0ac\uc6a9\ud560 \uc218 \ubc16\uc5d0 \uc5c6\uc2b5\ub2c8\ub2e4.  \\n\ucd5c\uadfc \ud654\ub450\uac00 \ub418\ub294 \uc5ec\ub7ec \ud68c\uc0ac\uc758 \uc778\uacf5 \uc778\uac04\ub4e4\uc744 \ubcf4\uba74 \uc2a4\ud2b8\ub9ac\ubc0d\uc744 \uc9c0\uc6d0\ud558\ub294 \uac83\ub4e4\uc774 \ub9ce\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \ubbf8\ub9ac \uc0dd\uc131\ud55c \uc601\uc0c1\uc744 \uac00\uc838\ub2e4\uac00 \ub9cc\ub4e4\uace4 \ud558\uc8e0. Brain\ud300\uc774 \ub9cc\ub4e4\uace0\uc790 \ud558\ub294 AI Human\uc740 \uc2e4\uc2dc\uac04\uc73c\ub85c \ub300\ud654\uac00 \uac00\ub2a5\ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4.  \\n\ubaa8\ub378\uc5d0 \uc788\uc5b4 lightweight \ud558\uace0 inference \ud560 \ub54c \ube60\ub974\ub3c4\ub85d \ub514\uc790\uc778\ud558\ub294 \ubc29\ubc95\uc740 \uc5ec\ub7ec \uac00\uc9c0\uac00 \uc788\uc2b5\ub2c8\ub2e4. Brain\ud300\uc774 \uad6c\uc131\ud55c \ubaa8\ub378\uc5d0 \ub300\ud574\uc11c\ub294 \uc790\uc138\ud788 \ub9d0\uc500\ub4dc\ub9ac\uae30 \uc5b4\ub835\uc9c0\ub9cc, \uc8fc\ub85c autoregressive\ud55c \uc694\uc18c\ub4e4\uc744 \ucd5c\ub300\ud55c non-autoregressive \ud558\ub3c4\ub85d \ubcc0\uacbd\ud558\ub294 \ubc29\ud5a5\uc73c\ub85c \ub514\uc790\uc778\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 RTX 3080 GPU\uac00 \ud0d1\uc7ac\ub41c \ub370\uc2a4\ud06c\ud0d1\uc5d0\uc11c\ub3c4 \uc74c\uc131 \uc0dd\uc131 \ubc0f \uc5bc\uad74 \uc601\uc0c1 \uc0dd\uc131\uae4c\uc9c0 54.1FPS \uc758 \uc18d\ub3c4\ub97c \uc790\ub791\ud569\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 AI Human\uc774 \ubc29\ubb38\ud55c \uace0\uac1d\uc758 \uc774\ub984\uc744 \uc77d\uc5b4\uc8fc\uac70\ub098, \ud604\uc7a5 \uc0c1\ud669\uc5d0 \uc54c\ub9de\ub294 \ubc1c\ud654 \uc601\uc0c1\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uac8c \uad6c\uc131\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4.\\n\\n### \ub9c8\ubb34\ub9ac\\n\\n\uad6d\ub0b4 \uc740\ud589\uc5d0\ub294 \ud55c\uad6d\uc5b4 \ubc1c\ud654 \uc601\uc0c1\uc774 \uad6c\uc131\ub418\uc5b4 \uc788\uc5c8\uc9c0\ub9cc, \uc774\ubc88 CES\uc5d0\uc11c\ub294 \uc601\uc5b4 \ubc1c\ud654 \uc601\uc0c1\uc73c\ub85c \uc804\uc2dc\uac00 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ud0c0 \uae30\uc5c5\ub4e4\uc5d0\uc11c\ub3c4 \uadf8\ub807\uace0 \ub9c8\uc778\uc988\ub7a9\uc5d0\uc11c\ub3c4 \uc601\uc5b4 TTS\uc640 \ud638\ud658\ub418\ub294 \uc5bc\uad74 \uc0dd\uc131 \uc5d4\uc9c4\uc774 \ubcc4\ub3c4\ub85c \uc874\uc7ac\ud558\uae30 \ub54c\ubb38\uc5d0, \uc601\uc5b4 \ubc1c\ud654 \uc601\uc0c1\uc744 \uac00\uc9c0\uace0 \uc804\uc2dc\ud560 \uc218 \uc788\uc9c0\ub9cc, \ub9c9\uc0c1 \uc74c\uc131\uc744 \ub4e4\uc5b4\ubcf4\uba74 \uc2e4\uc81c \ubc1c\ud654\uc790\uac00 \ub2e4\uad6d\uc5b4 \ubc1c\ud654\ub97c \ud560 \uc218 \uc788\ub294 \uac8c \uc544\ub2c8\uba74 TTS \ubaa9\uc18c\ub9ac\uac00 \ubcf8\uc778 \ubaa9\uc18c\ub9ac\uac00 \uc544\ub2cc \uacbd\uc6b0\uac00 \ub9ce\uc2b5\ub2c8\ub2e4. \uc601\uc5b4 \uc601\uc0c1 \ubfd0\ub9cc \uc544\ub2c8\ub77c, \ub3d9\uc77c\ud55c \ud1a4\uacfc \uc5bc\uad74\ub85c \uc77c\ubcf8\uc5b4, \uc911\uad6d\uc5b4\ub97c \ubc1c\ud654\ud558\ub294 AI Human\uc744 \uc804\uc2dc\ud55c \ub355\uc5d0 \ub354\uc6b1 \ub9ce\uc740 \ubd84\ub4e4\ub85c\ubd80\ud130 \uc774\ubaa9\uc744 \ub04c\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\uc774\ubc88 CES\uc5d0\uc11c \ubcf4\uc5ec\ub4dc\ub9b0 \ub2e4\uad6d\uc5b4 \ubc1c\ud654 \uac00\ub2a5\ud55c AI Human \uae30\uc220\ub4e4\uc744 \ud1b5\ud558\uc5ec \uc6d0\ub798 \uc911\uad6d\uc5b4, \uc601\uc5b4, \uc77c\ubcf8\uc5b4\ub97c \ud558\uc9c0 \ubabb\ud558\ub294 \ubd84\ub3c4 4\uac1c \uad6d\uc5b4\ub97c \ud558\uc2e4 \uc218 \uc788\ub3c4\ub85d \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774 \uc678\ub85c\ub3c4 Brain\ud300\uc740 \ube60\ub978 \ucd94\ub860 \uc18d\ub3c4\uc640 \uc88b\uc740 \ud004\ub9ac\ud2f0\uc758 \uc5bc\uad74 \uc601\uc0c1\uc744 \uae30\ubc18\uc73c\ub85c \ub354\uc6b1 \uc790\uc5f0\uc2a4\ub7fd\uace0 \ub300\ud654\uac00 \uac00\ub2a5\ud55c AI Human\uc774 \ub418\ub294 \ub370\uc5d0 \ud544\uc694\ud55c \uc5ec\ub7ec \uc54c\uace0\ub9ac\uc998\uc744 \uad6c\uc131\ud574\ub098\uac08 \uc608\uc815\uc785\ub2c8\ub2e4.  \\n\\nCES\uc5d0\uc11c \ub290\ub080 \uc7ac\ubbf8\ub294 \ud559\ud68c\ub97c \ucc38\uc11d\ud574\uc11c \ub290\ub07c\ub294 \uac10\ub3d9\uacfc \uc7ac\ubbf8\ub294 \uc0c9\ub2ec\ub790\uc2b5\ub2c8\ub2e4. \ud559\ud68c\uc5d0\uc11c\ub294 \uc5ec\ub7ec \uac00\uc9c0 Contribution\uc5d0 \ub300\ud55c \uc9c8\ubb38, \ubc29\ubc95\ub860\uc5d0 \ub300\ud55c \uc9c8\ubb38\uc774 \ub9ce\uc558\ub2e4\uba74, CES\uc5d0\uc11c AI Human\uc5d0 \ub300\ud574 \ubc1b\uc740 \uc9c8\ubb38\ub4e4\uc740 \ud488\uc9c8 \uc790\uccb4\uc5d0 \ub300\ud574 \uaf3c\uaf3c\ud55c \ud53c\ub4dc\ubc31\ub4e4\uc774 \uc8fc\ub97c \uc774\ub918\uc2b5\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uc5b4, \ube44\ub514\uc624 \uc7ac\uc0dd\uc774 \ub290\ub9ac\uac70\ub098 \ubc84\ubc85\uc774\ub294 \ubd80\ubd84\uc774 \uae30\uae30\uc758 \ubb38\uc81c\uc778\uc9c0 \uc54c\uace0\ub9ac\uc998\uc758 \ubb38\uc81c\uc778\uc9c0\ub97c \uc5ec\ucb64\ubcf4\ub294 \uc9c8\ubb38\ub4e4\uc774\uc5c8\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \ub354\uc6b1 \ub9ce\uc740 \uc190\ub3d9\uc791\ub4e4\uc774 \uac00\ub2a5\ud588\uc73c\uba74 \uc88b\uaca0\ub2e4\ub294 \ud53c\ub4dc\ubc31\uc774\ub098 \ubc16\uc5d0\uc11c \uac78\uc5b4 \ub4e4\uc5b4\uc624\uace0 \ub098\uac00\ub294 \ub4f1\uc758 \uae30\ud68d\uc774 \ub4b7\ubc1b\uce68\ub418\uba74 \uc88b\uc744 \uac83 \uac19\ub2e4\ub294 \uc758\uacac\ub3c4 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\ubcf4\ud1b5 \ub525\ub7ec\ub2dd \ubaa8\ub378\uc744 \uc5f0\uad6c\ud558\uace0 \ub9cc\ub4dc\ub294 \uc0ac\ub78c\uc774 \uc774\ub7ec\ud55c \ud53c\ub4dc\ubc31\uc744 \uc9c1\uc811 \ubc1b\ub294 \uc77c\uc774 \uc5c6\ub294\ub370, \uc9c1\uc811 \ud53c\ub4dc\ubc31\uc744 \ub4e4\uc5b4 \ubcf4\uba74\uc11c \ubaa8\ub378\uc5d0\uc11c \uc218\uc815\ud574\uc57c \ud560 \ubd80\ubd84\uc774\ub098 \uac1c\uc120\ud560 \uc218 \uc788\ub294 \ubd80\ubd84\uc774 \uc788\uc744 \uc9c0 \uc0dd\uac01\ud574\ubcf4\ub294 \uc2dc\uac04\uc774 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ubc31\uc5d4\ub4dc\ub098 \uc11c\ube44\uc2a4 \uae30\ud68d\uc5d0\uc11c \ud574\uacb0\ud574\uc57c \ud560 \uc774\uc288 \uc5ed\uc2dc \ubaa8\ub378\uc744 \uad6c\uc131\ud558\ub294 \uc785\uc7a5\uc5d0\uc11c \uc88b\uc740 \ud53c\ub4dc\ubc31\uc774 \ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc544\ubb34\ub798\ub3c4 \uc0dd\uc131 \ubaa8\ub378\uc744 \uc5f0\uad6c\ud558\uace0 \uc788\uace0, \uc0dd\uc131\ud55c \uc601\uc0c1\uc774\ub098 \uc74c\uc131\uc774 \uadf8\ub300\ub85c \uc0ac\uc6a9\uc790\uc5d0\uac8c \ub178\ucd9c\uc774 \ub418\ub2e4 \ubcf4\ub2c8 \uc774\ub7ec\ud55c \ud53c\ub4dc\ubc31\uc774 \ub354\uc6b1 \uc640\ub2ff\ub294 \uac83 \uac19\uc2b5\ub2c8\ub2e4. \uc544 \ubb3c\ub860, \uc800\ub294 \uadf8\ub798\ub3c4 CES\ubcf4\ub2e4\ub294 \ud559\ud68c\uac00 \ub9c8\uc74c\ub3c4 \ud3b8\ud558\uace0 \ub354 \uc7ac\ubc0c\ub294 \uac83 \uac19\uc2b5\ub2c8\ub2e4 :smile:  \\n\\n<img className={styles.figCenter} src={figVegasEnd} alt=\\"figure4_vegas\\" />\\n\\n\\nBrain\ud300\uc5d0\uc11c Publish\ud55c 2022\ub144 CVPR, ICASSP Paper\ub97c \ud3ec\ud568\ud558\uc5ec, 2021\ub144 NeurIPS Workshop, InterSpeech Paper\uc5d0\ub3c4 \ub9ce\uc740 \uad00\uc2ec \ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4!\\n\\n\\n\\n### TL;DR\\n\\n- \ub9c8\uc778\uc988\ub7a9 AI Human\uc774 \ubbf8\uad6d \ub77c\uc2a4\ubca0\uac00\uc2a4\uc5d0\uc11c \uc5f4\ub9b0 CES 2022\uc5d0 \uc804\uc2dc\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\\n- \ud55c\uad6d\uc5b4 \ub370\uc774\ud130\ub9cc \uac00\uc9c0\uace0 \uc601\uc5b4, \uc77c\ubcf8\uc5b4, \uc911\uad6d\uc5b4\uae4c\uc9c0 \ubc1c\ud654\ud558\ub294 \ub370\ubaa8\ub85c \uc815\ub9d0 \ub9ce\uc740 \ud638\ud3c9\uc744 \ubc1b\uc558\uc2b5\ub2c8\ub2e4.\\n- \ud559\ud68c \ub9d0\uace0 \uc804\uc2dc\ud68c\uc5d0 \ucc38\uc11d\ud558\uba74\uc11c \uc0dd\uc131 \ubaa8\ub378 \uc5f0\uad6c\uc640 \uc0dd\uc131 \ubaa8\ub378 \uc0c1\uc6a9\ud654 \uc0ac\uc774\uc758 \uac04\uadf9\uc744 \ud55c \ubc88 \ub354 \ub290\uaf08\uc2b5\ub2c8\ub2e4."},{"id":"vits","metadata":{"permalink":"/blog/vits","source":"@site/blog/2021-10-19-paper-review-vits/index.mdx","title":"VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech","description":"\ubcf5\uc7a1\ub2e4\ub2e8\ud55c End-to-End TTS \ubaa8\ub378\uc778 VITS\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2021-10-19T00:00:00.000Z","formattedDate":"October 19, 2021","tags":[{"label":"paper-review","permalink":"/blog/tags/paper-review"}],"readingTime":31.505,"truncated":false,"authors":[{"name":"Wonbin Jung","title":"AI Scientist (Audio)","url":"https://github.com/Wonbin-Jung","imageURL":"https://github.com/Wonbin-Jung.png","key":"wonbin"}],"frontMatter":{"slug":"vits","title":"VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech","description":"\ubcf5\uc7a1\ub2e4\ub2e8\ud55c End-to-End TTS \ubaa8\ub378\uc778 VITS\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/mindslab_default.png","authors":["wonbin"],"tags":["paper-review"]},"prevItem":{"title":"CES 2022\uc5d0 \ucc38\uc11d\ud55c \ub9c8\uc778\uc988\ub7a9, AI Human","permalink":"/blog/ces-2022-review"},"nextItem":{"title":"Activate or Not: Learning Customized Activation","permalink":"/blog/acon"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figAttention from \'./image/alignment.png\';\\nimport figMas from \'./image/mas.png\';\\nimport figFlow from \'./image/flow.png\';\\nimport figTraining from \'./image/training.png\';\\nimport figInference from \'./image/inference.png\';\\nimport figTextEncoder from \'./image/text_encoder.png\';\\nimport figPosteriorEncoder from \'./image/posterior_encoder.png\';\\nimport figPriorEncoder from \'./image/prior_encoder.png\'\\nimport figDecoder from \'./image/decoder.png\'\\nimport figFigureFive from \'./image/figure5.png\'\\nimport figFigureSix from \'./image/figure6.png\'\\nimport figDurationPredictor from \'./image/duration_predictor.png\'\\nimport figTableOne from \'./image/table1.png\'\\nimport figTableTwo from \'./image/table2.png\'\\nimport figTableThree from \'./image/table3.png\'\\nimport figFigureTwo from \'./image/figure2.png\'\\nimport figFigureThree from \'./image/figure3.png\'\\nimport figTableFour from \'./image/table4.png\'\\nimport figFigureSeven from \'./image/figure7.png\'\\n\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2106.06103-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2106.06103)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/jaywalnut310/vits)\\n[![githubio](https://img.shields.io/static/v1?message=Audio%20Samples&logo=Github&labelColor=grey&color=lightgrey&logoColor=white&label=%20&style=flat-square)](https://jaywalnut310.github.io/vits-demo/index.html)\\n\\n> Kim, Jaehyeon, Jungil Kong, and Juhee Son. \\"Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech.\\" \\n>\\n> International Conference on Machine Learning (ICML) 2021\\n\\n## Variational Inference with adversarial learning for end-to-end Text-to-Speech\\n\\n\\n\uc548\ub155\ud558\uc138\uc694! MINDs Lab Brain\uc5d0\uc11c text-to-speech (TTS) \uc5f0\uad6c\ub97c \ud558\uace0 \uc788\ub294 \uc815\uc6d0\ube48\uc785\ub2c8\ub2e4. \uc624\ub298\uc740 \uc9c0\ub09c \uc5ec\ub984\uc5d0 \ubc1c\ud45c\ub41c end-to-end TTS\uc778 Variational Inference with adversarial learning for end-to-end Text-to-Speech, **VITS**\uc5d0 \ub300\ud574 \uc18c\uac1c\ud558\uace0, \ub9ac\ubdf0\ub97c \uc9c4\ud589\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\\n\\n### Contributions\\n\\n- 1\ub2e8\uacc4 \ud569\uc131 \ubc0f \ubcd1\ub82c \ud2b8\ub808\uc774\ub2dd\uc774 \uac00\ub2a5\ud558\uba70 \uc131\ub2a5\uc774 \uae30\uc874 \ubaa8\ub378\uc5d0 \uacac\uc904 \uc218 \uc788\ub294 end-to-end TTS\ub97c \uc81c\uc548\ud588\uc2b5\ub2c8\ub2e4.\\n- Variational Auto-Encoder (VAE)\uc758 \uad6c\uc870\ub97c \uc801\uc6a9\ud558\uc5ec 2\ub2e8\uacc4 \ud569\uc131\uc744 \ud558\ub098\ub85c \uc5f0\uacb0\uc2dc\ucf30\uc2b5\ub2c8\ub2e4.\\n- Variational inference\uc5d0 normalizing flow\uc640 generative adversarial network (GAN)\uc758 adversarial training\uc744 \uacb0\ud569\uc2dc\ucf1c \ud45c\ud604\ub825\uc744 \ub192\uc600\uc2b5\ub2c8\ub2e4.\\n- Stochastic duration predictor (SDP)\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub79c\ub364\ud558\uac8c \uc74c\uc131\uc758 \uae38\uc774\ub97c \uc608\uce21\ud558\ubbc0\ub85c \uc74c\uc131\uc758 \ub2e4\uc591\uc131\uc774 \ud5a5\uc0c1\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n### Background Knowledge\\n\\n#### Neural TTS\uc758 \ubcc0\ud654: 2\ub2e8\uacc4\uc5d0\uc11c 1\ub2e8\uacc4\ub85c\\n\\nNeural network\ub97c \uc0ac\uc6a9\ud55c TTS \uc5f0\uad6c\uac00 \uc2dc\uc791\ub418\uace0, \uc5f0\uad6c\uac00 \ucd95\uc801\ub418\uba74\uc11c \uadf8 \ud30c\uc774\ud504\ub77c\uc778\uc740 2\ub2e8\uacc4 \ud569\uc131\uc774 \uc8fc\ub958\ub97c \ucc28\uc9c0\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\uc774\ub7ec\ud55c 2\ub2e8\uacc4 \ud569\uc131 \uacfc\uc815\uc740 \ud14d\uc2a4\ud2b8\ub97c \uc911\uac04 \uacb0\uacfc\ubb3c\ub85c \ubc14\uafb8\ub294 **\uc5b4\ucfe0\uc2a4\ud2f1 \ubaa8\ub378**\uacfc \uc911\uac04 \uacb0\uacfc\ubb3c\uc744 \uc74c\uc131 \ud30c\ud615\uc73c\ub85c \ubcc0\ud658\ud558\ub294 **\ubcf4\ucf54\ub354**\ub85c \uc774\ub8e8\uc5b4\uc9c0\ub294\ub370, \ub192\uc740 \uc74c\uc9c8\uc758 \uc74c\uc131\uc744 \ud569\uc131\ud558\ub294\ub370 \uc131\uacf5\ud588\uc9c0\ub9cc \uc5b4\ub290 \ud55c \ub2e8\uacc4\uc5d0\uc11c \ud2b8\ub808\uc774\ub2dd\uc774 \uc9c1\ub82c\ub85c \uc774\ub904\uc9c0\uac70\ub098 \uc774\uc804 \ub2e8\uacc4\uc5d0\uc11c \uc5bb\uc740 \uacb0\uacfc\ubb3c\ub85c \uc774\ud6c4 \ub2e8\uacc4\ub97c fine-tuning\ud558\ub294 \uc791\uc5c5\uc774 \uc694\uad6c\ub418\ub294 \ub4f1\uc758 \ubb38\uc81c\uc810\uc774 \ub0a8\uc544 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c \uc911\uac04 \uacb0\uacfc\ubb3c\uc758 \ud615\ud0dc(\uc8fc\ub85c mel-spectrogram)\uac00 \uace0\uc815\ub418\uc5b4 hidden representation \ud559\uc2b5\uc744 \ud1b5\ud55c \ubcc0\ud615\uc774\ub098 \uc131\ub2a5 \ud5a5\uc0c1\uc774 \ubd88\uac00\ub2a5\ud558\ub2e4\ub294 \ub09c\uc810\uc774 \uc874\uc7ac\ud569\ub2c8\ub2e4.\\n\\n\ucd5c\uadfc \uc774\ub7f0 \ub09c\uad00\uc744 \uadf9\ubcf5\ud558\uae30 \uc704\ud574 FastSpeech 2S[[5]](#r5)\ub098 EATS[[6]](#r6) \uac19\uc774 \ud14d\uc2a4\ud2b8\uc5d0\uc11c \uc74c\uc131\uc744 \ubc14\ub85c \ud569\uc131\ud558\ub294 end-to-end TTS\ub4e4\uc774 \uc81c\uc548\ub418\uace0 \uc788\ub294\ub370, \uc774\ub4e4\uc740 adversarial training\uc5d0 \uc804\uccb4 \uc74c\uc131 \ub300\uc2e0 \uc9e7\uc740 \uc624\ub514\uc624 \ud074\ub9bd\uc744 \uc0ac\uc6a9\ud558\uace0 \uae38\uc774\uac00 \ub2e4\ub978 \uc74c\uc131 \uc0ac\uc774\uc758 \ucc28\uc774\ub97c loss\ub85c \uacc4\uc0b0\ud558\uae30 \uc704\ud55c \ubc29\uc2dd\uc744 \uace0\uc548\ud558\uc600\uc2b5\ub2c8\ub2e4. \uadf8\ub7fc\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 1\ub2e8\uacc4 \ud569\uc131\uc744 \ud1b5\ud574 \ub9cc\ub4e4\uc5b4\uc9c4 \uc74c\uc131\uc758 \uc74c\uc9c8\uc740 2\ub2e8\uacc4 \ud569\uc131\uc758 \uadf8\uac83\ubcf4\ub2e4 \ub0ae\uc740 \uc218\uc900\uc5d0 \uba38\ubb3c\ub800\uc2b5\ub2c8\ub2e4.\\n\\n\uc624\ub298 \ub9ac\ubdf0\uc758 \uc8fc\uc778\uacf5\uc778 VITS \ub610\ud55c 1\ub2e8\uacc4 \ud569\uc131\uc774 \uac00\ub2a5\ud55c end-to-end TTS \uc5f0\uad6c \uc911 \ud558\ub098\ub85c, \uc5b4\ub5a4 \ubc29\uc2dd\uc744 \ud1b5\ud574 VITS\uac00 2\ub2e8\uacc4 \ud569\uc131\ub9cc\ud07c \ub192\uc740 \uc74c\uc9c8\uc744 \ub2ec\uc131\ud588\ub294\uc9c0 \uc124\uba85\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\\n\\n#### TTS\uc758 \uadfc\ubcf8\uc801 \ub09c\uc81c: One-to-Many Problem\\n\\n\uc0ac\ub78c\ub4e4\uc740 \uac19\uc740 \ud14d\uc2a4\ud2b8\ub3c4 \uc5ec\ub7ec \ubc29\uc2dd\uc73c\ub85c \uc77d\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc0ac\ub78c\ub9c8\ub2e4 \ub2e4\ub978 \ubaa9\uc18c\ub9ac\uc640 \ubc1c\ud654 \ud328\ud134\uc744 \uac00\uc9c0\ub294 \uac74 \ubb3c\ub860\uc774\uace0, \uac19\uc740 \uc0ac\ub78c\uc774\ub77c\ub3c4 \ub192\ub0ae\uc774\ub098 \uc18d\ub3c4\ub97c \uc870\uc808\ud558\uba74\uc11c \uac19\uc740 \uae00\uc790\ub97c \ub2e4\ub974\uac8c \uc77d\uc744 \uc218 \uc788\uae30 \ub54c\ubb38\uc5d0 \ud14d\uc2a4\ud2b8\uc640 \uc74c\uc131\uc744 one-to-many relationship\ub97c \uc774\ub8e8\uac8c \ub429\ub2c8\ub2e4. \uc774\ub7f0 \uc778\uac04 \ubc1c\ud654\uc758 \ud2b9\uc131 \ub54c\ubb38\uc5d0 TTS \ub610\ud55c \uc77c\uc885\uc758 one-to-many problem\uc774 \ub418\uace0, \ub54c\ubb38\uc5d0 \ud558\ub098\uc758 \ud14d\uc2a4\ud2b8\uc5d0 \ud558\ub098\uc758 \uc74c\uc131\ub9cc\uc774 \ub300\uc751\ub41c\ub2e4\ub294 \uac00\uc815 \ud558\uc5d0\uc11c \uc774 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub824 \ud558\ub294 \uac83\uc740 \uc704\ud5d8\ud55c \uc2dc\ub3c4\uac00 \ub429\ub2c8\ub2e4.\\n\\nVITS \ub610\ud55c \uc774\ub7ec\ud55c TTS\uc758 \ud2b9\uc131\uc744 \uc778\uc2dd\ud558\uace0, latent modeling\uacfc SDP\ub97c \ud1b5\ud574 \uc774\uc5d0 \ub300\uc751\ud558\uace0\uc790 \ud569\ub2c8\ub2e4.\\n\\n#### \ud569\uc131\uc74c\uc758 \uae38\uc774 \uc608\uce21: Alignment\uc640 Duration Predictor-based Model\\n\\n2\ub2e8\uacc4 \ud569\uc131 \uc911 \uc5b4\ucfe0\uc2a4\ud2f1 \ubaa8\ub378\uc740 \ubcf4\ud1b5 \uc778\ucf54\ub354\uac00 \ud14d\uc2a4\ud2b8\ub97c \uc785\ub825\ubc1b\uace0, \ub514\ucf54\ub354\uac00 \uc74c\uc131\uc744 \ucd9c\ub825\ud558\ub294 \ud615\ud0dc\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4.\\n\uadf8\ub7ec\ub098 \uc785\ucd9c\ub825\uc774 \ub2e4\ub978 \uae38\uc774\uc758 \uc2dc\ud000\uc2a4\uc774\ubbc0\ub85c, \ucd9c\ub825 \uc2dc\ud000\uc2a4\uc758 \ud2b9\uc815 \ubd80\ubd84\uc774 \uc785\ub825 \uc2dc\ud000\uc2a4\uc758 \uc5b4\ub5a4 \ubd80\ubd84\uc5d0 \ub300\uc751\ub418\ub294\uc9c0 \uc54c\uc544\uc57c \uae38\uc774\ub97c \ub9de\ucdb0\uac00\uba70 \uacb0\uacfc\ubb3c\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub7ec\ud55c \uc785\ucd9c\ub825 \uc0ac\uc774\uc758 \uad00\uacc4\ub97c alignment\ub77c\uace0 \ubd80\ub985\ub2c8\ub2e4. \uc0ac\ub78c\uc740 \ud14d\uc2a4\ud2b8\ub97c \uc801\ud78c \uc21c\uc11c\ub300\ub85c \uc77d\uc5b4\ub098\uac00\ubbc0\ub85c, \ub2ec\ub9ac \ubcf4\uba74 alignment\ub294 \ud14d\uc2a4\ud2b8\uc758 \uac01 \ubd80\ubd84\uc774 \uc74c\uc131\uc5d0\uc11c \uc5bc\ub9c8\ub9cc\ud07c\uc758 \uae38\uc774(duration)\ub97c \ucc28\uc9c0\ud558\ub294\uc9c0 \ub098\ud0c0\ub0b8\ub2e4\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figAttention} alt=\\"attention\\" />\\n\\n<center><span>TTS\uc5d0 \uc758\ud574 \uc608\uce21\ub41c alignment\uc758 \uc608\uc2dc\ub85c, \uac01 \ub514\ucf54\ub354 \uc2a4\ud15d\uc5d0\uc11c \ud2b9\uc815 \uc778\ucf54\ub354 \uc2a4\ud15d\uc5d0 \ub300\uc751\ub420 \ud655\ub960\uc744 \ub098\ud0c0\ub0b4\uace0 \uc788\uc2b5\ub2c8\ub2e4.</span></center>\\n\\n<br/>\\n\\n\ub530\ub77c\uc11c \ud14d\uc2a4\ud2b8\ub9cc \uc8fc\uc5b4\uc9c0\ub294 \uc0c1\ud669\uc5d0\uc11c TTS\ub294 alignment\ub97c \uad6c\ud558\uae30 \uc704\ud574 \ud14d\uc2a4\ud2b8\uc758 \uac01 \uc74c\uc18c(phoneme)\uac00 \uc74c\uc131\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uae38\uac8c \ubc1c\ud654\ub418\ub294\uc9c0 \uc608\uce21\ud560 \ud544\uc694\uac00 \uc788\uc2b5\ub2c8\ub2e4. Duration predictor\ub294 \uc774\uc5d0 \ub300\ud55c \ud574\ubc95 \uc911 \ud558\ub098\ub85c, \ud14d\uc2a4\ud2b8 \ub0b4\uc758 \uac01 \uc74c\uc18c\uc758 \uae38\uc774\ub97c \uc608\uce21\ud574\uc11c alignment\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\\n\\n#### \uac00\uc5ed\ubcc0\ud658\uc73c\ub85c \ubcf5\uc7a1\ud55c \ubd84\ud3ec\ub97c \ub2e4\ub8e8\uae30 \uc27d\uac8c \ubc14\uafb8\uae30: Normalizing Flow\\n\\nNormalizing flow\ub294 GAN\uc774\ub098 VAE\uc640 \uac19\uc740 \uc77c\uc885\uc758 \uc0dd\uc131 \ubaa8\ub378\uc785\ub2c8\ub2e4. \uac00\uc6b0\uc2dc\uc548 \ubd84\ud3ec \uac19\uc740 \ub2e8\uc21c\ud55c \ubd84\ud3ec\uc5d0 \uc77c\ub828\uc758 \uac00\uc5ed \ubcc0\ud658\uc744 \uc5f0\uc1c4\uc801\uc73c\ub85c \uac00\ud558\uc5ec \ubcf5\uc7a1\ud55c \ubd84\ud3ec\ub85c \ubcc0\ud615\uc2dc\ud0a4\ub294 \uacfc\uc815\uc744 \ud1b5\ud574 \ud604\uc2e4\uc758 \ubcf5\uc7a1\ud55c \ubd84\ud3ec\ub97c \uac04\ub2e8\ud55c \ubd84\ud3ec\uc5d0 \ub300\uc751\uc2dc\ud0ac \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc57d\uac04\uc758 \uacc4\uc0b0 \uacfc\uc815\uc744 \uac70\uce58\uba74, \ud604\uc2e4\uc758 \ud655\ub960 \ubd84\ud3ec\uc5d0 \uae30\ubc18\ud55c $x = z_K$\ub97c \ub2e8\uc21c\ud55c \ubd84\ud3ec\uc5d0\uc11c \ubc1c\uc0dd\ud55c latent $z = z_0$\ub85c\ubd80\ud130 \uad6c\ud560 \uc218 \uc788\ub2e4\ub294 \uc810\uc774 normalizing flow\uc758 \ud2b9\uc9d5\uc774\uba70, \uc77c\ub828\uc758 \uac00\uc5ed \ubcc0\ud658\uc73c\ub85c \uad6c\uc131\ub418\uae30 \ub54c\ubb38\uc5d0 \ubc18\ub300\ub85c $x$\uc5d0\uc11c $z$\ub97c \uad6c\ud560 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figFlow} alt=\\"flow\\" />\\n\\n\\n<center><span>Normalizing flow\uc758 \uc791\ub3d9 \uacfc\uc815 \ub3c4\uc2dd<a href=\\"#r4\\">[4]</a>. \ubcc0\ud658\uc774 \uac70\ub4ed\ub418\uba74\uc11c \ub2e8\uc21c\ud55c \ubd84\ud3ec\uac00 \ubcf5\uc7a1\ud55c \ubd84\ud3ec\ub85c \uc810\ucc28 \ubc14\ub00c\uc5b4 \ub098\uac11\ub2c8\ub2e4.</span></center>\\n\\n<br/>\\n\\nVITS\uc5d0\uc11c normalizing flow\ub294 \uc8fc\ub85c \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294 \uc911\uc5d0 \ubcf5\uc7a1\ud55c \ub370\uc774\ud130 \ubd84\ud3ec\uc5d0\uc11c \ucd94\ucd9c\ub41c \uac12\uc744 \uc815\uaddc \ubd84\ud3ec \ud558\uc758 \uac12\uc73c\ub85c \ubcc0\ud658\ud558\uc5ec \uad00\uacc4\ub97c \ud559\uc2b5\ud558\uace0, \uc74c\uc131 \ud569\uc131 \uc2dc\uc5d0\ub294 \uc815\uaddc \ubd84\ud3ec\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ub41c \uac12\uc774\ub098 \ub178\uc774\uc988\ub97c \uadf8\uc5d0 \ub300\uc751\ud558\ub294 \ubcf5\uc7a1\ud55c \ubd84\ud3ec\uc758 \uac12\ub4e4\ub85c \uc5ed\ubcc0\ud658\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \uc0ac\uc6a9\ub429\ub2c8\ub2e4.\\n\\n### Overview\\n\\n\uc774 \uc139\uc158\uc5d0\uc11c\ub294, VITS\uc758 \uad6c\uc870\uc5d0 \uc758\ud574 loss \uc2dd\uc774 \uacc4\uc0b0\ub418\ub294 \uacfc\uc815\uc744 \ub2e4\ub8f9\ub2c8\ub2e4.  VITS\uc758 \ub3c4\uc2dd\ub3c4\ub294 \uc544\ub798\uc640 \uac19\uc774 \ub098\ud0c0\ub0a9\ub2c8\ub2e4.\\n\\n|                       VITS at training                       |                      VITS at inference                       |\\n| :----------------------------------------------------------: | :----------------------------------------------------------: |\\n| ![training](./image/training.png ) | ![inference](./image/inference.png) |\\n\\n\uc804\uccb4\uc801\uc73c\ub85c \ubcf4\uba74, VITS\ub294 text encoder\uc640 flow\ub85c \uc774\ub904\uc9c4 prior encoder, \uadf8\ub9ac\uace0 latent $z$\ub97c \uc74c\uc131\uc73c\ub85c \ubcc0\ud658\ud558\ub294 decoder\ub85c \uc774\ub904\uc9c4 VAE\uc758 \uad6c\uc870\ub97c \ucde8\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \uac70\uae30\uc5d0 duration predictor, posterior encoder, discriminator, monotonic alignment search (MAS) \ub4f1\uc758 \ubaa8\ub4c8 \ubc0f \uacfc\uc815\uc774 \ubd99\uc740 \ud615\ud0dc\uc785\ub2c8\ub2e4.\\n\\n\ub530\ub77c\uc11c \uc6b0\uc120 data $x$\uc758 marginal log-likelihood \ud558\ud55c\uc5d0 \ub300\uc751\ub418\ub294 evidence lower bound (ELBO)\ub294 \uc544\ub798\uc640 \uac19\uc774 \ud45c\ud604\ud560 \uc218 \uc788\uace0, \uc2e4\uc81c\ub85c\ub294 negative ELBO\ub97c training loss\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\\n\\n$$\\n\\\\log p_\\\\theta(x|c) \\\\geq \\\\mathbb{E}_{q_\\\\phi(z|x)}[\\\\log p_\\\\theta(x|z) - \\\\log \\\\frac {q_\\\\phi(z|x)} {p_\\\\theta(z|c)}]\\n$$\\n\\nNegative ELBO\uc758 \ub450 \ud56d\uc740 \uac01\uac01 reconstruction loss\uc640 KL divergence\uc5d0 \ud574\ub2f9\ub418\uace0, \ud480\uc5b4\uc11c \uacc4\uc0b0\ud558\uba74 \uc544\ub798\uc640 \uac19\uc774 \uc815\ub9ac\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. Prior encoder\uc758 \uacbd\uc6b0 latent $z$\ub97c \uad6c\ud558\uae30 \uc704\ud574 text encoder\uc640 alignment \uc791\uc5c5\uc744 \uac70\uce58\uace0 \ub2e4\uc2dc flow\ub97c \uc9c0\ub098\uae30 \ub54c\ubb38\uc5d0 \ucd94\uac00 \ud56d\uc774 \ubd99\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n$$\\nL_{recon} = \\\\|x_{mel} - \\\\hat x_{mel}\\\\|_1 \\\\\\\\\\nL_{kl} = \\\\log{q_\\\\phi(z|x_{lin})} - \\\\log{p_\\\\theta(z|c_{text}, A)} \\\\\\\\\\nz \\\\sim q_\\\\phi(z|x_{lin}) = N\\\\big(z; \\\\mu_\\\\phi(x_{lin}), \\\\sigma_\\\\phi(x_{lin})\\\\big),\\\\\\\\\\np_\\\\theta(z|c_{text}, A) = N\\\\big(f_\\\\theta(z); \\\\mu_\\\\theta(c_{text}, A), \\\\sigma_\\\\theta(c_{text}, A)\\\\big) \\\\bigg|det \\\\frac {\\\\partial f_\\\\theta(z)} {\\\\partial z}\\\\bigg| \\\\\\\\\\n$$\\n\\n\ub610\ud55c decoder\ub294 GAN\uc758 generator\uc5d0 \ud574\ub2f9\ub418\ubbc0\ub85c, generator\uc640 discriminator\uc758 loss\ub97c GAN\uc758 adversarial loss\uc5d0 \ub9de\uac8c \uc124\uc815\ud569\ub2c8\ub2e4. \uc774 \ub54c, \ucd94\uac00\ub85c feature matching loss\ub97c \uc124\uc815\ud558\uc5ec discrminator\uc758 \uac01 \ub808\uc774\uc5b4\uc5d0\uc11c \uc6d0\ubcf8 \uc74c\uc131\uacfc \uc0dd\uc131\ub41c \uc74c\uc131 feature map \uc0ac\uc774\uc758 L1-norm\uc5d0 \uae30\ubc18\ud55c loss\ub97c \ub3c4\uc785\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\\n$$\\nL_{adv}(D) = \\\\mathbb E_{(y,z)}\\\\bigg[\\\\big(D(y) - 1\\\\big)^2 + \\\\big(D(G(z))\\\\big)^2\\\\bigg] \\\\\\\\\\nL_{adv}(G) = \\\\mathbb E_z\\\\bigg[\\\\big(D(G(z)) - 1\\\\big)^2\\\\bigg] \\\\\\\\\\nL_{fm}(G) = \\\\mathbb E_{(y,z)}\\\\bigg[\\\\sum_{l=1}^T\\\\frac{1}{N_l}\\\\|D^l(y) - D^l(G(z))\\\\|_1\\\\bigg]\\n$$\\n\\nDuration predictor\uc5d0\uc11c\ub294 \uc785\ub825\ub418\ub294 \ud14d\uc2a4\ud2b8\uc758 hidden representation\uc758 \uac01 \ud1a0\ud070\uc5d0 \ud574\ub2f9\ub418\ub294 latent variable \uac2f\uc218\ub97c \ud1a0\ud070\uc758 \uae38\uc774, \uc989 duration\uc73c\ub85c \uace0\ub824\ud558\uc5ec \uacc4\uc0b0\ud569\ub2c8\ub2e4. Glow-TTS\ub294 \uac01 \ud1a0\ud070\uc758 \uc608\uce21\ub41c \uae38\uc774\ub97c \uc0ac\uc6a9\ud574 MSE loss\ub97c duration loss\ub85c \uc0ac\uc6a9\ud558\uc9c0\ub9cc, \uc774\ub294 deterministic duration predictor\ub85c VITS\uc758 SDP\ucc98\ub7fc \ub9e4\ubc88 \ub2ec\ub77c\uc9c0\ub294 \ubc1c\ud654 \uae38\uc774\ub97c \uad6c\ud604\ud558\uae30 \uc704\ud574\uc120 \ub2e4\ub978 \ubc29\uc2dd\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.\\n\\n\uadf8\ub807\uac8c \uace0\uc548\ub41c SDP\ub294 flow-based model\ub85c duration\uc758 distribution\uc744 \ubaa8\ub378\ub9c1\ud558\uc5ec maximum likelihood estimation\ub85c duration\uc744 \uc608\uce21\ud569\ub2c8\ub2e4.\\n\uadf8\ub7ec\ub098 \uc5ec\uae30\ub294 \uc5ec\uae30\ub294 \uba87 \uac00\uc9c0 \ub09c\uc810\uc774 \uc788\ub294\ub370 \uc6b0\uc120 duration\uc740 \ubd88\uc5f0\uc18d\uc801\uc778 \uc591\uc758 \uc815\uc218\uc9c0\ub9cc continuous normalizing flow\uc5d0\uc11c\ub294 \uc5f0\uc18d\uc801\uc778 \uac12\uc744 \ub2e4\ub8ec\ub2e4\ub294 \uac83\uc774\uace0, \ub610 duration\uc740 \uc2a4\uce7c\ub77c\uc774\uae30 \ub54c\ubb38\uc5d0 flow\uc758 \uac00\uc5ed \uc870\uac74\uc744 \ucda9\uc871\ud558\uae30 \uc704\ud55c high-dimension transformation\uc774 \uc5b4\ub835\uc2b5\ub2c8\ub2e4. \uc774\ub97c \uc704\ud574 \ud574\uacb0\ucc45\uc73c\ub85c \ub3c4\uc785\ub41c \uac83\uc774 variational dequantization\uacfc variational data augmentation\uc785\ub2c8\ub2e4.\\n\\n\uc138\ubd80\uc801\uc73c\ub85c \uc124\uba85\ud558\uba74, duration sequence d\uc640 \uac19\uc740 \ucc28\uc6d0\uc758 random variable $u$\uc640 $v$\ub97c \uc0dd\uc131\ud569\ub2c8\ub2e4. \uc774\ub54c $u$\uc758 \ubc94\uc704\ub294 $[0, 1)$\ub85c \uc7a1\uc544 $d - u$\uac00 \uc591\uc758 \uc2e4\uc218\uac00 \ub418\uac8c \uc124\uc815\ud558\uace0, $v$\uc640 $d$\ub97c channel-wise\ud558\uac8c concatenate\ud558\uc5ec higher dimensional latent representation\uc744 \ub9cc\ub4ed\ub2c8\ub2e4. \uc774 \uac12\uc740 flow\uc744 \ud1b5\uacfc\ud574 $noise ~ N(0, I)$\ub85c \ubcc0\ud658\ub429\ub2c8\ub2e4. \uc5ec\uae30\uc11c \uc4f0\uc778 random variable $u, v$\ub97c \ubaa8\ub450 $d, c_{text}$\ub97c \uc870\uac74\uc73c\ub85c \ud55c approximate posterior distribution $q_\\\\phi$\uc5d0\uc11c \uc0d8\ud50c\ub9c1\ub418\ubbc0\ub85c, duration loss\ub294 duration log-likelihood\uc758 negative ELBO\uac00 \ub429\ub2c8\ub2e4. \uc0d8\ud50c\ub9c1 \uacfc\uc815\uc5d0\uc11c\ub294 \ubc18\ub300\ub85c, random noise\uac00 flow\uc758 \uc5ed\ubcc0\ud658\uc744 \uac70\uccd0 duration\uc774 \uc608\uce21\ub418\uace0, ceil operation\uc744 \uac70\uccd0 \uc815\uc218 \ud615\ud0dc\ub85c \ubcc0\ud658\ub429\ub2c8\ub2e4.\\n\\n$$\\n\\\\log{p_\\\\theta(d|c_{text})} \\\\geq \\\\mathbb E_{q_\\\\phi(u, v|d, c_{text})}\\\\bigg[\\\\log\\\\frac{p_\\\\theta(d-u,\\\\nu|c_{text})}{q_\\\\phi(u, \\\\nu|d, c_{text})}\\\\bigg] = -L_{dur}\\n$$\\n\\n\uace0\ub85c loss\uc758 \ucd5c\uc885 \ud615\ud0dc\ub294 \uc544\ub798\uc640 \uac19\uc774 \ub418\uace0, discrminator\ub294 \ubcc4\uac1c\ub85c $L_{adv}(D)$\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\\n\\n$$\\nL_{vae} = L_{recon} + L_{kl} + L_{dur} + L_{adv}(G) + L_{fm}(G)\\n$$\\n\\n#### Alignment Estimation\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figMas} alt=\\"alignment\\" />\\n\\n\x3c!-- ![alignment](./image/mas.png){: style={{width: 600px;}} .center-image} --\x3e\\n\\n<center><span>Monotonic alignment search\ub294 \uc77c\uc815\ud55c \uc870\uac74\uc744 \ub9cc\uc871\ud558\ub294 \ud14d\uc2a4\ud2b8 \uce21\uc758 hidden representation\uacfc </span></center>\\n<center><span>\uc74c\uc131 \uce21\uc758 latent representation \uc0ac\uc774\uc758 alignment\ub97c \ucc3e\ub294 \uacfc\uc815\uc774\ub2e4<a href=\\"#r1\\">[1]</a>.</span></center>\\n\\n<br/>\\n\\nVITS\ub294 \uc11c\ub85c \ub2e4\ub978 \uae38\uc774\uc758 \uc2dc\ud000\uc2a4\uc778 hidden representation\uacfc latent variable \uc0ac\uc774\uc758 alignment\ub97c \uad6c\ud558\uae30 \uc704\ud574 Glow-TTS\uc758 monotonic alignment search\ub97c \ud65c\uc6a9\ud569\ub2c8\ub2e4. MAS\ub294 dynamic programming\uc744 \uc0ac\uc6a9\ud55c \ud0d0\uc0c9\ubc95\uc785\ub2c8\ub2e4. \ud0d0\uc0c9\uc758 \uacfc\uc815\uc740 \ubaa8\ub4e0 \uc591\ucabd\uc758 \uc694\uc18c\ub4e4\uc774 \ub204\ub77d\ub418\uc9c0 \uc54a\uac8c alignment\uc5d0 \ub300\uc751\ub418\uace0(non-skipping), \uc120\ud6c4\uad00\uacc4\uac00 \ub4a4\uc9d1\ud788\uc9c0 \uc54a\ub3c4\ub85d, \uc989 \uc55e\uc758 latent variable\uac00 \ub4a4\uc758 latent variable\uc5d0 \ud574\ub2f9\ub418\ub294 hidden representation\ubcf4\ub2e4 \ub354 \ub4a4\ucabd\uc758 hidden representation\uc5d0 \ud574\ub2f9\ud558\uc9c0 \uc54a\ub3c4\ub85d(monotonic) \uc5ed\ubc29\ud5a5\uc73c\ub85c \uc9c4\ud589\ub429\ub2c8\ub2e4.\\n\\n\ucd5c\uc801\uc758 alignment $A$\ub294 flow $f$\ub97c \ud1b5\uacfc\ud55c $f(x)$\uc758 likelihood\ub97c \ucd5c\ub300\ud654\ud558\ubbc0\ub85c, $A$\ub294 \uc544\ub798\uc640 \uac19\uc774 \ucd94\uc0b0\ub429\ub2c8\ub2e4.\\n\\n$$\\nA = \\\\underset {\\\\hat A} {\\\\arg \\\\max} \\\\log p(x|c_{text}, \\\\hat A) \\\\\\\\\\n= \\\\underset {\\\\hat A} {\\\\arg \\\\max} \\\\log N(f(x);\\\\mu(c_{text}, \\\\hat A), \\\\sigma(c_{text}, \\\\hat A))\\n$$\\n\\n\ub2e4\ub9cc VITS\ub294 VAE \uae30\ubc18\uc774\ubbc0\ub85c \uc774 \uc870\uac74\uc744 \uadf8\ub300\ub85c \uc801\uc6a9\ud558\uae30 \uc5b4\ub824\uc6b0\ubbc0\ub85c, \ub300\uc2e0 loss\uc758 ELBO\ub97c \ucd5c\ub300\ud654\ud558\ub294 $A$\ub97c \ucc3e\ub294 \uc2dd\uc73c\ub85c \uc7ac\uc815\uc758\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\\n$$\\n\\\\arg \\\\max_{\\\\hat A} \\\\log p_\\\\theta(x_{mel}|z) - \\\\log \\\\frac {q_\\\\phi(z|x_{lin})} {p_\\\\theta(z|c_{text}, \\\\hat A)} \\\\\\\\\\n= \\\\arg \\\\max_{\\\\hat A} \\\\log p_\\\\theta(z|c_{text}, \\\\hat A) \\\\\\\\\\n= \\\\log N(f_\\\\theta(z);\\\\mu(c_{text}, \\\\hat A), \\\\sigma(c_{text}, \\\\hat A))\\n$$\\n\\nMAS\ub97c \uc0ac\uc6a9\ud558\ub294 \ub370\ub294 \uba87\uac00\uc9c0 \uc774\uc810\uc774 \ub530\ub974\ub294\ub370, \uc6b0\uc120 \ubc1c\ud654\uc758 \ud2b9\uc9d5\uc5d0 \ubd80\ud569\ud558\ub294 non-skipping monotonic alignment\ub97c \ud655\uc815\uc801\uc73c\ub85c \uc5bb\uc744 \uc218 \uc788\uace0, \uc678\ubd80 aligner\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uace0 end-to-end\ub85c \ubaa8\ub378\uc744 \ub514\uc790\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### Architecture\\n\\nVITS\ub294 prior encoder, posterior encoder, decoder, discriminator, SDP\uc758 5\uac00\uc9c0 \ubaa8\ub4c8\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\uc2b5\ub2c8\ub2e4. \ucc28\ub840\ub300\ub85c \uac01 \ubaa8\ub4c8\uc758 \uad6c\ud604\uc5d0 \ub300\ud574 \uc124\uba85\ud558\ub3c4\ub85d \ud558\uaca0\uc2b5\ub2c8\ub2e4.\\n\\n#### Prior Encoder\\n\\nPrior encoder\ub294 \ud14d\uc2a4\ud2b8\ub97c hidden representation\uc73c\ub85c \ubcc0\ud658\ud558\ub294 text encoder\uc640 latent variable\uc744 \uc591\ubc29\ud5a5 \ubcc0\ud658\ud558\ub294 normalizing flow $f_\\\\theta$ \ub2e8\uacc4\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n##### Text Encoder\\n\\n<img className={styles.figCenter} src={figTextEncoder} alt=\\"text_encoder\\" />\\n\\nText encoder\ub294 **transformer** \uae30\ubc18\uc73c\ub85c, absolute positional encoding \ub300\uc2e0 relative positional representation\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. Text encoder\uc5d0\uc11c \ucd9c\ub825\ub41c hidden representation $h_{text}$\uc740 linear projection\uc744 \uac70\uccd0 prior distribution\uc744 \uad6c\uc131\ud558\uae30 \uc704\ud55c mean $\\\\mu_\\\\theta$ \ubc0f variance $\\\\sigma_\\\\theta$\ub85c \ubcc0\ud658\ub429\ub2c8\ub2e4.\\n\\n##### Normalizing Flow\\n\\n<img className={styles.figCenter} src={figPosteriorEncoder} alt=\\"normalizing_flow\\" />\\n\\n\\nNormalizing flow\ub294 \uac00\uc5ed \uad6c\uc870\ub97c \uac00\uc9c4 **affine coupling layer**\uc758 stack\uc73c\ub85c, \uac01 \ub808\uc774\uc5b4\ub294 WaveNet residual block\uc73c\ub85c \uc774\ub904\uc838 \uc788\uc2b5\ub2c8\ub2e4. \uacc4\uc0b0\uc758 \ud3b8\ub9ac\ud568\uacfc \ub2e8\uc21c\uc131\uc744 \uc704\ud574 volume-preserving transformation \uc870\uac74\uc744 \uac78\uc5b4 Jacobian determinant\uc744 1\ub85c \uc720\uc9c0\ud558\ub294 \uc81c\ud55c\uc744 \uac78\uc5c8\uc2b5\ub2c8\ub2e4. \\n\\nTraining \uc911\uc5d0\ub294 latent variable $z$\uac00 \uc815\ubc29\ud5a5\uc73c\ub85c \ubcc0\ud658\ub418\uc5b4 $f_\\\\theta(z)$\uac00 \ub418\uace0, inference \uc911\uc5d0\ub294 \ubc18\ub300\ub85c $f_\\\\theta(z)$\uac00 \uc5ed\ubc29\ud5a5 \ubcc0\ud658\uc744 \uac70\uccd0 latent variable z\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4. \\n\\n##### Monotonic Alignment Search\\n\\n<img className={styles.figCenter} src={figPriorEncoder} alt=\\"mas\\" />\\n\\n\\nFlow\ub97c \uac70\uccd0 \ubcc0\ud658\ub41c latent variable $f_\\\\theta(z)$\uc640 text hidden representation\uc5d0\uc11c \uc0dd\uc131\ub41c mean \ubc0f variance \ubc30\uc5f4 \uc0ac\uc774\uc758 alignment\uc640 duration\uc774 MAS\ub97c \ud1b5\ud574 \uad6c\ud574\uc9d1\ub2c8\ub2e4. Text hidden representation\uc758 \uae38\uc774\ub97c latent variable\uc5d0 \ub9de\ucdb0\uc8fc\uae30 \uc704\ud574 duration\ub9cc\ud07c mean\uacfc variance\uc758 \uac01 \uc694\uc18c\ub97c \ubc18\ubcf5\ud574 \uc5f0\uc7a5\uc2dc\ud0a4\uace0, KL divergence \uacc4\uc0b0\uc5d0 \ud655\uc7a5\ub41c \uac12\uacfc latent variable\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc591\uce21\uc758 \ubd84\ud3ec\ub97c \ub9de\ucdb0\uc90d\ub2c8\ub2e4.\\n\\n#### Posterior Encoder\\n\\n<img className={styles.figCenter} src={figDecoder} alt=\\"decoder\\" />\\n\\n\\nPosterior encoder\ub294 \uc74c\uc131\uc758 linear spectrogram\uc5d0\uc11c latent variable\uc744 \ucd94\ucd9c\ud558\uba70, WaveGlow[[2]](#r2)\uc758 non-causal WaveNet residual block\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4. \uac01 \ube14\ub85d\uc740 gated activation unit\uc774 \ubd99\uc740 dilated convolution\uacfc skip connection\uc73c\ub85c \uc774\ub904\uc838 \uc788\uc2b5\ub2c8\ub2e4. \ub9c8\uc9c0\ub9c9 \ub2e8\uc758 linear projection\uc5d0\uc11c normal posterior distribution\uc758 mean\uacfc variance\ub97c \ucd9c\ub825\ud558\uace0, \uc774\uac78\ub85c \uc0d8\ud50c\ub9c1\ud55c $z$\uac00 latent variable\uc758 \uc5ed\ud560\uc744 \ud569\ub2c8\ub2e4.\\n\\n#### Decoder\\n\\nDecoder\ub294 latent varable\uc744 raw waveform\uc73c\ub85c \ubc14\uafd4\uc8fc\ub294 \uc5ed\ud560\uc744 \ud558\uba70, HiFi-GAN[[3]](#r3) V1 generator\ub97c \uae30\ubc18\uc73c\ub85c \ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub530\ub77c\uc11c transposed convolution\uac00 stack\ub418\uc5b4 \uc788\uc73c\uba70 \uac01 convolution \ub4a4\uc5d0\ub294 multi-receptive field fusion module (MRF)\uac00 \ubd99\uc5b4\uc788\uc5b4, \uac01\uac01 \ub2e4\ub978 receptive field size\ub97c \uac00\uc9c4 residual block\uc744 \uac70\uccd0 \ucd5c\ub300\ud55c \ub9ce\uc740 \uc218\uc758 \ud328\ud134\uc744 \uace0\ub824\ud558\uc5ec \uc74c\uc131\uc744 \ud569\uc131\ud569\ub2c8\ub2e4. \ub2e4\ub9cc \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\uc5d0\uc11c bias parameter\ub97c \uc81c\uac70\ud588\ub294\ub370, audio mean\uc740 \ubcf4\ud1b5 0\uc774\ubbc0\ub85c \uc774\ub294 \ubd88\uc548\uc815\ud55c gradient scaling\uc744 \uc720\ubc1c\ud558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\\n\\nTraining \uc911\uc5d0\ub294 decoder\uc5d0 latent variable \uc804\uccb4\uac00 \uc544\ub2c8\ub77c \ud2b9\uc815 \uae38\uc774\ub85c \ub79c\ub364\ud558\uac8c \uc798\ub9b0 \ubd80\ubd84\uc744 \ub123\uace0, \uc120\ud0dd\ub41c \ubd80\ubd84\uc5d0 \ub300\uc751\ub418\ub294 ground-truth\uc758 \uc77c\ubd80\ubd84\uc744 \uac00\uc838\ub2e4 \ud0c0\uac9f\uc73c\ub85c \uc0ac\uc6a9\ud558\uc5ec reconstruction loss\ub97c \uacc4\uc0b0\ud588\uc2b5\ub2c8\ub2e4. Inference \uc911\uc5d0\ub294 \uadf8\ub0e5 latent variable \uc804\uccb4\ub97c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\\n\\n#### Discriminator\\n\\nDiscriminator\ub3c4 decoder\uc640 \uac19\uc774 HiFi-GAN\uc758 multi-period discriminator\ub97c \uc4f0\ub294\ub370, \ud6a8\uc728\uc744 \uc704\ud574 \ub2e4\uc18c \uac04\uc18c\ud654\ub41c \ubc84\uc804\uc785\ub2c8\ub2e4. \uc774 \ubaa8\ub4c8\uc740 \uc5ec\ub7ec \uac1c\uc758 sub-discriminator\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc5b4, waveform\uc758 \uc11c\ub85c \ub2e4\ub978 \uc8fc\uae30\uc801 \ud328\ud134\uc744 \ud3ec\ucc29\ud569\ub2c8\ub2e4.\\n\\n#### Stochastic Duration Predictor\\n\\n<img className={styles.figCenter} src={figFigureFive} alt=\\"figure5\\" />\\n\\n\\nSDP\ub294 text hidden representation\uc73c\ub85c\ubd80\ud130 stochastic\ud558\uac8c duration\uc744 \uc608\uce21\ud558\ub294 \ubaa8\ub4c8\ub85c, \uc720\ub3d9\uc801\uc778 \ubc1c\ud654 \uc18d\ub3c4\ub77c\ub294 \uc778\uac04 \ubc1c\ud654\uc758 \ud2b9\uc9d5\uc744 \ubc18\uc601\ud558\uae30 \uc704\ud55c \uc811\uadfc\uc785\ub2c8\ub2e4. \uc55e\uc11c \uc124\uba85\ud55c \uac83\uacfc \uac19\uc774 flow \uae30\ubc18\uc758 \ubaa8\ub378\ub85c \uad6c\uc131\ub418\uba70 text hidden representation\uacfc duration\uc744 \ucc98\ub9ac\ud558\ub294 condition encoder, \uc774 \ub450 \uc870\uac74\uc744 \uc0ac\uc6a9\ud574 noise\uc5d0\uc11c random variable\uc744 \uc0dd\uc131\ud558\ub294 flow-based posterior encoder, \uadf8\ub9ac\uace0 noise\uc640 duration\uc744 \uac00\uc5ed\ubcc0\ud658\uc2dc\ud0a4\ub294 normalizing flow $g_\\\\theta$\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figFigureSix} alt=\\"figure6\\" />\\n\\n\\nConditional encoder\uc640 flow-based network \ub0b4\uc758 coupling layer\uc5d0\uc11c dilated and depth-separable convolutional (DDSConv) layer\uac00 \uc0ac\uc6a9\ub418\ub294\ub370, DDSConv\ub97c \uc0ac\uc6a9\ud55c \uc774\uc720\ub294 \ub113\uc740 receptive field\ub97c \uc720\uc9c0\ud558\uba74\uc11c parameter efficiency\ub97c \ub192\uc774\uae30 \uc704\ud568\uc785\ub2c8\ub2e4. Flow-based network\uc778 Posterior encoder\uc640 normalizing flow\uac00 \ubaa8\ub450 **neural spline flow**\ub97c \uc0ac\uc6a9\ud558\ub294\ub370, \uc77c\ubc18\uc801\uc73c\ub85c flow \uad6c\ud604\uc5d0 \uc4f0\uc774\ub294 affine coupling layer\ubcf4\ub2e4 \ud45c\ud604\ub825 \uce21\uba74\uc5d0\uc11c \ud6a8\uacfc\uac00 \uc88b\uc558\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figDurationPredictor} alt=\\"stop_gradient\\" />\\n\\n\\n\ub354\ud558\uc5ec SDP\uc5d0 stop gradient operator\ub97c \uc801\uc6a9\ud558\uc5ec \uc785\ub825 \uc870\uac74\uc744 \ud1b5\ud574 \ub2e4\ub978 \ubaa8\ub4c8\uc5d0 \uc601\ud5a5 \ubbf8\uce58\uc9c0 \ubabb\ud558\ub3c4\ub85d \uc81c\ud55c\ud569\ub2c8\ub2e4.\\n\\n\uc774\ub807\uac8c \uad6c\uc131\ub41c SDP\ub294 training \uc2dc\uc5d0\ub294 alignment\uc5d0\uc11c \uad6c\ud55c duration\uc744 \uac00\uc9c0\uace0 \ud559\uc2b5\ub418\uace0, inference \uc911\uc5d0\ub294 \ud14d\uc2a4\ud2b8\ub97c \ud1b5\ud574 \uc608\uce21\ud55c \uac12\uc744 duration\uc73c\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\\n\\n#### Speaker Embedding\\n\\n\uc5ec\ub7ec \ud654\uc790\uc758 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \ud559\uc2b5\ud560 \uacbd\uc6b0, \ubaa8\ub378\uc774 \uac01 \ud654\uc790\uc758 \ud2b9\uc9d5\uc744 \ubc18\uc601\ud560 \uc218 \uc788\ub3c4\ub85d \ud654\uc790\ubcc4\ub85c \uc784\ubca0\ub529\uc744 \ub9cc\ub4e4\uc5b4 \uc785\ub825\uc5d0 \ub354\ud574\uc8fc\ub294 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ud654\uc790\uc758 \uc815\ubcf4\uac00 \uc81c\uacf5\ub418\ub294 \ubaa8\ub4c8\uc740 prior encoder\uc758 normalizing flow, posterior encoder, decoder, SDP\uc774\uba70, text encoder\uc5d0\ub294 \uc81c\uacf5\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\\n\\n### Results\\n\\n#### Experiment Setup\\n\\n\uc800\uc790\ub4e4\uc740 VITS\uc758 \uc131\ub2a5\uc744 \ube44\uad50\ud560 \ub300\uc870\uad70\uc73c\ub85c autoregressive model\uc778 Tacotron 2\uc640 non-autoregressive model\uc778 Glow-TTS\ub97c \uc120\ud0dd\ud588\uc2b5\ub2c8\ub2e4. \ub458 \ub2e4 \ubcf4\ucf54\ub354\ub85c\ub294 HiFi-GAN\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \ub370\uc774\ud130\uc14b\uc740 \ub2e8\uc77c \ud654\uc790 \ud658\uacbd\uc5d0\uc120 LJSpeech\ub97c, \ub2e4\ud654\uc790 \ud658\uacbd\uc5d0\uc11c\ub294 VCTK\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\\n\\n\uc0dd\uc131\ub41c \ud569\uc131\uc74c \uc0d8\ud50c\ub4e4\uc740 \uc778\uac04 \ud3c9\uac00\uc790\uac00 \uc74c\uc131\uc744 \ub4e3\uace0 \uc74c\uc9c8\uc5d0 \ub300\ud574 1~5\uc810 \uc0ac\uc774\uc758 \uc810\uc218\ub97c \ub9e4\uae30\ub294 mean opinion score (MOS) \ubc29\uc2dd\uc73c\ub85c \ud3c9\uac00\ub429\ub2c8\ub2e4.\\n\\n#### Speech Quality\\n\\n\ubcf8 \uc139\uc158\uc5d0\uc11c\ub294 VITS\uac00 \ud569\uc131\ud55c \uc74c\uc131\uc774 \uc2e4\uc81c \uc74c\uc131\uc5d0 \uc5bc\ub9c8\ub098 \uadfc\uc811\ud55c\uc9c0, \uc778\uac04\uc774 \ub4e3\uae30\uc5d0 \uc5bc\ub9c8\ub098 \uc790\uc5f0\uc2a4\ub7ec\uc6b4\uc9c0\uc5d0 \ub300\ud574 \ub2e4\ub8f9\ub2c8\ub2e4.\\n\\n##### Single Speaker Setting\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figTableOne} alt=\\"table1\\" />\\n\\n\\n\uae30\uc874\uc758 2\ub2e8\uacc4 \ud569\uc131 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud55c \uacb0\uacfc, fine-tuning\ud55c \uacbd\uc6b0\ubcf4\ub2e4\ub3c4 VITS\uc758 \uc74c\uc9c8\uc774 \ub192\uc558\uace0 ground-truth\uc778 \uc6d0\ubcf8 \uc74c\uc131\uc5d0\ub3c4 \ub9e4\uc6b0 \uadfc\uc811\ud55c \uc810\uc218\ub97c \ubc1b\uc558\uc2b5\ub2c8\ub2e4. \ub354\ud558\uc5ec SDP\ub97c deterministic duration predictor (DDP)\ub85c \ub300\uccb4\ud574 \uc74c\uc131 \uae38\uc774\ub97c \uace0\uc815\uc2dc\ud0a8 \uacbd\uc6b0\ub3c4 \uc0c1\ub2f9\ud788 \ub192\uc740 \uc810\uc218\ub97c \uae30\ub85d\ud588\uc2b5\ub2c8\ub2e4. \uc774\ub97c \ud1b5\ud574 SDP\uac00 \uc74c\uc9c8 \ud5a5\uc0c1\uc5d0 \uae30\uc5ec\ud55c\ub2e4\ub294 \uc810\uacfc VITS\ub294 DDP\ub97c \uc0ac\uc6a9\ud574\ub3c4 \uae30\uc874 \ubaa8\ub378\ub4e4\uacfc \ube44\uad50\ud560 \ub9cc\ud55c \uc131\ub2a5\uc744 \ub0b8\ub2e4\ub294 \uc810\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n##### Ablation\\n\\n<img className={styles.figCenter} src={figTableTwo} alt=\\"table2\\" />\\n\\n\\nVITS\uc758 \uc5ec\ub7ec \uc694\uc18c\uac00 \uc5bc\ub9c8\ub098 \uc911\uc694\ud55c\uc9c0 \uadf8 \uc601\ud5a5\ub825\uc744 \ud655\uc778\ud558\uae30 \uc704\ud574, \uac01 \ubd80\ubd84\uc744 \uc81c\uc678\ud558\uace0 \ud3c9\uac00\ud558\ub294 ablation study\ub97c \uc9c4\ud589\ud588\uc2b5\ub2c8\ub2e4. \uadf8 \uacb0\uacfc, prior encoder\uc758 normalizing flow\ub97c \uc81c\uac70\ud55c \uacbd\uc6b0 \uc0c1\ub2f9\ud55c \uc131\ub2a5 \uc800\ud558\uac00 \uc788\uc5c8\uace0, posterior encoder\uc758 \uc785\ub825\uc740 linear-scale\uc774 \uc544\ub2cc mel-scale spectrogram\uc73c\ub85c \ubc14\uafe8\uc744 \ub54c\ub3c4 \uc57d\uac04\uc758 \uc131\ub2a5 \uc800\ud558\uac00 \uad00\ucc30\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n##### Multi-Speakers Setting\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figTableThree} alt=\\"table3\\" />\\n\\n\ud654\uc790\ubcc4\ub3c4 \uc784\ubca0\ub529\uc744 \ud560\ub2f9\ud574 \ub2e4\ud654\uc790 \ub370\uc774\ud130\ub85c \ud559\uc2b5\ud55c \uacbd\uc6b0, \ub9c8\ucc2c\uac00\uc9c0\ub85c VITS\uac00 \ud0c0 \ubaa8\ub378\ubcf4\ub2e4 \ub192\uc740 \uc74c\uc9c8\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4. VITS\uac00 \ub2e4\ud654\uc790 \ud658\uacbd\uc5d0\uc11c\ub3c4 \uc0ac\uc6a9 \uac00\ub2a5\ud568\uc744 \ud655\uc778\uc2dc\ucf1c\uc8fc\ub294 \uacb0\uacfc\uc785\ub2c8\ub2e4.\\n\\n#### Speech Variation\\n\\n\ubcf8 \uc139\uc158\uc5d0\uc11c\ub294 VITS\uac00 \uc5bc\ub9c8\ub098 \ub2e4\uc591\ud55c \ud2b9\uc131\uc758 \uc74c\uc131\uc744 \ud569\uc131\ud560 \uc218 \uc788\ub294\uc9c0, \ud569\uc131\ud55c \uc74c\uc131\uc774 \uc778\uac04 \ubc1c\ud654\uc758 \ud2b9\uc131\uc744 \uc5bc\ub9c8\ub098 \uc798 \ubc18\uc601\ud558\ub294\uc9c0\uc5d0 \ub300\ud574 \ub2e4\ub8f9\ub2c8\ub2e4.\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figFigureTwo} alt=\\"figure2\\" />\\n\\nFig. 2(a)\ub294 Tacotron 2, Glow-TTS, VITS\uac00 \\"How much variation is there?\\"\ub77c\ub294 \ubb38\uc7a5\uc5d0 \ub300\ud574 \uc0dd\uc131\ud55c \ud569\uc131\uc74c 100\uac1c\uc758 \uae38\uc774\uc5d0 \ub300\ud574 \ubd84\ud3ec\ub97c \ub098\ud0c0\ub0b8 \uac83\uc785\ub2c8\ub2e4. Glow-TTS\ub294 DDP\ub97c \uc0ac\uc6a9\ud574 \uace0\uc815\ub41c \uae38\uc774\uc758 \ubb38\uc7a5\ub9cc \ub0b4\ub193\ub294 \ubc18\uba74 VITS\ub294 Tacotron 2\uc640 \ube44\uc2b7\ud55c \ubd84\ud3ec\ub97c \ub530\ub974\ub294\ub370, \uac19\uc740 \ubb38\uc7a5\uc5d0 \ub300\ud574\uc11c\ub3c4 \ub2e4\uc591\ud55c \uae38\uc774\ub85c \ub2e4\ub974\uac8c \ubc1c\ud654\ud558\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\nFig. 2(b)\ub294 VITS\uac00 \uc0dd\uc131\ud55c 100\uac1c \ubc1c\ud654\uc758 \uae38\uc774\uc5d0 \ub300\ud574 \ubd84\ud3ec\ub97c \ud654\uc790\ubcc4\ub85c \ub098\ud0c0\ub0b8 \uac83\uc73c\ub85c, \uac01 \ud654\uc790\uc758 \ud2b9\uc131\uc5d0 \ub530\ub77c \ubc1c\ud654 \uae38\uc774\uac00 \ud06c\uac8c \ub2ec\ub77c\uc9c0\ubbc0\ub85c VITS\uac00 \ud654\uc790\uc758 \ud2b9\uc131\uc5d0 \uae30\ubc18\ud558\uc5ec \ubc1c\ud654 \uae38\uc774\ub97c \uc608\uce21\ud568\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figFigureThree} alt=\\"figure3\\" />\\n\\nFig. 3(a), (b), (c)\ub294 \uac01 \ubaa8\ub378\uc774 \uc0dd\uc131\ud55c \ubc1c\ud654 10\uac1c\uc758 F<sub>0</sub> contour\ub97c \ub098\ud0c0\ub0b8 \uac83\uc73c\ub85c VITS\uac00 \ud569\uc131\ud55c \uc74c\uc131\uc774 \ub2e4\uc591\ud55c \ub9ac\ub4ec\uacfc \ub192\ub0ae\uc774\ub97c \uac00\uc9d0\uc744 \ud655\uc778\ud560 \uc218 \uc788\uace0, Fig. 3d\uc5d0\uc11c\ub294 \ub354 \ub098\uc544\uac00 \uac01 \ud654\uc790\ubcc4\ub85c \ub2e4\ub978 \ubc1c\ud654\uc758 \ub9ac\ub4ec\uc744 \uc798 \ud45c\ud604\ud568\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n#### Synthesis Speed\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figTableFour} alt=\\"table4\\" />\\n\\n100\uac1c\uc758 \ubc1c\ud654\ub97c \ud569\uc131\ud560 \ub54c \uac01 \ubaa8\ub378\uc758 \ud3c9\uade0 \ud569\uc131 \uc18d\ub3c4\ub97c \ub098\ud0c0\ub0b8 \uac83\uc73c\ub85c, SDP\ub97c \ube7c\uba74 \ub354 \ube68\ub77c\uc9c0\uc9c0\ub9cc, SDP\ub97c \uc0ac\uc6a9\ud574\ub3c4 \uae30\uc874\uc758 Glow-TTS\ubcf4\ub2e4 \ube60\ub984\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uc800\uc790\ub4e4\uc740 \uc774\ub7ec\ud55c \uacb0\uacfc\uc5d0 \ub300\ud574 VITS\ub294 mel-spectrogram \uac19\uc740 \uace0\uc815\ub41c \ud615\uc2dd\uc758 \uc911\uac04 \ub2e8\uacc4 \uacb0\uacfc\ubb3c\uc744 \uc0dd\uc131\ud560 \ud544\uc694\uac00 \uc5c6\uc73c\ubbc0\ub85c \uc0d8\ud50c\ub9c1 \ud6a8\uc728\uc774 \ud06c\uac8c \uc0c1\uc2b9\ud558\uc600\ub2e4\uace0 \ubd84\uc11d\ud588\uc2b5\ub2c8\ub2e4.\\n\\n#### Voice Conversion\\n\\n\uc55e\uc11c \uc5b8\uae09\ud55c \ubc14\uc640 \uac19\uc774 \ub2e4\ud654\uc790 \ud658\uacbd\uc5d0\uc11c text encoder\uc5d0\ub294 \ud654\uc790 \uc784\ubca0\ub529\uc774 \uc785\ub825\ub418\uc9c0 \uc54a\uc73c\ubbc0\ub85c latent variable\uc740 \ud654\uc790\uc5d0 \ubb34\uad00\ud55c \uac12\uc774 \ub429\ub2c8\ub2e4. \ub530\ub77c\uc11c \uc774\ub7ec\ud55c speaker-independent representation\uc5d0 \ud654\uc790 \uc815\ubcf4\ub97c \uc870\uac74\uc73c\ub85c \uc81c\uacf5\ud558\uc5ec \uc74c\uc131\uc744 \ud569\uc131\ud55c\ub2e4\uba74, \ud2b9\uc815 \ud654\uc790\uc758 \ubc1c\ud654\ub97c \ub2e4\ub978 \ud654\uc790\uac00 \ubc1c\ud654\ud55c \uac83\ucc98\ub7fc \ubc14\uafb8\ub294 voice conversion (VC)\uc774 \uac00\ub2a5\ud569\ub2c8\ub2e4.\\n\\n\uc6d0\ub798 \ud654\uc790\uc778 s\uc5d0 \ub300\ud574 \ubc14\uafb8\uace0 \uc2f6\uc740 \ubc1c\ud654\uc758 linear spectrogram $x_{lin}$\uc744 \uac00\uc9c0\uace0 posterior encoder\uc5d0 \uc785\ub825\uc2dc\ud0a4\uace0, \uc5ec\uae30\uc11c \ub098\uc628 latent variable\uc744 normalizing flow\ub97c \uac70\uccd0 \ubcc0\ud658\uc2dc\ucf1c speaker-independent representation $e$\uc73c\ub85c \ubc14\uafc9\ub2c8\ub2e4.\\n\\n$$\\nz \\\\sim q_\\\\phi(z|x_{lin}, s) \\\\\\\\\\ne = f_\\\\theta(z|s)\\n$$\\n\\n\uc774\ub807\uac8c \ub9cc\ub4e4\uc5b4\uc9c4 independent representation\uc778 e\uc5d0 \ub300\ud574 \ub2e4\ub978 \uc0c8\ub85c\uc6b4 \ud654\uc790 $\\\\hat s$\uc744 \uc870\uac74\uc73c\ub85c \uac78\uace0 normalizing flow\uc758 \uc5ed\ubcc0\ud658\uacfc decoder\ub97c \uac70\uccd0 \uc74c\uc131\uc744 \ud569\uc131\ud558\uba74, \ub2e4\ub978 \uc870\uac74\ub4e4\uc740 \uc720\uc9c0\ud55c \ucc44 \ud654\uc790\uc758 \ud2b9\uc131\ub9cc \ub300\uccb4\ub41c \uc0c8 \uc74c\uc131 $\\\\hat y$\uc744 \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n$$\\n\\\\hat y = G\\\\big(f_\\\\theta^{-1}(e|\\\\hat s)|\\\\hat s\\\\big)\\n$$\\n\\n\uc989 \uae30\ubcf8 \uc74c\uc131\uc744 posterior encoder\uc640 normalizing flow\uc758 \uc815\ubcc0\ud658\uc744 \uac70\uccd0 \ud654\uc790 \uc815\ubcf4\ub97c \uc81c\uac70\ud558\uace0 \ub2e4\uc2dc normalizing flow\uc758 \uc5ed\ubcc0\ud658\uacfc decoder\ub97c \uac70\uccd0 \uc0c8\ub85c\uc6b4 \ud654\uc790 \uc815\ubcf4\ub97c \ub123\uc5b4 \ub300\uccb4\ud574\uc8fc\ub294 \uacfc\uc815\uc73c\ub85c \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. Independent representation\uc744 \ud559\uc2b5\ud558\uc5ec VC\uc5d0 \uc0ac\uc6a9\ud558\ub294 \ubc29\uc2dd\uc740 \uc774\uc804\uc5d0 Glow-TTS\uc5d0\uc11c \uc81c\uc548\ub41c \ubc14 \uc788\uc2b5\ub2c8\ub2e4. \ub2e4\ub9cc VITS\ub294 1\ub2e8\uacc4 \ud569\uc131\uc774 \uac00\ub2a5\ud558\ubbc0\ub85c mel-spectrogram\uc774 \uc544\ub2c8\ub77c raw waveform\uc758 \ud615\ud0dc\ub85c \ubcc0\ud658\uc2dc\ud0a8\ub2e4\ub294 \uc810\uc774 \ub2e4\ub985\ub2c8\ub2e4. \ud55c \uc74c\uc131\uc5d0 \ub300\ud574 \uc5ec\ub7ec \uc74c\uc131\uc73c\ub85c \ubcc0\ud658\uc2dc\ud0a8 \uacb0\uacfc\ub294 \uc544\ub798\uc640 \uac19\uc740\ub370, \uc804\ubc18\uc801\uc73c\ub85c \uc74c\uc131\uc758 \ub192\ub0ae\uc774 \ucd94\uc774\uac00 \uc720\uc9c0\ub428\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\n<img className={clsx(styles.figCenter, styles.small)} src={figFigureSeven} alt=\\"figure7\\" />\\n\\n### Conclusion\\n\\n\uc774\ub807\uac8c end-to-end TTS\uc778 Variational Inference with adversarial learning for end-to-end Text-to-Speech, VITS\uc5d0 \ub300\ud558\uc5ec \uc791\ub3d9 \uc6d0\ub9ac\uc640 \uad6c\uc870 \uadf8\ub9ac\uace0 \uc131\ub2a5\uc5d0 \ub300\ud574 \uc0b4\ud3b4\ubcf4\uc558\uc2b5\ub2c8\ub2e4. VITS\ub294 \uc0ac\uc2e4 \uc0c1\ub2f9\ud788 \ubcf5\uc7a1\ud55c \ubaa8\ub378\uc785\ub2c8\ub2e4. VAE, normalizing flow, GAN\uacfc \uac19\uc740 \uc0dd\uc131 \ubaa8\ub378\uc758 \uc694\uc18c\ub97c \ubaa8\ub450 \ud3ec\ud568\ud558\uace0 \uc788\uace0, Glow-TTS\ub098 HiFi-GAN \uac19\uc774 \ubaa8\ub378\uc758 \uae30\ubc18\uc774 \ub418\ub294 \uae30\uc874 \uc5f0\uad6c\uc5d0\uc11c \ucc28\uc6a9\ud574\uc628 \ubd80\ubd84\ub3c4 \ub9ce\uc2b5\ub2c8\ub2e4. \uc5ec\uae30\uae4c\uc9c0 \uc77d\uc73c\uc2dc\ub290\ub77c \uc218\uace0 \ub9ce\uc73c\uc168\uc2b5\ub2c8\ub2e4.\\n\\nVITS \uc5f0\uad6c\uac00 \uac00\uc9c4 \uac00\uc7a5 \ud070 \uc758\uc758\ub294 1\ub2e8\uacc4 \ud569\uc131 \ubaa8\ub378\ub85c\uc368\ub294 \ucd5c\ucd08\ub85c \uc5b4\ucfe0\uc2a4\ud2f1 \ubaa8\ub378\uacfc \ubcf4\ucf54\ub354\ub85c \uad6c\uc131\ub41c 2\ub2e8\uacc4 \ud569\uc131\uacfc \uacac\uc904\ub9cc\ud55c \uc131\ub2a5\uc758 end-to-end TTS\ub97c \uc81c\uc548\ud588\ub2e4\ub294 \uc810\uc785\ub2c8\ub2e4. \uc774\ub85c \uc778\ud574 \ud559\uc2b5 \uacfc\uc815\uc774 \uac04\ub2e8\ud574\uc84c\uace0 \uc18d\ub3c4 \ub610\ud55c \ube68\ub77c\uc84c\uc2b5\ub2c8\ub2e4. \ub354\ud558\uc5ec \uc678\ubd80 aligner\ub97c \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc544 \ud559\uc2b5 \uacfc\uc815\uc774 \ub354\uc6b1 \ub2e8\uc21c\ud654\ub418\uc5c8\uace0, duration predictor\ub97c \ud1b5\ud574 \uc74c\uc131 \ubc1c\ud654 \uc18d\ub3c4\ub97c \uc870\uc808\ud560 \uc218 \uc788\ub2e4\ub294 \uc810\ub3c4 \uc791\uc9c0 \uc54a\uc740 \uc774\uc810\uc785\ub2c8\ub2e4. TTS \uc5f0\uad6c\uc758 \ubc29\ud5a5\uc740 \ub2e8\uc21c \uc74c\uc9c8 \ud5a5\uc0c1\ubfd0\ub9cc \uc544\ub2c8\ub77c \uc18d\ub3c4 \ud5a5\uc0c1, \ub9ac\ub4ec \uc870\uc808, \uc18c\ub7c9\uc758 \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc801\uc751, \ub2e4\ud654\uc790 \uc124\uc815, \uad6c\uc870 \uac1c\uc120(1\ub2e8\uacc4 \ud569\uc131 \ubc0f \ubaa8\ub378 \uaddc\ubaa8 \uc808\uac10) \ub4f1 \ub2e4\uc591\ud55c \ubc29\uba74\uc5d0\uc11c \uc774\ub8e8\uc5b4\uc9c0\uace0 \uc788\ub294\ub370, VITS\ub294 \uc5ec\ub7ec \uce21\uba74\uc5d0\uc11c \uc131\uacfc\ub97c \uc774\ub8e8\uc5c8\ub2e4\ub294 \uc810\uc5d0\uc11c \uad04\ubaa9\ud560 \ub9cc\ud55c \uc5f0\uad6c\ub77c\uace0 \uc0dd\uac01\ud569\ub2c8\ub2e4. \ubaa8\ub378\ub9c1 \ucc28\uc6d0\uc5d0\uc11c \ubcf4\uba74, 1\ub2e8\uacc4 \ud569\uc131\uc774 \uac00\ub2a5\ud55c \ub2e8\uc77c\ud55c \ubaa8\ub378 \ub0b4\uc5d0\uc11c latent variable\uc744 \ubaa8\ub378\ub9c1\ud568\uc73c\ub85c\uc368 voice conversion\uacfc \uac19\uc740 \ubd80\uac00 \uae30\ub2a5 \ub610\ud55c \ucd94\uac00\ud560 \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n\ubcf5\uc7a1\ub2e4\ub2e8\ud55c \ubaa8\ub378\uc778 VITS\uc758 \ud765\ubbf8\ub85c\uc6b4 \uba74\ubaa8\ub97c \ubcf4\uc5ec\ub4dc\ub9ac\uace0 \uc2f6\uc5b4 \ubd80\uc871\ud558\ub098\ub9c8 \uccab \ub9ac\ubdf0\ub97c \uc9c4\ud589\ud574\ubcf4\uc558\uc2b5\ub2c8\ub2e4. \ub2e4\uc74c \ub9ac\ubdf0\ub3c4 \uae30\ub300\ud574\uc8fc\uc138\uc694!\\n\\n### References\\n\\n<a name=\\"r1\\"></a>\\n\\n1. Kim, Jaehyeon, et al. \\"Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search\\" *arXiv preprint arXiv:2005.11129* (2020). [[arxiv]](https://arxiv.org/abs/2005.11129)\\n\\n<a name=\\"r2\\"></a>\\n\\n2. Prenger, Ryan, Rafael Valle, and Bryan Catanzaro. \\"WaveGlow: A Flow-based Generative Network for Speech Synthesis.\\" *ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 2019. [[arxiv]](https://arxiv.org/abs/1811.00002)\\n\\n<a name=\\"r3\\"></a>\\n\\n3. Kong, Jungil, Jaehyeon Kim, and Jaekyoung Bae. \\"HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis.\\" *arXiv preprint arXiv:2010.05646* (2020). [[arxiv]](https://arxiv.org/abs/2010.05646)\\n\\n<a name=\\"r4\\"></a>\\n\\n4. Lilian Weng, Flow-based Deep Generative Models. [[blog]](https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html)\\n\\n<a name=\\"r5\\"></a>\\n\\n5. Ren, Yi, et al. \\"Fastspeech 2: Fast and high-quality end-to-end text to speech.\\" *arXiv preprint arXiv:2006.04558* (2020). [[arxiv]](https://arxiv.org/abs/2006.04558)\\n\\n<a name=\\"r6\\"></a>\\n\\n6. Donahue, Jeff, et al. \\"End-to-end adversarial text-to-speech.\\" *arXiv preprint arXiv:2006.03575* (2020). [[arxiv]](https://arxiv.org/abs/2006.03575)"},{"id":"acon","metadata":{"permalink":"/blog/acon","source":"@site/blog/2021-07-19-paper-review-acon/index.mdx","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2021-07-19T00:00:00.000Z","formattedDate":"July 19, 2021","tags":[{"label":"paper-review","permalink":"/blog/tags/paper-review"}],"readingTime":14.48,"truncated":false,"authors":[{"name":"Hyoung-Kyu Song","title":"AI Scientist (Vision, Head)","url":"https://github.com/deepkyu","imageURL":"https://github.com/deepkyu.png","key":"hkyu"}],"frontMatter":{"slug":"acon","title":"Activate or Not: Learning Customized Activation","description":"Swish\uc640 ReLU\uc640\uc758 \uad00\uacc4\ub97c \uc124\uba85\ud558\uace0, \ud559\uc2b5\uc774 \uac00\ub2a5\ud55c \ud65c\uc131\ud568\uc218\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/mindslab_default.png","authors":["hkyu"],"tags":["paper-review"]},"prevItem":{"title":"VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech","permalink":"/blog/vits"},"nextItem":{"title":"NU-Wave(Interspeech):","permalink":"/blog/nu-wave"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figSwish from \'./image/figure1_swish.png\';\\nimport figAcon from \'./image/figure4_acon.png\';\\nimport figFamily from \'./image/figure5_maxout_family_acon_family.png\';\\nimport figExample from \'./image/figure6_acon_example.png\';\\nimport figProperty from \'./image/figure7_acon_property.png\';\\nimport figDistribution from \'./image/figure8_meta_acon_distribution.png\';\\nimport figResultFour from \'./image/figure12_result4.png\';\\nimport figResultFive from \'./image/figure13_result5.png\';\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2009.04759-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2009.04759)\\n[![githubio](https://img.shields.io/static/v1?message=Official%20Repo&logo=Github&labelColor=grey&color=blue&logoColor=white&label=%20&style=flat-square)](https://github.com/nmaac/acon)\\n\\n> Ma, Ningning, et al. \\"Activate or Not: Learning Customized Activation.\\"  \\nProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.\\n\\n\\n## \uba3c\uc800 \uc54c\uba74 \uc88b\uc740 \uac83\ub4e4\\n\\n### Swish Activation Function [<sup>[1]</sup>](#r1)\\n\\n$$\\n\\\\operatorname{swish}(x):=x \\\\times \\\\sigma(\\\\beta x)=\\\\frac{x}{1+e^{-\\\\beta x}}\\n$$\\n\\n<img className={styles.figCenter} src={figSwish} alt=\\"figure1_swish\\" />\\n\\n- Linear Function\uacfc ReLU \uc0ac\uc774\uc5d0\uc11c\uc758 non-linearly interpolated activation\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n    - $\u03b2 = 0$ \uc77c \uacbd\uc6b0, Linear function $f(x) = x/2$ \ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - \ubc18\ub300\ub85c $\u03b2 \u2192 \u221e$\uc77c \uacbd\uc6b0, Sigmoid\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84\uc774 0-1 activation\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub418\uc5b4, Swish\uac00 ReLU\ucc98\ub7fc \uc791\uc6a9\ud558\uac8c \ub429\ub2c8\ub2e4.\\n    - $\u03b2 = 1$\uc77c \uacbd\uc6b0, \uac15\ud654\ud559\uc2b5\uc5d0\uc11c \uc0ac\uc6a9\ub418\ub294 Sigmoid-weighted Linear Unit (SiL) function\ucc98\ub7fc \uc791\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n    - $\u03b2$\ub294 \uc704\uc5d0\uc11c \ubcf4\uc2e0 \uac83\ucc98\ub7fc \uc5b4\ub5a4 \uc0c1\uc218\uc77c \uc218\ub3c4 \uc788\uace0, \ubaa8\ub378\uc5d0 \ub530\ub77c\uc11c\ub294 \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\uac00 \ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ube0c\ub808\uc778\ud300 AI Scientist\ubd84\ub4e4\uc774 \uc790\uc8fc \uc0ac\uc6a9\ud558\uc2dc\ub294 Activation Function\uc774\uae30\ub3c4 \ud558\uc8e0 \ud83d\ude42\\n- Generative Model\uc5d0\uc11c\ub3c4 ReLU \ub300\uc2e0 \uc0ac\uc6a9\ud558\ub294 \uacbd\uc6b0\uac00 \ub9ce\uc774 \uc788\uc2b5\ub2c8\ub2e4.\\n- \ucd5c\uadfc\uc5d0\ub294 Implicit Representation Network \uc0c1\uc5d0\uc11c\ub3c4 Swish\uac00 \ub2e4\uc2dc\uae08 \uc8fc\ubaa9\uc744 \ubc1b\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n    - SIREN\uc5d0\uc11c \uc5b8\uae09\ud558\ub294 periodic function activation (Sine \ud568\uc218 \ub4f1) \ubcf4\ub2e4 Swish\uac00 \ub354 \ub098\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\ub294 Task\uac00 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### Sigmoid\\n\\n$$\\n\\\\sigma(x)=\\\\frac{1}{1+e^{-x}}\\n$$\\n\\n- \uc5ec\uae30\uc11c\ub294 Activation\uc73c\ub85c \uc2dc\uc0ac\ud558\uae30\ubcf4\ub2e4\ub294 \uc218\uc2dd \ud45c\ud604 \uc2dc\uc5d0 sigmoid\ub85c \ubb36\uc5b4 \ud45c\ud604\ud558\uae30 \uc704\ud574 \ud655\uc778\ud558\uace0 \ub118\uc5b4\uac00\uc57c \ud569\ub2c8\ub2e4.\\n- Swish\uac00 \uacb0\uad6d **input \uac12\uc5d0 sigmoid\ud55c \uac83\uacfc input \uac12\uc758 \uacf1\uc73c\ub85c \ud45c\ud604\ub41c\ub2e4**(\u03b2 \ub97c \uacf1\ud558\uae30\ub294 \ud558\uaca0\uc9c0\ub9cc)\ub294 \uac83\ub3c4 \ub2e4\uc2dc \ud55c\ubc88 \ub9ac\ub9c8\uc778\ub4dc\ud558\uace0 \ub118\uc5b4\uac11\uc2dc\ub2e4 \ud83d\ude0e\\n\\n### Maxout Family\\n\\n- ReLU\uc640 \uac19\uc740 Activation Function\uc758 \ucd9c\ubc1c\uc810\uc5d0 \ud574\ub2f9\ud558\ub294 \uac1c\ub150 \uc911 \ud558\ub098\uc785\ub2c8\ub2e4.\\n- Goodfellow\uc640 Bengio\uc758 \ub17c\ubb38[<sup>[2]</sup>](#r2) \uc73c\ub85c, Maximum\uc744 \uc120\ud0dd\ud558\ub294 \uac83\uc73c\ub85c\ub3c4 \uc784\uc758\uc758 Convex Function\uc5d0 \ub300\ud574 \ub450\ub8e8 \uadfc\uc0ac\ud560 \uc218 \uc788\uc74c\uc744 \uc2dc\uc0ac\ud569\ub2c8\ub2e4.\\n\\n## Main Idea\\n\\n### ACON(**Ac**tivationOrNot) Activation Function\\n\\n$$\\n\\\\operatorname{ACON-C}(x) := \\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n<img className={styles.figCenter} src={figAcon} alt=\\"figure4_acon\\" />\\n\\n*ACON Activation\uc744 \uc0ac\uc6a9\ud558\uc600\uc744 \ub54c, \ud2b9\uc815 Layer\uc758 Activation\uc774 Linear \ud558\uac8c pass\uc218\ub3c4, Non-linear Activation\uc73c\ub85c \ud65c\uc131\ub420 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4*\\n\\n\uc800\uc790\ub294 ACON(\ub354 \ub098\uc544\uac00\uc11c Meta-ACON)\uc774\ub77c\uace0 \ud558\ub294 Activation Function\uc744 \uc81c\uc548\ud569\ub2c8\ub2e4. ACON activation\uc740 trainable\ud55c activation\uc73c\ub85c Neuron\uc744 Activation\ud560 \uc9c0 \uc548 \ud560\uc9c0\ub97c \uac01 Layer\uc758 \ud2b9\uc131\uc5d0 \ub9de\uac8c \uacb0\uc815\ud569\ub2c8\ub2e4.\\n\\n\\n\\n### \uc5b4\ub5bb\uac8c \ud574\uc11c ACON \uc2dd\uc744 \ub3c4\ucd9c\ud560 \uc218 \uc788\uac8c \ub418\uc5c8\uc744\uae4c\uc694?\\n\\n\uba3c\uc800 Maximum Function $max(x1, ..., xn)$ \uc5d0 \ub300\ud574 smooth\ub41c \ubc84\uc804\uc744 \ubcf4\uc544\uc57c \ud569\ub2c8\ub2e4. Maximum\uc744 \uad6c\ud55c\ub2e4\ub294 \uac83\uc740 \uc77c\ubc18\uc801\uc73c\ub85c differentiable\ud558\uc9c0 \uc54a\uc9c0\ub9cc, \uc774\ub97c smooth\ud55c \ud568\uc218\ub294 differentiable\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf4\ud1b5 \uc544\ub798\uc758 \uc2dd\ucc98\ub7fc \ud45c\ud604\ud569\ub2c8\ub2e4.\\n\\n$$\\nS_{\\\\beta}\\\\left(x_{1}, \\\\ldots, x_{n}\\\\right)=\\\\frac{\\\\sum_{i=1}^{n} x_{i} e^{\\\\beta x_{i}}}{\\\\sum_{i=1}^{n} e^{\\\\beta x_{i}}}\\n$$\\n\\n\uc774 \ub54c, $\u03b2$ \ub294 switching factor\ub85c\uc11c\\n\\n- $\u03b2 \u2192 \u221e$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 Maximum Function \uc758 \uc5ed\ud560\uc744 \ud558\uac8c \ub429\ub2c8\ub2e4.\\n- $\u03b2 \u2192 0$\uc77c \ub54c, \uc8fc\uc5b4\uc9c4 \ud568\uc218\ub294 \uc0b0\uc220\ud3c9\uade0(Arithmetic Mean, \uc6b0\ub9ac\uac00 \uc77c\ubc18\uc801\uc73c\ub85c \uc544\ub294 \ud3c9\uade0)\ucc98\ub7fc \uc791\ub3d9\ud569\ub2c8\ub2e4.\\n\\n\uc77c\ubc18\uc801\uc73c\ub85c Neural Network\uc5d0\uc11c \ub9ce\uc774 \uc0ac\uc6a9\ud558\ub294 Activation Function\ub4e4\uc740 \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c Maxout\uc5d0 \uc900\ud558\ub294 \uac83\uc73c\ub85c \ud45c\ud604\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n$$\\nmax( \u03b7a(x), \u03b7b(x))\\n$$\\n\\n\uc608\ub97c \ub4e4\uc5b4, ReLU\ub294 $\u03b7a(x)=x$, $\u03b7b(x)=0$\uc778 \uac83\uc73c\ub85c \uc0dd\uac01\ud558\uba74, \uc774 \uc5ed\uc2dc Maxout Family\uc5d0 \uc18d\ud55c\ub2e4\uace0 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.  \\nLeaky ReLU, FReLU \ub4f1\ub3c4 \uc774\ub7ec\ud55c \ubc29\uc2dd\uc73c\ub85c \uc811\uadfc\ud574\ubcf4\uba74 \ubaa8\ub450 Maxout Family\uc5d0 \uc18d\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\n\ubcf8 \ub17c\ubb38\uc5d0\uc11c\uc758 \ubaa9\ud45c\ub294 Maximum Function\uacfc \uc704 Maxout Family\ub97c \ud568\uaed8 \uc0ac\uc6a9\ud558\uc5ec, Maxout Family \uac01\uac01\uc5d0 \uc0c1\uc751\ud558\ub294 activation function\ub4e4\uc744 smooth\ud55c \ud568\uc218\ub85c \uadfc\uc0ac\ud574\ubcf4\ub294 \uac83\uc785\ub2c8\ub2e4. \uc704\uc5d0\uc11c Smooth\ub41c Maximum Function\uc744 \uc791\uc131\ud560 \ub54c, \uc785\ub825 \uac12\uc758 \uac1c\uc218\ub97c 2\uac1c\ub85c\ub9cc \ud55c\uc815\ud574\uc11c \uc2dd\uc744 \uc804\uac1c\ud558\uba74 \ub531\uc774\uaca0\ub124\uc694!\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{a}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{e^{\\\\beta \\\\eta_{b}(x)}}{e^{\\\\beta \\\\eta_{a}(x)}+e^{\\\\beta \\\\eta_{b}(x)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)}}+\\\\eta_{b}(x) \\\\cdot \\\\frac{1}{1+e^{-\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)}} \\\\\\\\=\\\\eta_{a}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{b}(x)-\\\\eta_{a}(x)\\\\right)\\\\right] \\\\\\\\=\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc989, Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74\\n\\n$$\\n\\\\begin{array}{l}S_{\\\\beta}\\\\left(\\\\eta_{a}(x), \\\\eta_{b}(x)\\\\right) =\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right) \\\\cdot \\\\sigma\\\\left[\\\\beta\\\\left(\\\\eta_{a}(x)-\\\\eta_{b}(x)\\\\right)\\\\right]+\\\\eta_{b}(x)\\\\end{array}\\n$$\\n\\n\uc774 \ub420 \uac83\uc785\ub2c8\ub2e4!\\n\\n### ACON \uc548\uc5d0 Swish \uc788\ub2e4 \ud83d\ude09\\n\\n\uc790, \uadf8\ub7fc \uc544\uae4c \uc5b8\uae09\ud55c Maxout Family\uc5d0 \uc900\ud558\uc5ec \uc5ec\ub7ec Activation\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uc5c8\ub2e4\uba74, \uac01\uac01\uc744 Smooth\ub41c Maximum Function\uc5d0 \ud574\ub2f9\ud558\ub3c4\ub85d \uc804\uac1c\ub97c \ud574\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figFamily} alt=\\"figure5_maxout_family_acon_family\\" />\\n\\n\\nReLU\uc758 smooth\ub418\ub294 \ubc84\uc804\uc774 Swish\ub77c\ub294 \uac74 \uc9c1\uad00\uc73c\ub85c\ub3c4 \ub9ce\uc774\ub4e4 \uc774\ud574\ud558\uace0 \uc788\uc5c8\ub294\ub370\uc694. \uc774 \uc2dd\uc5d0\uc11c \ubcf4\ub4ef\uc774 Smooth\ub41c Maximum Function\uc5d0 \ub300\uc785\ud574\uc11c \uc804\uac1c\ud574\ubcf4\uba74, \ubc14\ub85c Swish \uc2dd\uc774 \ub098\uc624\uac8c \ub429\ub2c8\ub2e4. \uc800\uc790\ub294 \uc774\ub97c \ud1b5\ud574 Swish\uac00 ReLU\uc758 Smooth Approximation\uc784\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub41c\ub2e4\uace0 \ub9d0\ud569\ub2c8\ub2e4.\\n\\n\ub610\ud55c, Leaky ReLU\uc758 \uc0c1\uc704 \ud638\ud658\uc774\uae30\ub3c4 \ud55c PReLU(Parametric ReLU, \uc74c\uc218 \ubd80\ubd84\uc758 \uae30\uc6b8\uae30 \uac12\uc774 learnable\ud568)\ub3c4 \uc0b4\ud3b4\ubcf4\uba74, \uc5ed\uc2dc Smooth\ub418\ub294 \ud568\uc218\ub85c \ub300\uc751\ud558\ub294 \uac83\uc744 \ucc3e\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. (\uc544 \uc774 \ub54c PReLU\uc5d0 \ub300\uc751\ud558\ub824\uba74, p < 1 \uc778 \uac78\ub85c \ud55c\uc815\ud574\uc11c \uc0dd\uac01\ud574\ubd10\uc694 \uc6b0\ub9ac \ud83d\ude42)\\n\\n\uadf8\ub9ac\uace0 \ub9c8\uc9c0\ub9c9\uc73c\ub85c \uac01 \uc120\ud615 \ud568\uc218\uc758 \uac00\uc911\uce58(Cartesian \uc88c\ud45c\uacc4 \uc0c1\uc740 \uae30\uc6b8\uae30\uaca0\uc8e0?)\uac00 p1, p2\ub85c \ud45c\ud604\ud558\uba74 \uac00\uc7a5 \uc77c\ubc18\ud654\ub41c \ud45c\ud604\uc77c\ud150\ub370\uc694 (p1 \u2260 p2). \uc5ec\uae30\uc5d0 \uac01\uac01 Maxout Family, ACON Family\ub97c \ub300\uc751\ud574\ubcf4\uba74 \uc77c\ubc18\ud654\ub41c \uc2dd\uc774 \ub098\uc635\ub2c8\ub2e4. \uc704\uc5d0\uc11c \uc5b8\uae09\ud55c\\n\\n$$\\n\\\\operatorname{ACON-C}(x):=\\\\left(p_{1}-p_{2}\\\\right) x \\\\cdot \\\\sigma\\\\left(\\\\beta\\\\left(p_{1}-p_{2}\\\\right) x\\\\right)+p_{2} x\\n$$\\n\\n\uc774 \uc774\ub807\uac8c \uc720\ub3c4\ub418\uac8c \ub418\ub294 \uac83\uc774\uc8e0!\\n\\n\uc0ac\uc2e4 Maxout Family\uc5d0\uc11c \ube44\uad50\ud558\uac8c \ub418\ub294 \ub450 \ud568\uc218\ub294 \uc704\uc5d0\uc11c\ucc98\ub7fc \ub2e8\uc21c\ud558\uc9c0 \uc54a\uc744 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4. \uac01\uac01\uc774 \ubcf5\uc7a1\ud574\uc9c8\uc218\ub85d \ub354 \ub9ce\uc740 \ud568\uc218\ub4e4\uc744 \ud45c\ud604\ud560 \uc218 \uc788\uac8c \ub418\uc8e0. \ub2e4\ub9cc, \uc800\uc790\ub294 \uc774 Maxout Family\ub97c ACON Family\ub85c \ubc14\uafe8\uc744 \ub54c(\uc989, Smooth Maximum Function\uc73c\ub85c \uadfc\uc0ac\ud588\uc744 \ub54c)\uc758 \ud6a8\uacfc\ub97c \ubcf4\ub294 \ub370\uc5d0 \uc5f0\uad6c\ub97c \uc9d1\uc911\ud588\ub2e4\uace0 \ud574\uc694. \ud5a5\ud6c4 \uc5f0\uad6c\uc5d0\uc11c \ub354 \uc804\uccb4\uc801\uc778 Scope\uc5d0\uc11c\uc758 \ube44\uad50\uac00 \uc788\uae30\ub97c \uae30\ub300\ud574\ubd05\ub2c8\ub2e4!\\n\\n### ACON\uc758 \ud2b9\uc131\\n\\nACON\uc5d0 \ud2b9\uc815 \uac12\uc744 \ub300\uc785\ud574\uc11c \ud55c\ubc88 \uc0b4\ud3b4\ubcfc\uae4c\uc694?\\n\\n<img className={styles.figCenter} src={figExample} alt=\\"figure6_acon_example\\" />\\n\\np1=1.2, p2=-0.8\uc77c \ub54c ACON-C\uc5d0 \ub300\uc751\ud558\ub294 \uc2dd\uc744 \uc5ec\ub7ec \u03b2\uac12\uc5d0 \ub300\ud574 \ud45c\ud604\ud55c graph\uc785\ub2c8\ub2e4.\\n\\n- \u03b2\uac00 \ud074 \ub54c\ub294, maximum function\ucc98\ub7fc \ubc18\uc751\ud558\uc5ec \ube44\uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\uac8c \ub418\uace0\uc694.\\n- \u03b2\uac00 0\uc5d0 \uac00\uae4c\uc6b8 \ub54c\ub294 mean function\uc5d0 \uadfc\uc0ac\ub418\uc5b4 \uc120\ud615\uc801\uc778 \ud2b9\uc131\uc744 \uac16\ub124\uc694.\\n\\n<img className={styles.figCenter} src={figProperty} alt=\\"figure7_acon_property\\" />\\n\\nACON Activation\uacfc \uc774\uc5d0 \ub300\ud55c \ub3c4\ud568\uc218(derivative)\ub97c \ubcf4\uc5ec\uc8fc\ub294 \uadf8\ub9bc\uc785\ub2c8\ub2e4.\\n\\n- \uc67c\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c \uc5b4\ub5bb\uac8c Activation function\uc774 \ub2ec\ub77c\uc9c0\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n- \uac00\uc6b4\ub370: \u03b2 \uac12\uc774 \ub2ec\ub77c\uc9d0\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \ubcc0\ud654\ud558\uac8c \ub418\uace0 \uc774\ub97c \ud1b5\ud574 \u03b2\uc758 \uc5ed\ud560\uc744 \uc9d0\uc791\ud574\ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n- \uc624\ub978\ucabd: \u03b2\uac00 fixed \ub418\uc5b4 \uc788\uc744 \ub54c, p1, p2 \uacc4\uc218\uc5d0 \ub530\ub77c ACON\uc758 \ub3c4\ud568\uc218\uac00 \uc5b4\ub5bb\uac8c \ubcc0\ud558\ub294 \uc9c0\ub97c \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\nACON\uc758 \ub3c4\ud568\uc218\ub97c \ubcf4\uba74\uc11c \uc544\ub798\uc640 \uac19\uc740 \uc0ac\uc2e4\uc744 \uc54c \uc218 \uc788\uc5b4\uc694.\\n\\n- p1, p2\ub294 \uac01\uac01 Upper/Lower Bound\uc5d0 \ud574\ub2f9\ud558\ub294 \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n- \u03b2 \uac12\uc740 \ub3c4\ud568\uc218 \uc0c1\uc5d0\uc11c p1, p2\uc5d0 \uc758\ud574 \uacb0\uc815\ub41c Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube60\ub974\uac8c \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub429\ub2c8\ub2e4.\\n\\nSwish\uc5d0\uc11c\ub294 Hyperparameter \u03b2\ub9cc\uc774 Upper/Lower Bound\uc5d0 \uc5bc\ub9c8\ub098 \ube68\ub9ac \uadfc\uc0ac\ub418\ub294 \uc9c0\ub97c \uacb0\uc815\ud558\uac8c \ub418\ub294\ub370\uc694. ACON\uc5d0\uc11c\ub294 p1, p2\uac00 \uc774 Bound \uac12\uc744 \uacb0\uc815\ud558\uac8c \ub418\uace0, \uc774 \uc5ed\uc2dc learnable\ud574\uc9c8 \uc218 \uc788\ub2e4\ub294 \ud2b9\uc131\uc774 \uc788\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c boundary\uac00 learnable\ud558\ub2e4\ub294 \uac83\uc740 optimization\uc744 \uc27d\uac8c \ud558\ub294 \ub370\uc5d0 \ud544\uc218\uc801\uc778 \ud2b9\uc131\uc774\uace0, \uc800\uc790\ub294 \uc774 \uc7a5\uc810\uc744 \uc2e4\ud5d8 \uacb0\uacfc\ub97c \ud1b5\ud574 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n### \ud559\uc2b5\uc5d0 \ubaa8\ub450 \ub9e1\uaca8\ubc84\ub9ac\uc790! Meta-ACON\\n\\nMeta-ACON\uc740 \u03b2 \uc790\uccb4\ub97c Learnable\ud55c parameter\ub85c \ub194\ub450\ub294 \uac83\uc5d0\uc11c \ub354 \ub098\uc544\uac00, Layer\uc5d0 \uc785\ub825\ub418\ub294 feature map\uc73c\ub85c\ubd80\ud130 FC Layers\ub97c \uac70\uccd0 estimation \ub418\ub3c4\ub85d \ub9cc\ub4e0 \uac83\uc785\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figDistribution} alt=\\"figure8_meta_acon_distribution\\" />\\n\\nACON\uacfc meta-ACON\uc744 \ube44\uad50\ud55c \ub3c4\uc2dd\uc785\ub2c8\ub2e4. ResNet50\uc758 \ub9c8\uc9c0\ub9c9 BottleNeck Layer\uc5d0\uc11c\uc758 activation\uc744 \ube44\uad50\ud55c \uac83\uc785\ub2c8\ub2e4. \uc5ec\uae30\uc5d0\uc11c 7\uac1c\uc758 sample\uc744 \uc784\uc758\ub85c \ucd94\ucd9c\ud574\ubd24\uc2b5\ub2c8\ub2e4.\\n\\n- ACON\uc5d0\uc11c \ucd94\ucd9c\ud560 \uacbd\uc6b0, \ud30c\ub780 \ud788\uc2a4\ud1a0\uadf8\ub7a8\uc5d0 \ud574\ub2f9\ud558\ub294\ub370\uc694. 7\uac1c\uc758 sample\uc774 \ub3d9\uc77c\ud55c \u03b2 distribution\uc744 \ub098\ud0c0\ub0c5\ub2c8\ub2e4.\\n- Meta-ACON\uc5d0\uc11c\ub294 7\uac1c\uc758 sample\uc774 \uc11c\ub85c \ub2e4\ub978 \u03b2 distribution\uc744 \ubcf4\uc5ec\uc8fc\uac8c \ub429\ub2c8\ub2e4. \uc5ec\uae30\uc11c \u03b2 \uac12\uc774 \uc791\uc744\uc218\ub85d, \uc120\ud615\uc801\uc73c\ub85c(linear) \ubc18\uc751\ud558\ub294 \uac83\uc774\uace0, \u03b2 \uac12\uc774 \ud074 \uc218\ub85d \ube44\uc120\ud615\uc801(non-linear)\uc73c\ub85c \ubc18\uc751\ud558\uace0 \uc788\ub294 \uac83\uc785\ub2c8\ub2e4.\\n\\nCode Snippet\uc73c\ub85c \ubcf4\uba74 \uc544\ub798\uc640 \uac19\uc2b5\ub2c8\ub2e4. \ubcf8 Snippet\uc740 \uc800\uc790\uc758 [official github](https://github.com/nmaac/acon)\uc5d0\uc11c \ubc1c\ucdcc\ud588\uc73c\uba70, \ud574\ub2f9 Repository\uc5d0\uc11c \uc790\uc138\ud55c \ucf54\ub4dc\ub97c \ud655\uc778\ud558\uc2e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<script src=\\"https://gist.github.com/deepkyu/1616637a06e1b00534a7557c35ad2209.js\\"><\/script>\\n<script src=\\"https://gist.github.com/deepkyu/77b2e5acd98969fdb21ea22198954ad5.js\\"><\/script>\\n\\n### \uacb0\uacfc\\n\\n| ImageNet Classification Result       | Accuracy Improvements       |\\n| --------------------------- | --------------------------- |\\n| ![figure9_result1.png](./image/figure9_result1.png) | ![figure10_result2.png](./image/figure10_result2.png) |\\n\\nImageNet Classification\uc5d0 \ub300\ud55c ShuffleNetV2 \uae30\uc900 \uacb0\uacfc\ub97c \uc0b4\ud3b4\ubcf4\uba74, \ud559\uc2b5 \uc18d\ub3c4\ub3c4 \ube60\ub97c \ubfd0\ub354\ub7ec, Meta-ACON\uc744 \uc0ac\uc6a9\ud588\uc744 \ub54c Error rate\uac00 \ub0ae\uc544\uc9c0\ub294 \uac83\uc744 \ud655\uc778\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc804\ubc18\uc801\uc73c\ub85c \ubaa8\ub378 \uc0ac\uc774\uc988\uac00 \ucee4\uc9c8 \uc218\ub85d, Meta-ACON\uc744 \uc0ac\uc6a9\ud560 \uc218\ub85d Accuracy \ud5a5\uc0c1\uc774 \ud07d\ub2c8\ub2e4. (Swish \ub300\uccb4, SENet Novelty \ucd94\uac00 \ub4f1 \ub300\ube44)\\n\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFour} alt=\\"figure12_result4\\" />\\n<img className={clsx(styles.figCenter, styles.medium)} src={figResultFive} alt=\\"figure13_result5\\" />\\n\\n\uc774\ub807\uac8c Meta-ACON\uc740 \ub2e4\ub978 activation \ub300\ube44 ImageNet Classification\uc5d0\uc11c \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub610\ud55c, \uc81c\ud55c\uc801\uc774\uae30\ub294 \ud558\ub098, \ud2b9\uc815 backbone\uc5d0 \ub300\ud574\uc11c Object Detection \ubc0f Semantic Segmentation\uc5d0 \uc788\uc5b4\uc11c\ub3c4 \ub2e4\ub978 activation function\uc744 \uc0ac\uc6a9\ud560 \ub54c\ubcf4\ub2e4 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90d\ub2c8\ub2e4.\\n\\n### \ub9c8\ubb34\ub9ac\\n\\n\uc774\ub807\uac8c \uc624\ub298\uc740 ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ud1b5\ud574 \uc0c8\ub85c\uc6b4 Activation Function\ub4e4\uc774 \ud3ec\uc9c4\ub418\uc5b4 \uc788\uc744\ub9cc\ud55c \uc77c\ubc18\ud654\ub41c \uc2dd\uc744 \ucc3e\uace0(ACON Family), \uc774\ub97c \uae30\ubc18\uc73c\ub85c Trainable\ud55c Activation Function\uc744 \uc0c8\ub85c \ub9cc\ub098\ubcfc \uc218 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.  \\n\uc0ac\uc2e4 \uc774\ub807\uac8c \ud6c8\ub828 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub97c \uac00\uc9c4 Activation Function\uc774 ACON\ub9cc \ucc98\uc74c\uc778 \uac83\uc740 \uc544\ub2d9\ub2c8\ub2e4. \ub610\ud55c, \uc5ec\ub7ec Sub-task\uc5d0 \ub300\ud574 \ubc94\uc6a9\uc801\uc73c\ub85c \uc0ac\uc6a9\ub420 \uc218 \uc788\ub294 Activation Function\uc77c\uc9c0\ub294 \ubbf8\uc9c0\uc218\uc774\uae30\ub3c4 \ud558\uace0\uc694. \ud2b9\ud788 \ubaa8\ub378 \uacbd\ub7c9\ud654 \ub4f1 \uc5b4\ub290 \ud55c\ud3b8\uc5d0\uc11c\ub294 Non-linear Activation Function\ub9c8\uc800 Bottleneck\uc73c\ub85c \uc9da\uace0 \ub118\uc5b4\uac00\ub294 \uc2e4\uc815\uc774\uae30\uc5d0[<sup>[3]</sup>](#r3), \ubaa8\ub4e0 \ubaa9\uc801\uc744 \ub9cc\uc871\uc2dc\ud0ac\ub9cc\ud55c \uc0c8\ub85c\uc6b4 \ud65c\uc131 \ud568\uc218\ub97c \ucc3e\uc740 \uc5f0\uad6c\ub294 \uc544\ub2d9\ub2c8\ub2e4. \ub2e4\ub9cc, \uc2dd\uc5d0 \ub300\ud55c \uac04\ub2e8\ud55c \uc815\ub9ac\ub85c ReLU\uc640 Swish \uac04\uc758 \uad00\uacc4\ub97c \ubcf4\uc784\uacfc \ub3d9\uc2dc\uc5d0, \uc0c8\ub85c\uc6b4 Activation Family\ub97c \uc81c\uc2dc\ud588\ub2e4\ub294 \ub370\uc5d0 \uc758\uc758\uac00 \uc788\ub294 \ub17c\ubb38\uc774\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\nCVPR 2021\uc5d0\uc11c \uc774\ub7ec\ud55c \ub17c\ubb38\ub3c4 \ubc1c\ud45c\ub41c\ub2e4\ub294 \uac83\uc744 \ud568\uaed8 \uacf5\uc720\ud558\uace0 \uc2f6\uc5b4 \uac04\ub7b5\ud558\uac8c\ub098\ub9c8 \ub9ac\ubdf0\ub97c \uc9c4\ud589\ud574\ubd24\uc2b5\ub2c8\ub2e4 :+1:\\n\\n\\n### References (+ \ud568\uaed8 \uc77d\uc73c\uba74 \uc88b\uc740 \ub17c\ubb38\ub4e4)\\n\\n<a name=\\"r1\\"></a>\\n\\n1. Ramachandran, Prajit, Barret Zoph, and Quoc V. Le. \\"Searching for activation functions.\\" arXiv preprint arXiv:1710.05941 (2017). [[paper]](https://arxiv.org/abs/1710.05941) \\n\\n<a name=\\"r2\\"></a>\\n\\n2. Goodfellow, Ian, et al. \\"Maxout networks.\\" International conference on machine learning. PMLR, 2013. [[paper]](http://proceedings.mlr.press/v28/goodfellow13.html)\\n\\n<a name=\\"r3\\"></a>\\n\\n3. Han Cai, Chuang Gan, Ligeng Zhu, and Song Han. \\"TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning\\n.\\" Part of Advances in Neural Information Processing Systems 33 (NeurIPS 2020) [[paper]](https://proceedings.neurips.cc//paper_files/paper/2020/hash/81f7acabd411274fcf65ce2070ed568a-Abstract.html)\\n\\n\\n\\n### TL;DR\\n\\n- Activation function\ub4e4\uc5d0 \ub300\ud574 \uae30\uc874 Maxout family\uc5d0 \ud574\ub2f9\ud558\ub294 \uc77c\ubc18\ud654\ub97c \ub118\uc5b4 **ACON Family**\ub77c\ub294 \uac1c\ub150\uc73c\ub85c \ud655\uc7a5\ud558\uc5ec \uc77c\ubc18\ud654\ub97c \ud569\ub2c8\ub2e4.\\n- \uc774\ub97c \ud1b5\ud574 ACON Family\uc5d0\uc11c \uac01 activation\uc744 \uacb0\uc815 \uc9d3\ub294 parameter \uc790\uccb4\ub97c learnable\ud558\uac8c \ud558\uc5ec **acon** \uc774\ub77c\ub294 activation\uc744 \uc0c8\ub86d\uac8c \uc81c\uc2dc\ud569\ub2c8\ub2e4.\\n- \uae30\uc874 Swish \ub294 NAS\ub85c \ucc3e\uc740 activation\uc73c\ub85c\uc11c, \ub354 \uc88b\ub2e4\ub294 \uac83\ub9cc \uc54c \ubfd0, \uc65c \uc88b\uc740\uc9c0\ub97c \ubab0\ub790\ub294\ub370, **ACON Family**\uc5d0 \ub300\uc751\ud558\uc5ec \ubd24\uc744 \ub54c, \uc774\ub97c \uc5b4\ub290\uc815\ub3c4 \uc124\uba85\ud560 \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4."},{"id":"nu-wave","metadata":{"permalink":"/blog/nu-wave","source":"@site/blog/2021-07-14-publication-nuwave/index.mdx","title":"NU-Wave(Interspeech):","description":"\ucd5c\ucd08\ub85c 48kHz\ub85c upsampling\uc744 \uc131\uacf5\ud55c \uc800\ud76c \uc5f0\uad6c\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","date":"2021-07-14T00:00:00.000Z","formattedDate":"July 14, 2021","tags":[{"label":"publication","permalink":"/blog/tags/publication"},{"label":"paper-review","permalink":"/blog/tags/paper-review"}],"readingTime":15.27,"truncated":false,"authors":[{"name":"JunHyeok Lee","title":"AI Scientist (Audio, Head)","url":"https://github.com/junjun3518","imageURL":"https://github.com/junjun3518.png","key":"junjun3518"},{"name":"Seungu Han","title":"AI Scientist (Audio)","url":"https://github.com/Seungwoo0326","imageURL":"https://github.com/Seungwoo0326.png","key":"seungu"}],"frontMatter":{"slug":"nu-wave","title":"NU-Wave(Interspeech):","description":"\ucd5c\ucd08\ub85c 48kHz\ub85c upsampling\uc744 \uc131\uacf5\ud55c \uc800\ud76c \uc5f0\uad6c\ub97c \uc18c\uac1c\ud569\ub2c8\ub2e4.","image":"img/mindslab_default.png","authors":["junjun3518","seungu"],"tags":["publication","paper-review"]},"prevItem":{"title":"Activate or Not: Learning Customized Activation","permalink":"/blog/acon"}},"content":"import clsx from \'clsx\';\\nimport styles from \'../blog.module.css\';\\n\\nimport figKeenet from \'./image/keenet.png\';\\nimport figMugan from \'./image/mugan.png\';\\nimport figMc from \'./image/mc.png\';\\nimport figDdpm from \'./image/ddpm.png\';\\nimport figNuwave from \'./image/nuwave.png\';\\nimport figSampling from \'./image/sampling.gif\';\\nimport figResult from \'./image/result.png\';\\n\\n\\n[![arXiv](https://img.shields.io/badge/arXiv-2104.02321-brightgreen.svg?style=flat-square)](https://arxiv.org/abs/2104.02321) [![GitHub Repo stars](https://img.shields.io/github/stars/mindslab-ai/nuwave?color=yellow&label=NU-Wave&logo=github&style=flat-square)](https://github.com/mindslab-ai/nuwave) [![githubio](https://img.shields.io/badge/GitHub.io-audio_samples-blue?logo=Github&style=flat-square)](https://mindslab-ai.github.io/nuwave/)\\n\\n\\n## A Diffusion Probabilistic Model for Neural Audio Upsampling\\n\uc548\ub155\ud558\uc138\uc694 MINDs Lab Brain\uc5d0\uc11c Audio\uc640 Speech \uc5f0\uad6c\ub97c \ud558\uace0 \uc788\ub294 [\uc774\uc900\ud601](https://github.com/junjun3518)\uc785\ub2c8\ub2e4. Audio domain\uc758 \ub525\ub7ec\ub2dd \uc5f0\uad6c\ub294 \ub300\ubd80\ubd84 *Sampling Rate* 16kHz\uc778 \uacbd\uc6b0\uc5d0 \ub300\ud574\uc11c \uc9c4\ud589\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc0dd\uc131\ubaa8\ub378 (TTS) \uac19\uc740 \uacbd\uc6b0 22.05kHz\uc778 \uacbd\uc6b0\ub3c4 \uc788\uc5c8\uc9c0\ub9cc \uc74c\uc545\uc774\ub098 \uc601\ud654 \ucabd\uc5d0\uc11c \ub9ce\uc774 \uc4f0\uc774\ub294 44.1kHz\ub098 48kHz\uc5d0 \ube44\ud574\uc11c\ub294 \uc808\ubc18\ubc16\uc5d0 \uc548 \ub418\ub294 sampling rate\uc774\uc5c8\uae30 \ub54c\ubb38\uc5d0 high sampling rate TTS\uc5d0 \ub300\ud55c \uc218\uc694\uac00 \uafb8\uc900\ud788 \uc788\uc5c8\uc2b5\ub2c8\ub2e4. \uc800\ud76c\uac00 \uac1c\ubc1c\ud55c TTS\uc5d0 \ub300\ud574\uc11c \ub354 \ub192\uc740 \ud004\ub9ac\ud2f0\ub85c \uc11c\ube44\uc2a4\ub97c \uc81c\uacf5\ud558\uae30 \uc704\ud574\uc11c *Neural Audio Upsampling*\uc5d0 \ub300\ud55c \uc5f0\uad6c\ub97c \uc9c4\ud589\ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4. 48kHz\ub77c\ub294 \ub192\uc740 sampling rate\ub97c \ubaa9\ud45c\ub85c \ud558\ub294 \uc5f0\uad6c\ub97c \uc9c4\ud589\ud558\ub2e4 \ubcf4\ub2c8 \uc790\uc5f0\uc2a4\ub7fd\uac8c \ucd5c\uadfc\uc5d0 \ud56b\ud55c \uc0dd\uc131\ubaa8\ub378\uc778 *diffusion model*\uc744 \uc801\uc6a9\ud558\uac8c \ub418\uc5c8\uace0 **\ucd5c\ucd08\ub85c 48kHz\ub97c target\uc73c\ub85c upsampling \ud558\ub294\ub370 \uc131\uacf5**\ud558\uc600\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c \uc9c4\ud589\ud55c \uc5f0\uad6c\ub85c [\uc2b9\uc6b0](https://github.com/Seungwoo0326)\ub2d8\uacfc \uac19\uc774 \uc4f4 paper\uac00 **\uc138\uacc4 \ucd5c\uace0\uc758 \uc74c\uc131\uc2e0\ud638\ucc98\ub9ac\ud559\ud68c\uc778 [INTERSPEECH 2021](https://www.interspeech2021.org)\uc5d0 Accept**:tada: \ub418\uc5b4 \uc18c\uac1c\ud574 \ub4dc\ub9ac\uace0\uc790 \ud569\ub2c8\ub2e4!\\n\\n\\n\\n\\n### Audio Upsampling\\n\\nImage domain\uc5d0\uc11c\uc758 super resolution\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd84\uc57c\uac00 *Audio Upsampling*\uc785\ub2c8\ub2e4. Image super resolution\uc5d0\uc11c \ub530\uc640\uc11c *audio super resolution* \ud639\uc740 \uc8fc\ud30c\uc218 \ubc94\uc704 (bandwidth)\ub97c \ub113\ud78c\ub2e4\ub294 \uc758\ubbf8\ub85c *bandwidth extension*\uc774\ub77c\uace0 \ubd80\ub974\uae30\ub3c4 \ud569\ub2c8\ub2e4. Audio\uc758 \uacbd\uc6b0 1\ucd08\uc5d0 \uba87 \ubc88 sampling\uc744 \ud558\ub294\uc9c0\ub97c \ub098\ud0c0\ub0b4\ub294 *Sampling Rate*\ub85c temporal resolution\uc744 \ud45c\ud604\ud569\ub2c8\ub2e4. \uc774 \uac12\uc774 \uc911\uc694\ud55c \uc774\uc720\ub294 sampling rate\uac00 \uc815\ud574\uc9c0\uba74 discrete-time (or digital) audio data\uac00 \uac00\uc9c8 \uc218 \uc788\ub294 maximum frequency (Nyquist frequency)\uac00 \uc815\ud574\uc9c0\uae30 \ub54c\ubb38\uc778\ub370\uc694. Audio domain\uc5d0 \uc775\uc219\ud558\uc9c0 \uc54a\uc73c\uc2e0 \uacbd\uc6b0 \uc544\ub798 \uadf8\ub9bc\uc744 \ubcf4\uc2dc\uba74 \uc774\ud574\uac00 \ube60\ub974\uc2e4 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\\n\\n- continuous-time \ub370\uc774\ud130 ![\uc5b4\ub5a4 audio data](./image/sine.png)\\n- 1000Hz\ub85c \uc0d8\ud50c\ub9c1 \ud588\uc744 \ub54c  ![1000Hz\ub85c \uc0d8\ud50c\ub9c1 \ud588\uc744\ub54c](./image/sr1000hz.png)\\n- 100Hz\ub85c \uc0d8\ud50c\ub9c1 \ud588\uc744 \ub54c ![100Hz \ub85c \uc0d8\ud50c\ub9c1 \ud588\uc744\ub54c](./image/sr100hz.png)\\n\\n\uacf5\uae30\uc758 \uc9c4\ub3d9\uc5d0 \ud574\ub2f9\ud558\ub294 \uc18c\ub9ac\ub97c audio data\ub85c \ucef4\ud4e8\ud130\uc5d0\uc11c \ub2e4\ub8e8\uae30 \uc704\ud574\uc11c\ub294 \ub9c8\uc774\ud06c\uc5d0\uc11c \uc218\uc74c\ub41c \uc2e0\ud638\ub97c discretize\ud558\ub294 \uacfc\uc815\uc774 \ud544\uc694\ud55c\ub370, \uc2dc\uac04\uc5d0 \ub300\ud574 discretize \ud558\ub294 \uac83\uc744 sampling\uc774\ub77c\uace0 \ud569\ub2c8\ub2e4. \uc6d0\ubcf8 \uc2e0\ud638\ubcf4\ub2e4 sampling rate\uac00 \uc0c1\ub2f9\ud788 \ub192\uc744 \uacbd\uc6b0 \ub450 \ubc88\uc9f8 \uadf8\ub9bc\ucc98\ub7fc \uc2e0\ud638\uc5d0 \ub300\ud55c \uc815\ubcf4\ub97c \uc798 \ub2f4\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \ud558\uc9c0\ub9cc \uc774 \uacfc\uc815\uc5d0\uc11c \uc2e0\ud638\uc758 \uc8fc\ud30c\uc218\uac00 *N*\uc77c \ub54c sampling rate\uac00 2\\\\**N* \ubcf4\ub2e4 \uc791\ub2e4\uba74 \uc2e0\ud638\uc5d0 \ub300\ud55c \uc5b4\ub5a4 \uc815\ubcf4\ub3c4 \uc5bb\uc744 \uc218 \uc5c6\ub294 \ub178\uc774\uc988\uac00 \ub418\uac8c \ub429\ub2c8\ub2e4. \uc704\uc758 \uc0ac\uc9c4\uc5d0\uc11c \uc138 \ubc88\uc9f8 \uadf8\ub9bc\uc774 \uadf8 \ucf00\uc774\uc2a4\uc8e0. 2\\\\**N*\uc778 \uacbd\uc6b0 \uc6b4\uc774 \uc88b\ub2e4\uba74 \uc8fc\ud30c\uc218 *N*\uc73c\ub85c \uc9c4\ub3d9\ud558\ub294 \uc2e0\ud638\uac00 \uc788\ub2e4 \uc815\ub3c4\ub294 \uc54c\uc544\ub0bc \uc218 \uc788\uac8c \ub429\ub2c8\ub2e4. \\n\\n\uc5b4\ub5a4 \uc2e0\ud638\ub97c \ub525\ub7ec\ub2dd \uc5c6\uc774 linear, nearest interpolation \ub4f1\uc758 \ubc29\ubc95\uc73c\ub85c upsampling\ud558\uac8c\ub418\uba74 \uc704\uc758 \uc774\uc720 \ub54c\ubb38\uc5d0 \uc6d0\ubcf8\uc758 sampling rate\uc758 \uc808\ubc18 \uc774\uc0c1\uc5d0 \ud574\ub2f9\ud558\ub294 \uc8fc\ud30c\uc218\ub294 \ud3ec\ud568\ud558\uc9c0 \uc54a\uac8c \ub429\ub2c8\ub2e4 ~~\uc815\ud655\ud788\ub294 spectral alias\uac00 \uc0dd\uae30\uae30 \ub54c\ubb38\uc5d0 post filtering\uc744 \ud558\uae30 \ub54c\ubb38\uc774\uc9c0\ub9cc \uc2e0\ud638\ucc98\ub9ac \uc2dc\uac04\uc774 \uc544\ub2c8\ub2c8 \ub118\uc5b4\uac00\uc8e0~~. \uadf8\ub798\uc11c sampling rate \uc790\uccb4\ub294 \ub192\uc544\uc9c0\uc9c0\ub9cc STFT (Short-Time Fourier Transform)\uc744 \ud588\uc744 \ub54c \uc717\ubd80\ubd84\uc774 \ube44\uc5b4 \ubcf4\uc774\uac8c \ub429\ub2c8\ub2e4. \uc774\ub7f0 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\uae30 \uc704\ud574\uc11c \ub525\ub7ec\ub2dd\uc744 \uc801\uc6a9\ud55c \uc5f0\uad6c\ub4e4\uc774 \uc788\uc2b5\ub2c8\ub2e4. \ud06c\uac8c \uc800\ud76c \uc5f0\uad6c\uc640 \ube44\uad50\ud55c \ucf00\uc774\uc2a4 \ub450 \uac1c\ub9cc \uc18c\uac1c\ud558\uace0 \ub118\uc5b4\uac00\uaca0\uc2b5\ub2c8\ub2e4.\\n\\n\\n\\n\\n#### Audio Super Resolution Using Neural Networks[<sup>[1]</sup>](#r1)\\n\\n<img className={styles.figCenter} src={figKeenet} alt=\\"keenet\\" />\\n\\nAudio upsampling task\uc5d0\uc11c \ub525\ub7ec\ub2dd\uc744 \uc801\uc6a9\ud55c \uccab \ub17c\ubb38\uc785\ub2c8\ub2e4. U-Net\uacfc \uac19\uc740 \uad6c\uc870\ub97c \uc801\uc6a9\ud558\uc600\uace0 *N* Hz \uc2e0\ud638\ub97c input\uc73c\ub85c \ud558\uace0 *N\\\\*r* Hz \uc2e0\ud638\ub97c output\uc73c\ub85c \ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4. Loss\ub85c L<sub>2</sub>-norm\uc744 \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\\n\\n\\n\\n#### Bandwidth Extension on Raw Audio via Generative Adversarial Networks[<sup>[2]</sup>](#r2)\\n\\n<img className={styles.figCenter} src={figMugan} alt=\\"mugan\\" />\\n\\nGAN\uc744 \uc0ac\uc6a9\ud574\uc11c upsampling\uc744 \uc2dc\ub3c4\ud55c \ub17c\ubb38\uc785\ub2c8\ub2e4. \uad6c\uc870 \uc790\uccb4\ub294 \uc704\uc758 \ub17c\ubb38\uacfc \ube44\uc2b7\ud558\uace0 loss\ub85c L<sub>2</sub>-norm, discriminator loss, feature loss\ub97c \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.\\n\\n\\n\\n### Diffusion Probabilistic Models\\n\\n#### What is Diffusion Model?\\n\\n\ucd5c\uadfc *Denoising Diffusion Probabilistic Model*[<sup>[3]</sup>](#r3)\uc744 \ud544\ub450\ub85c *diffusion probabilistic model* (\uc904\uc5ec\uc11c *diffusion model*)\uc774 \ud56b\ud55c \uc0dd\uc131\ubaa8\ub378\ub85c \ub5a0\uc624\ub974\uace0 \uc788\uc2b5\ub2c8\ub2e4. \ub354 \ub113\uc740 \ubc94\uc704\uc758 *score-based model*\uc774\ub77c\ub294 \uac83\ub3c4 \uc788\uc73c\ub098 \uc774 \uce5c\uad6c\ub294 \uc544\ub9c8 \ub2e4\ub978 \ud3ec\uc2a4\ud2b8\ub85c \uc18c\uac1c\ud560 \uac83 \uac19\uc2b5\ub2c8\ub2e4. Diffusion model\uc740 GAN\uc774\ub098 VAE\uc640 \ub2e4\ub974\uac8c output\uacfc latent variable\uc758 \uc0ac\uc774\uc988\uac00 \uac19\uc2b5\ub2c8\ub2e4. latent varable\uc740 \uac01 step \ub9c8\ub2e4 \uc6d0\ubcf8\uc5d0 \uc77c\uc815\ud55c Gaussian noise\uac00 \ub354\ud574\uc9c4 \uac83\uc73c\ub85c \uc815\uc758\ub429\ub2c8\ub2e4. \uc774\ub97c 0\ubd80\ud130 T\uae4c\uc9c0\uc758 step\uc744 \uac00\uc9c0\uace0 *forward/reverse* \ub450 \uac1c\uc758 path\ub97c \uac00\uc9c0\ub294 Markov chain\uc73c\ub85c \uc0dd\uac01\ud569\ub2c8\ub2e4. Forward path\uc758 \uacbd\uc6b0 \uc704\uc5d0\uc11c \uc124\uba85\ud55c\ub300\ub85c \uadf8 \uc804 step\uc5d0  Gaussian noise\ub97c \ub354\ud558\ub294 \uac83\uc73c\ub85c \uc815\uc758\ub418\uace0 reverse path \uc758 \uacbd\uc6b0 forward path\uc5d0\uc11c \ub354\ud574\uc9c4 Gaussian noise\ub97c \uc608\uce21\ud574\uc11c \ube7c\ub294 \uac83\uc73c\ub85c \uc815\uc758\ub429\ub2c8\ub2e4. \uacb0\uacfc\uc801\uc73c\ub85c Gaussian distribution\uc73c\ub85c\ubd80\ud130 sampling\ud55c latent variable\uc744 \uc5ec\ub7ec \ubc88 iteration\uc744 \ud558\ub294 Markov Chain Monte-Carlo Sampling\uc744 \ud1b5\ud574 noise\ub97c \uc81c\uac70\ud574\uac00\uba74\uc11c \uc6b0\ub9ac\uac00 \uc6d0\ud558\ub294 output\uc73c\ub85c sampling\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4. \\n\\n<img className={styles.figCenter} src={figMc} alt=\\"\uc6d0\ub798_\ub17c\ubb38\uc5d0_\ub123\uc73c\ub824\uace0_\ud588\ub358_\uc774\ubbf8\uc9c0\\" />\\n\\n*\uc6d0\ub798 \ub17c\ubb38\uc5d0 \ub123\uace0 \uc2f6\uc5c8\ub294\ub370 4p\ub77c \ubd84\ub7c9\uc774 \ubaa8\uc790\ub77c \ubabb \ub123\uc740 Markov Chain \uc774\ubbf8\uc9c0. forward path(\uc810\uc120), reverse path(\uc9c1\uc120)*\\n\\n\\n\\n#### Training and Sampling\\n\\n\uc6d0\ubcf8 \ub370\uc774\ud130\uc5d0 \uc784\uc758\ub85c \ub178\uc774\uc988\ub97c \ub354\ud558\uace0 \ub354\ud574\uc9c4 \ub178\uc774\uc988\ub97c \ubaa8\ub378\uc774 \uc608\uce21\ud558\ub294 \ubc29\uc2dd\uc73c\ub85c \ud559\uc2b5\uc744 \uc9c4\ud589\ud558\uace0 sampling\uc2dc\uc5d0\ub294 Gaussian noise\ubd80\ud130 \uc2dc\uc791\ud558\uc5ec \uc6b0\ub9ac\uac00 \uc6d0\ud558\ub294 data distribution\uc73c\ub85c \uac00\ub294 \ubc29\ud5a5\uc5d0 \ud574\ub2f9\ud558\ub294 noise (score)\ub97c \uc608\uce21\ud558\uc5ec \ube7c\uc8fc\ub294 \uac83\uc744 \ubc18\ubcf5\ud558\uac8c \ub429\ub2c8\ub2e4. Diffusion model\uc740 sampling\uc774 \uc5ec\ub7ec \ubc88 \ubc18\ubcf5\ub418\uc5b4\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0 \uc624\ub798 \uac78\ub9b0\ub2e4\ub294 \ub2e8\uc810\uc774 \uc788\uc9c0\ub9cc \ub9e4\uc6b0 \ub192\uc740 \ud004\ub9ac\ud2f0\uc758 sample\uc744 \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figDdpm} alt=\\"ddpm\\" />\\n\\n*DDPM\uc758 training and sampling algoritihm*\\n\\n\\n#### Conditional Diffusion Models as a Neural Vocoder\\n\\n| DiffWave Architecture       | WaveGrad Architecture       |\\n| --------------------------- | --------------------------- |\\n| ![DiffWave](./image/diffwave.png) | ![wavegrad](./image/wavegrad.png) |\\n\\nDiffusion model\uc774 audio domain\uc5d0 \uac00\uc7a5 \uba3c\uc800 \uc801\uc6a9\ub41c \ubd84\uc57c\ub294 neural vocoder\uc778\ub370\uc694, neural vocoder\ub294 Mel\\\\-spectrogram\uc744 input\uc73c\ub85c \ubc1b\uc544 raw audio\ub97c \uc0dd\uc131\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4. *ICLR 2020*\uc5d0 \ub3d9\uc2dc\uc5d0 *DiffWave*[<sup>[4]</sup>](#r4)\uc640 *WaveGrad*[<sup>[5]</sup>](#r5)\ub77c\ub294 diffusion-based neural vocoder \ub17c\ubb38\uc774 \ub098\uc654\uc2b5\ub2c8\ub2e4. Mel-spectrogram\uc744 local condition\uc73c\ub85c \uc8fc\uace0  \ub9c8\ucc2c\uac00\uc9c0\ub85c noise\ub85c\ubd80\ud130 iterative\ud558\uac8c sampling \ud569\ub2c8\ub2e4. Mel-spectrogram\uacfc output\uc778 raw waveform\uc774 linear\ud558\uac8c align \ub418\uc5b4 \uc788\ub2e4\ub294 \uc810\uc740 audio upsampling\uacfc \uc720\uc0ac\ud558\uc5ec \uc801\uadf9\uc801\uc73c\ub85c audio upsampling \uc5f0\uad6c\uc5d0 \ucc28\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4. \\n\\n\uc0ac\uc2e4 \uc774 \uc5f0\uad6c\ub294 \uc704\uc758 \ub17c\ubb38\ub4e4\uc744 \uc77d\uace0 \ub108\ubb34 \uac10\uba85 \ubc1b\uc544~~\uac04\uc9c0\ub098\uc11c~~ \uc2dc\uc791\ud558\uac8c \ub418\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n\\n\\n### NU-Wave \\n\\n\ucc98\uc74c\uc5d4 \ubaa9\ud45c\ub97c **48kHz\ub97c \ud0c0\uac9f\uc73c\ub85c \ud558\ub294 neural audio upsampling\uc744 \ud558\ub294 \uac83**\uc73c\ub85c \uc7a1\uc558\uc2b5\ub2c8\ub2e4. \uadf8\ub9ac\uace0 \uad6c\ud604\uc774 \uc0c1\ub300\uc801\uc73c\ub85c \uac04\ub2e8\ud55c \uc704\uc5d0 \uc18c\uac1c\ud588\uc5c8\ub358 \uc5f0\uad6c\ub4e4\uc744 \uad6c\ud604\ud558\uc5ec \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4. \uadf8\ub7f0\ub370 \uc0c1\uc0c1 \uc774\uc0c1\uc73c\ub85c \uacb0\uacfc\uac00 \uc88b\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4. Low frequency \ubd80\ubd84\uc740 \ud06c\uac8c \uac74\ub4dc\ub9ac\uc9c0 \uc54a\uc558\uc9c0\ub9cc high frequency \ubd80\ubd84\ub4e4\uc740 \ub108\ubb34 \uacfc\ud558\uac70\ub098 \uac70\uc758 \uc5c6\uac70\ub098 \ud588\uc2b5\ub2c8\ub2e4. \uadf8\ub7ec\ub358 \uc911 \uc704\uc5d0\uc11c \uc124\uba85\ud55c *diffusion model*\uc774 vocoder task\uc5d0\uc11c \uc88b\uc740 \uacb0\uacfc\ub97c \ub0b4\uc5c8\uace0 image domain\uc5d0\uc11c\ub3c4 1024x1024 \ud574\uc0c1\ub3c4\uc758 \uc774\ubbf8\uc9c0\ub97c sampling\ud55c \uacb0\uacfc\uac00 \uc788\uc5b4 \ubc14\ub85c \uc801\uc6a9\ud574 \ubcf4\uae30\ub85c \ud558\uc600\uc2b5\ub2c8\ub2e4. \\n\\n<img className={styles.figCenter} src={figNuwave} alt=\\"nuwave\\" />\\n\\n*NU-Wave\uc758 architecture\uc640 algorithm*\\n\\nNeural vocoder \uc5f0\uad6c\ub97c audio upsampling\uc5d0 \uc801\uc6a9\ud558\uae30 \uc704\ud574 DiffWave\uc640 WaveGrad\ub97c \ub9ce\uc774 \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4. \uad6c\uc870\ub294 dilation convolution\uc744 \uc0ac\uc6a9\ud55c DiffWave\uc758 \uad6c\uc870\uac00 U-Net like\ud55c WaveGrad \ubcf4\ub2e4 \uc0ac\uc774\uc988\uc5d0 \ub354 \uc77c\ubc18\uc801\uc77c \uac83\uc73c\ub85c \uc0dd\uac01\ud558\uc5ec DIffWave\uc758 \uad6c\uc870\uc640 \ucd5c\ub300\ud55c \uc720\uc0ac\ud558\uac8c \ub9cc\ub4e4\uc5c8\uace0, WaveGrad\uc758 \uacbd\uc6b0 training \uacfc\uc815\uc5d0\uc11c continuous noise level training\uc774\ub77c\ub294 \uac83\uc744 \uc801\uc6a9\ud558\uc5ec sampling\uc2dc\uc5d0 \ub354 \uc801\uc740 \uc218\uc758 iteration\uc73c\ub85c sampling\uc744 \ud558\ub294 \ubc29\ubc95\uc744 \ucc38\uace0\ud558\uc600\uc2b5\ub2c8\ub2e4. \\n\\nNeural vocoder\uc5d0\uc11c \uc0ac\uc6a9\ub41c \uac12\ub4e4\uc744 upsampling\uc5d0 \uc0ac\uc6a9\ud558\ub824\uace0 \ud558\ub2e4 \ubcf4\ub2c8 \uba87\uac00\uc9c0 \ubb38\uc81c\uc810\uc774 \uc788\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n1. Raw waveform\uc744 condition\uc73c\ub85c \ub123\uc5b4\uc92c\uc744 \ub54c receptive field\uac00 \ub108\ubb34 \uc791\uc544 condition\uc774 \ubcc4\ub85c \uc601\ud5a5\uc744 \uc8fc\uc9c0 \ubabb\ud588\ub2e4.\\n2. \uc0dd\uac01\ubcf4\ub2e4 sample\uc774 \ub9ce\uc774 noisy \ud558\ub2e4.\\n3. \ub108\ubb34 high sampling rate\ub97c target\uc73c\ub85c \ud558\ub2e4 \ubcf4\ub2c8 computing power\uac00 \ub9ce\uc774 \ud544\uc694\ud588\ub2e4.\\n\\n1\ubc88\uc758 \uacbd\uc6b0 \uc5ec\ub7ec \uac00\uc9c0\ub97c \uc2dc\ub3c4\ud558\ub2e4 condition signal\uc5d0\ub3c4 Bi-DilConv\ub97c \uc801\uc6a9\ud588\ub354\ub2c8 \uac11\uc790\uae30 \uc5c4\uccad\ub098\uac8c \uc798\ub418\uae30 \uc2dc\uc791\ud558\uc600\uc2b5\ub2c8\ub2e4. Condition signal\uc758 receptive field\ub97c Bi-DilConv\ub85c \ub113\ud600\uc900 \uac83\uc774 \ud6a8\uacfc\uac00 \uc788\uc5c8\ub2e4\ub294 \uac8c \uc800\ud76c\uac00 \ubd84\uc11d\ud55c \uacb0\uacfc\uc785\ub2c8\ub2e4.\\n\\n2\ubc88\uc758 \uacbd\uc6b0 WaveGrad\uc5d0\uc11c \uc81c\uc2dc\ud588\ub358 noise schedule, linear scale \ub4f1\uc758 \uc218\uce58\ub97c \uc0c1\ub2f9\ud788 \uc870\uc808\ud558\uace0 \ud559\uc2b5\uc744 \uc624\ub798 \ud588\ub354\ub2c8 \ud574\uacb0\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc544\uc9c1 diffusion model\uc774 \ub9ce\uc774 \uc5f0\uad6c\ub418\uc5c8\ub358 \uac83\uc774 \uc544\ub2c8\ub2e4 \ubcf4\ub2c8 \uc774\ub7f0 hyperparameter\ub4e4\uc744 \uc9c1\uc811 \uc5ec\ub7ec \ubc88 \ud14c\uc2a4\ud2b8\ud574\ubcf4\ub294 \uac83\ubc16\uc5d0\ub294 \ub2f5\uc774 \uc5c6\uc5c8\uc2b5\ub2c8\ub2e4.\\n\\n3\ubc88\uc758 \uacbd\uc6b0 \uc88b\uc740 GPU\ub97c \uc81c\uacf5\ud574\uc8fc\ub294 MINDs Lab\uc774\ub77c\uc11c A100 \ub450 \ub300\ub97c \uc0ac\uc6a9\ud574\uc11c \ud574\uacb0\ud588\uc2b5\ub2c8\ub2e4.\\n\\n\ud574\uacb0 \ubc29\ubc95\uc744 \uc5ec\ub7ec \uac00\uc9c0\ub97c \uc2dc\ub3c4\ud574\uc11c \ud574\uacb0\ud588\ub2e4\uace0 \uc4f0\uae34 \ud588\uc9c0\ub9cc \uc774 \uae30\uac04\uc774 \ud55c \ub2ec \uc880 \ub118\uc5c8\ub358 \uac83 \uac19\uc2b5\ub2c8\ub2e4. 1\uc6d4\uc5d0 \ubcf8\uaca9\uc801\uc73c\ub85c \uc2dc\uc791\ud558\uc5ec \uad6c\ud604\uc740 2\uc8fc\uc548\uc5d0 \ub05d\ub0ac\ub294\ub370 hyperparameter\ub9cc \ud55c\ub2ec \ub118\uac8c \uace0\uccd0\uac00\uba74\uc11c \uc815\ub9d0 \uc5ec\ub7ec \uac00\uc9c0\ub97c \uc2dc\ub3c4\ud574\ubd24\uc2b5\ub2c8\ub2e4. \ud55c \ub2ec \ub118\ub294 \uc2dc\ub3c4 \ub05d\uc5d0 \uc88b\uc740 sample\uc744 \ubf51\uc544\ub0b4\ub294 \uc815\ub3c4\uac00 \ub418\uc5b4 3\uc6d4\uc5d0\ub294 \ub17c\ubb38 \uc791\uc131\uc5d0 \ubc15\ucc28\ub97c \uac00\ud588\ub358 \uac83 \uac19\uc2b5\ub2c8\ub2e4.\\n\\n<img className={styles.figCenter} src={figSampling} alt=\\"sampling\\" />\\n\\n*NU-Wave\uac00 8\ubc88 \ub9cc\uc5d0 sampling\ud558\ub294 \uacfc\uc815*\\n\\n\\n\\n### Results\\n\\n<img className={styles.figCenter} src={figResult} alt=\\"result\\" />\\n\\n\uc55e\uc5d0\uc11c \uc18c\uac1c\ud55c \uac83\ub4e4\uacfc\uc758 \ube44\uad50\ub97c \uc704\ud55c spectrogram\uc785\ub2c8\ub2e4. \uc81c\uc77c \uc67c\ucabd \uc6d0\ubcf8\uc5d0 \ube44\ud574\uc11c \uac00\uc6b4\ub370 \uc138\uac1c\uc758 \uacbd\uc6b0 \uacfc\ud558\uac8c \uae30\ub465\uc774 \uc130\uac70\ub098, Nyquist frequency \uae30\uc900\uc73c\ub85c \ub300\uce6d\uc774 \ub418\uac70\ub098 \ud558\ub294 \ud604\uc0c1\uc744 \ubcf4\uc785\ub2c8\ub2e4. \ud558\uc9c0\ub9cc NU-Wave\uc758 \uacbd\uc6b0 \uc790\uc5f0\uc2a4\ub7fd\uac8c high frequency \ubd80\ubd84\uc744 \uc0dd\uc131\ud558\ub294 \uac83\uc744 \ubcfc \uc218 \uc788\uc2b5\ub2c8\ub2e4. \\n\\n| SNR, LSD             | ABX accuracy          |\\n| -------------------- | --------------------- |\\n| ![](./image/objective.png) | ![](./image/subjective.png) |\\n\\nAudio upsampling task\uc5d0\uc11c\ub294 \ud06c\uac8c 3\uac00\uc9c0\uc758 metric\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4. \uc6d0\ubcf8\uacfc downsampling\ud55c \uc2e0\ud638\ub97c \ub2e4\uc2dc upsampling\ud55c \ud6c4 \uc218\uce58\uc801\uc73c\ub85c \ube44\uad50\ud558\ub294 *SNR (signal-to-noise ratio)*, *LSD (log-spectral distance)*\uc640 \uc0ac\ub78c\uc774 \ub2e4\ub978 \uc885\ub958\uc758 A, B\uc640 \ub458 \uc911 \ud558\ub098\ub97c \ubf51\uc740 X \uc138\uac00\uc9c0\ub97c \ub4e4\uc5b4\ubcf4\uace0 \uc5b4\ub290\uac83\uc778\uc9c0 \uad6c\ubd84\ud560 \uc218 \uc788\ub294 ABX test\uc758 \uc815\ud655\ub3c4\uc778 *ABX accuracy*\uac00 \uc788\uc2b5\ub2c8\ub2e4. **NU-Wave\uc758 \uacbd\uc6b0 SNR, LSD, ABX acc\uc5d0\uc11c 3.0M\uc758 parameter\ub85c \ub2e4\ub978 \ubaa8\ub378\ub4e4\ubcf4\ub2e4 \ub192\uc740 \uc131\ub2a5\uc744 \ubcf4\uc600\uc2b5\ub2c8\ub2e4.** \\n\\n\\n\\n### Discussion\\n\\nDownsampling \ubc29\uc2dd\uc744 \ud55c\uc815\uc9c0\uc5b4 \uc544\uc9c1 \uc2e4\uc81c\ub85c upsampling\uc744 \ud560 \ub54c\ub294 \ubb38\uc81c\uac00 \uc0dd\uae34\ub2e4\ub294 \uc810, diffusion model\uc758 \ud2b9\uc131\uc778\uc9c0 high noise\uac00 \uc0b4\uc9dd \ub0a8\ub294\ub2e4\ub294 \uc810 \ub4f1 \uac1c\uc120\ud574\uc57c\ud560 \ubd80\ubd84\uc774 \ub9ce\uace0 \uc6d0\ub798\uc758 \ubaa9\ud45c\uc778 TTS\uc5d0 \uc801\uc6a9\ud558\ub294 \ubd80\ubd84\ub3c4 \uc219\uc81c\ub85c \ub0a8\uc544\uc788\ub294\uac83 \uac19\uc2b5\ub2c8\ub2e4. \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 [\ub17c\ubb38](https://arxiv.org/abs/2104.02321)\uc744 \ucc38\uace0\ud574\uc8fc\uc2dc\uace0 [\ucf54\ub4dc](https://github.com/mindslab-ai/nuwave)\uc5d0 \ub9ce\uc740 \uc2a4\ud0c0:star:\ubd80\ud0c1\ub4dc\ub9bd\ub2c8\ub2e4. \\n\\n9\uc6d4\uc5d0 INTERSPEECH \ud559\ud68c\uc5d0\uc11c \ubd2c\uc694! \u200b\\n\\n\\n\\n### References\\n\\n<a name=\\"r1\\"></a>\\n\\n1. V. Kuleshov, S. Z. Enam, and S. Ermon, \u201cAudio super resolution using neural networks,\u201d in *Workshop of International Conference on Learning Representations*, 2017. [[arxiv]](https://arxiv.org/abs/1708.00853)\\n\\n<a name=\\"r2\\"></a>\\n\\n2. S. Kim and V. Sathe, \u201cBandwidth extension on raw audio via generative adversarial networks,\u201d *arXiv preprint arXiv:1903.09027*, 2019. [[arxiv]](https://arxiv.org/abs/1903.09027)\\n\\n<a name=\\"r3\\"></a>\\n\\n3. J. Ho, A. Jain, and P. Abbeel, \u201cDenoising diffusion probabilistic models,\u201d in *Advances in Neural Information Processing Systems*, 2020, pp. 6840\u20136851. [[arxiv]](https://arxiv.org/abs/2006.11239)\\n\\n<a name=\\"r4\\"></a>\\n\\n4. Z. Kong, W. Ping, J. Huang, K. Zhao, and B. Catanzaro, \u201cDiffwave: A versatile diffusion model for audio synthesis,\u201d in *International Conference on Learning Representations*, 2021. [[arxiv]](https://arxiv.org/abs/2009.09761)\\n\\n<a name=\\"r5\\"></a>\\n\\n5. N. Chen, Y. Zhang, H. Zen, R. J. Weiss, M. Norouzi, and W. Chan, \u201cWavegrad: Estimating gradients for waveform generation,\u201d in *International Conference on Learning Representations*, 2021. [[arxiv]](https://arxiv.org/abs/2009.00713)\\n\\n\\n\\n### TL;DR\\n\\n1. **\ucd5c\ucd08\ub85c 16kHz/24kHz\uc5d0\uc11c 48kHz\ub85c upsampling \uc131\uacf5**\\n2. **\ucd5c\ucd08\ub85c diffusion model\uc744 audio upsampling\uc5d0 \uc801\uc6a9**\\n3. **\uc801\uc740 parameter number(3.0M)\uc73c\ub85c \ub2e4\ub978 \ubaa8\ub378\ub4e4\uc744 \ub2a5\uac00**"}]}')}}]);