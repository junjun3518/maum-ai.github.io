"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[249],{3905:function(t,e,i){i.d(e,{Zo:function(){return u},kt:function(){return p}});var r=i(7294);function a(t,e,i){return e in t?Object.defineProperty(t,e,{value:i,enumerable:!0,configurable:!0,writable:!0}):t[e]=i,t}function n(t,e){var i=Object.keys(t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(t);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),i.push.apply(i,r)}return i}function s(t){for(var e=1;e<arguments.length;e++){var i=null!=arguments[e]?arguments[e]:{};e%2?n(Object(i),!0).forEach((function(e){a(t,e,i[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(i)):n(Object(i)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(i,e))}))}return t}function o(t,e){if(null==t)return{};var i,r,a=function(t,e){if(null==t)return{};var i,r,a={},n=Object.keys(t);for(r=0;r<n.length;r++)i=n[r],e.indexOf(i)>=0||(a[i]=t[i]);return a}(t,e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);for(r=0;r<n.length;r++)i=n[r],e.indexOf(i)>=0||Object.prototype.propertyIsEnumerable.call(t,i)&&(a[i]=t[i])}return a}var l=r.createContext({}),c=function(t){var e=r.useContext(l),i=e;return t&&(i="function"==typeof t?t(e):s(s({},e),t)),i},u=function(t){var e=c(t.components);return r.createElement(l.Provider,{value:e},t.children)},h={inlineCode:"code",wrapper:function(t){var e=t.children;return r.createElement(r.Fragment,{},e)}},m=r.forwardRef((function(t,e){var i=t.components,a=t.mdxType,n=t.originalType,l=t.parentName,u=o(t,["components","mdxType","originalType","parentName"]),m=c(i),p=a,f=m["".concat(l,".").concat(p)]||m[p]||h[p]||n;return i?r.createElement(f,s(s({ref:e},u),{},{components:i})):r.createElement(f,s({ref:e},u))}));function p(t,e){var i=arguments,a=e&&e.mdxType;if("string"==typeof t||a){var n=i.length,s=new Array(n);s[0]=m;var o={};for(var l in e)hasOwnProperty.call(e,l)&&(o[l]=e[l]);o.originalType=t,o.mdxType="string"==typeof t?t:a,s[1]=o;for(var c=2;c<n;c++)s[c]=i[c];return r.createElement.apply(null,s)}return r.createElement.apply(null,i)}m.displayName="MDXCreateElement"},920:function(t,e,i){i.r(e),i.d(e,{contentTitle:function(){return p},default:function(){return d},frontMatter:function(){return m},metadata:function(){return f},toc:function(){return b}});var r=i(7462),a=i(3366),n=(i(7294),i(3905)),s="category__EJB",o="repositories_dIUZ",l="stars_gWrp",c="paper_aHyy",u="description_H6wW",h=["components"],m={title:"Open-Source Activities",description:"List of Open-Source Activities from MINDsLab Brain Team"},p="Open-Source Activities",f={type:"mdx",permalink:"/open-source",source:"@site/src/pages/open-source.mdx",title:"Open-Source Activities",description:"List of Open-Source Activities from MINDsLab Brain Team",frontMatter:{title:"Open-Source Activities",description:"List of Open-Source Activities from MINDsLab Brain Team"}},b=[{value:"Implementations",id:"implementations",level:2},{value:"Official",id:"official",level:3},{value:"Unofficial",id:"unofficial",level:3},{value:"Libraries &amp; Tools",id:"libraries--tools",level:2}],k={toc:b};function d(t){var e=t.components,i=(0,a.Z)(t,h);return(0,n.kt)("wrapper",(0,r.Z)({},k,i,{components:e,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"open-source-activities"},"Open-Source Activities"),(0,n.kt)("h2",{id:"implementations"},"Implementations"),(0,n.kt)("h3",{id:"official"},"Official"),(0,n.kt)("section",{id:"activities",className:s},(0,n.kt)("ul",{className:o},(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=assem-vc&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/assem-vc"},"Assem-VC")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2104.00931"},"Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques"))),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=nuwave&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/nuwave"},"NU-Wave")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2104.02321"},"NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling"))),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=cotatron&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/cotatron"},"Cotatron")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2005.03295"},"Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data"))))),(0,n.kt)("h3",{id:"unofficial"},"Unofficial"),(0,n.kt)("section",{id:"activities",className:s},(0,n.kt)("ul",{className:o},(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=pnlp-mixer&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/pnlp-mixer"},"pNLP-Mixer")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2202.04350"},"pNLP-Mixer: an Efficient all-MLP Architecture for Language")),(0,n.kt)("p",{className:u},"First successful open-source implementation of ",(0,n.kt)("i",null,"pNLP-Mixer"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=hififace&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/hififace"},"HifiFace")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2106.09965"},"HifiFace: 3D Shape and Semantic Prior Guided High Fidelity Face Swapping")),(0,n.kt)("p",{className:u},"First successful open-source implementation of ",(0,n.kt)("i",null,"HifiFace"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=univnet&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/univnet"},"UnivNet")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2106.07889"},"UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation")),(0,n.kt)("p",{className:u},"First successful open-source implementation of ",(0,n.kt)("i",null,"UnivNet"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=wavegrad2&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/wavegrad2"},"WaveGrad2")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2106.09660"},"WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis")),(0,n.kt)("p",{className:u},"First successful open-source implementation of ",(0,n.kt)("i",null,"WaveGrad2"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=faceshifter&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/faceshifter"},"FaceShifter")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/1912.13457"},"FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping")),(0,n.kt)("p",{className:u},"First successful open-source implementation of ",(0,n.kt)("i",null,"FaceShifter"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Rick-McCoy&repo=Reformer-pytorch&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/Rick-McCoy/Reformer-pytorch"},"Reformer-pytorch")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/2001.04451"},"Reformer: The Efficient Transformer")),(0,n.kt)("p",{className:u},"Implementation of ",(0,n.kt)("i",null,"Reformer")," in PyTorch.")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=seungwonpark&repo=melgan&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/seungwonpark/melgan"},"MelGAN")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/1910.06711"},"MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis")),(0,n.kt)("p",{className:u},"Implementation of ",(0,n.kt)("i",null,"MelGAN")," vocoder (compatible with ",(0,n.kt)("a",{href:"https://github.com/NVIDIA/tacotron2"},"NVIDIA/tacotron2"))),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Deepest-Project&repo=MelNet&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/Deepest-Project/MelNet"},"MelNet")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/1906.01083"},"MelNet: A Generative Model for Audio in the Frequency Domain")),(0,n.kt)("p",{className:u},"Implementation of ",(0,n.kt)("i",null,"MelNet"),". Work done with Deepest AI (SNU Deep Learning Society).")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=seungwonpark&repo=RandWireNN&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/seungwonpark/RandWireNN"},"RandWireNN")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/1904.01569"},"Exploring Randomly Wired Neural Networks for Image Recognition")),(0,n.kt)("p",{className:u},"Implementation of ",(0,n.kt)("i",null,"RandWireNN"),".")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=voicefilter&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/mindslab-ai/voicefilter"},"VoiceFilter")),(0,n.kt)("p",{className:c},(0,n.kt)("a",{href:"https://arxiv.org/abs/1810.04826"},"VoiceFilter: Targeted Voice Separation by Speaker-Conditioned Spectrogram Masking")),(0,n.kt)("p",{className:u},"First successful open-source implementation of Google's ",(0,n.kt)("i",null,"VoiceFilter"))))),(0,n.kt)("h2",{id:"libraries--tools"},"Libraries & Tools"),(0,n.kt)("section",{id:"activities",className:s},(0,n.kt)("ul",{className:o},(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Diuven&repo=KoTDG&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/Diuven/KoTDG"},"KoTDG")),(0,n.kt)("p",{className:u},"Korean Text Data Generator for OCR tasks.")),(0,n.kt)("li",null,(0,n.kt)("div",{className:l},(0,n.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=ThisIsIsaac&repo=Data-Science-for-COVID-19&type=star&count=true",frameborder:"0",scrolling:"0",width:"90",height:"20",title:"GitHub"})),(0,n.kt)("h3",null,(0,n.kt)("a",{href:"https://github.com/ThisIsIsaac/Data-Science-for-COVID-19"},"Data-Science-for-COVID-19")),(0,n.kt)("p",{className:u},"COVID-19 Korea Dataset with patient routes and visualizer. Co-led the collaboration project.")))))}d.isMDXComponent=!0}}]);