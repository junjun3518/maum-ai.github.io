"use strict";(self.webpackChunkdocusaurus_test=self.webpackChunkdocusaurus_test||[]).push([[349],{3905:function(e,t,r){r.d(t,{Zo:function(){return m},kt:function(){return h}});var a=r(7294);function n(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){n(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,a,n=function(e,t){if(null==e)return{};var r,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||(n[r]=e[r]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)r=i[a],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(n[r]=e[r])}return n}var s=a.createContext({}),u=function(e){var t=a.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},m=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var r=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),c=u(r),h=n,g=c["".concat(s,".").concat(h)]||c[h]||p[h]||i;return r?a.createElement(g,o(o({ref:t},m),{},{components:r})):a.createElement(g,o({ref:t},m))}));function h(e,t){var r=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=r.length,o=new Array(i);o[0]=c;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:n,o[1]=l;for(var u=2;u<i;u++)o[u]=r[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}c.displayName="MDXCreateElement"},4449:function(e,t,r){r.r(t),r.d(t,{contentTitle:function(){return s},default:function(){return c},frontMatter:function(){return l},metadata:function(){return u},toc:function(){return m}});var a=r(7462),n=r(3366),i=(r(7294),r(3905)),o=["components"],l={title:"Publications & Open Source Activities",description:"List of Publications & Open Source Activities"},s="Publications & Open Source Activities",u={type:"mdx",permalink:"/publications",source:"@site/src/pages/publications.md",title:"Publications & Open Source Activities",description:"List of Publications & Open Source Activities",frontMatter:{title:"Publications & Open Source Activities",description:"List of Publications & Open Source Activities"}},m=[{value:"Publications",id:"publications",level:2},{value:"<strong>(June 2022)</strong> <em>Talking Face Generation with Multilingual TTS</em>",id:"june-2022-talking-face-generation-with-multilingual-tts",level:4},{value:"<strong>(June 2022)</strong> <em>Styleformer: Transformer based Generative Adversarial Networks with Style Vector</em>",id:"june-2022-styleformer-transformer-based-generative-adversarial-networks-with-style-vector",level:4},{value:"<strong>(May 2022)</strong> <em>Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques</em>",id:"may-2022-assem-vc-realistic-voice-conversion-by-assembling-modern-speech-synthesis-techniques",level:4},{value:"<strong>(December 2021)</strong> <em>Controllable and Interpretable Singing Voice Decomposition via Assem-VC</em>",id:"december-2021-controllable-and-interpretable-singing-voice-decomposition-via-assem-vc",level:4},{value:"<strong>(August 2021)</strong> <em>NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling</em>",id:"august-2021-nu-wave-a-diffusion-probabilistic-model-for-neural-audio-upsampling",level:4},{value:"<strong>(June 2021)</strong> <em>Sharp Edge Recovery via SE(3)-Equivariant Network</em>",id:"june-2021-sharp-edge-recovery-via-se3-equivariant-network",level:4},{value:"<strong>(December 2020)</strong> <em>DS4C Patient Policy Province Dataset: A Comprehensive COVID-19 Dataset for Causal and Epidemiological Analysis</em>",id:"december-2020-ds4c-patient-policy-province-dataset-a-comprehensive-covid-19-dataset-for-causal-and-epidemiological-analysis",level:4},{value:"<strong>(October 2020)</strong> <em>Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data</em>",id:"october-2020-cotatron-transcription-guided-speech-encoder-for-any-to-many-voice-conversion-without-parallel-data",level:4},{value:"<strong>(September 2020)</strong> <em>3D Room Layout Estimation Beyond the Manhattan World Assumption</em>",id:"september-2020-3d-room-layout-estimation-beyond-the-manhattan-world-assumption",level:4},{value:"Open-Source Activities",id:"open-source-activities",level:2},{value:"<strong>(February 2022)</strong> pNLP-Mixer",id:"february-2022-pnlp-mixer",level:4},{value:"<strong>(December 2021)</strong> HifiFace",id:"december-2021-hififace",level:4},{value:"<strong>(August 2021)</strong> UnivNet",id:"august-2021-univnet",level:4},{value:"<strong>(July 2021)</strong> WaveGrad2",id:"july-2021-wavegrad2",level:4},{value:"<strong>(October 2020)</strong> FaceShifter",id:"october-2020-faceshifter",level:4},{value:"<strong>(June 2020)</strong> KoTDG",id:"june-2020-kotdg",level:4},{value:"<strong>(March 2020)</strong> Data-Science-for-COVID-19",id:"march-2020-data-science-for-covid-19",level:4},{value:"<strong>(January 2020)</strong> Reformer-pytorch",id:"january-2020-reformer-pytorch",level:4},{value:"<strong>(October 2019)</strong> MelGAN",id:"october-2019-melgan",level:4},{value:"<strong>(August 2019)</strong> MelNet",id:"august-2019-melnet",level:4},{value:"<strong>(April 2019)</strong> RandWireNN",id:"april-2019-randwirenn",level:4},{value:"<strong>(March 2019)</strong> VoiceFilter",id:"march-2019-voicefilter",level:4},{value:"<strong>(August 2018 \u2013 August 2020)</strong> Contribution to TensorFlow, PyTorch, Flashlight",id:"august-2018--august-2020-contribution-to-tensorflow-pytorch-flashlight",level:4}],p={toc:m};function c(e){var t=e.components,r=(0,n.Z)(e,o);return(0,i.kt)("wrapper",(0,a.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"publications--open-source-activities"},"Publications & Open Source Activities"),(0,i.kt)("h2",{id:"publications"},"Publications"),(0,i.kt)("h4",{id:"june-2022-talking-face-generation-with-multilingual-tts"},(0,i.kt)("strong",{parentName:"h4"},"(June 2022)")," ",(0,i.kt)("em",{parentName:"h4"},"Talking Face Generation with Multilingual TTS")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Hyoung-Kyu Song",(0,i.kt)("sup",null,"*")),", ",(0,i.kt)("strong",{parentName:"li"},"Sang Hoon Woo",(0,i.kt)("sup",null,"*")),", ",(0,i.kt)("strong",{parentName:"li"},"Junhyeok Lee"),", ",(0,i.kt)("strong",{parentName:"li"},"Seungmin Yang"),", ",(0,i.kt)("strong",{parentName:"li"},"Hyunjae Cho"),", ",(0,i.kt)("strong",{parentName:"li"},"Dongho Choi"),", ",(0,i.kt)("strong",{parentName:"li"},"Kang-wook Kim"),", and ",(0,i.kt)("strong",{parentName:"li"},"Youseong Lee")),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"CVPR Demo 2022"))),(0,i.kt)("h4",{id:"june-2022-styleformer-transformer-based-generative-adversarial-networks-with-style-vector"},(0,i.kt)("strong",{parentName:"h4"},"(June 2022)")," ",(0,i.kt)("em",{parentName:"h4"},"Styleformer: Transformer based Generative Adversarial Networks with Style Vector")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Jeeseung Park",(0,i.kt)("sup",null,"*"),", and ",(0,i.kt)("strong",{parentName:"li"},"Younggeun Kim",(0,i.kt)("sup",null,"*"))),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"CVPR 2022")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/Jeeseung-Park/Styleformer"},"github"))),(0,i.kt)("h4",{id:"may-2022-assem-vc-realistic-voice-conversion-by-assembling-modern-speech-synthesis-techniques"},(0,i.kt)("strong",{parentName:"h4"},"(May 2022)")," ",(0,i.kt)("em",{parentName:"h4"},"Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Kang-wook Kim",(0,i.kt)("sup",null,"*")),", ",(0,i.kt)("strong",{parentName:"li"},"Seung-won Park"),", ",(0,i.kt)("strong",{parentName:"li"},"Junhyeok Lee"),", and ",(0,i.kt)("strong",{parentName:"li"},"Myun-chul Joe")),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"ICASSP 2022")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.00931"},"arXiv:2104.00931")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://mindslab-ai.github.io/assem-vc"},"audio samples")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/assem-vc"},"github"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=assem-vc&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"december-2021-controllable-and-interpretable-singing-voice-decomposition-via-assem-vc"},(0,i.kt)("strong",{parentName:"h4"},"(December 2021)")," ",(0,i.kt)("em",{parentName:"h4"},"Controllable and Interpretable Singing Voice Decomposition via Assem-VC")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Kang-wook Kim",(0,i.kt)("sup",null,"*"))," and ",(0,i.kt)("strong",{parentName:"li"},"Junhyeok Lee")),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"NeurIPS Workshop on ML for Creativity and Design 2021 (Oral)")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2110.12676"},"arXiv:2110.12676")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://mindslab-ai.github.io/assem-vc/singer/"},"audio samples")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/assem-vc"},"github"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=assem-vc&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"august-2021-nu-wave-a-diffusion-probabilistic-model-for-neural-audio-upsampling"},(0,i.kt)("strong",{parentName:"h4"},"(August 2021)")," ",(0,i.kt)("em",{parentName:"h4"},"NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Junhyeok Lee",(0,i.kt)("sup",null,"*"))," and ",(0,i.kt)("strong",{parentName:"li"},"Seungu Han")),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"Interspeech 2021")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2104.02321"},"arXiv:2104.02321")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://mindslab-ai.github.io/nuwave"},"audio samples")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/nuwave"},"github"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=nuwave&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"june-2021-sharp-edge-recovery-via-se3-equivariant-network"},(0,i.kt)("strong",{parentName:"h4"},"(June 2021)")," ",(0,i.kt)("em",{parentName:"h4"},"Sharp Edge Recovery via SE(3)-Equivariant Network")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Youseong Lee",(0,i.kt)("sup",null,"*"))),(0,i.kt)("li",{parentName:"ul"},"Presented at 2nd SHApe Recovery from Partial textured 3D scans at ",(0,i.kt)("em",{parentName:"li"},"CVPR 2021")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://youtu.be/UVYQzQ-mH1w?t=9231"},"talk")),(0,i.kt)("li",{parentName:"ul"},"2nd place at SHARP 2021 Challenge track 3")),(0,i.kt)("h4",{id:"december-2020-ds4c-patient-policy-province-dataset-a-comprehensive-covid-19-dataset-for-causal-and-epidemiological-analysis"},(0,i.kt)("strong",{parentName:"h4"},"(December 2020)")," ",(0,i.kt)("em",{parentName:"h4"},"DS4C Patient Policy Province Dataset: A Comprehensive COVID-19 Dataset for Causal and Epidemiological Analysis")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Jimi Kim",(0,i.kt)("sup",null,"*"),", ",(0,i.kt)("strong",{parentName:"li"},"DongHwan Jang"),", Seojin Jang, Woncheol Lee, and ",(0,i.kt)("strong",{parentName:"li"},"Joong Kun Lee")),(0,i.kt)("li",{parentName:"ul"},"Accepted to Causal Discovery and Causality-Inspired Machine Learning ",(0,i.kt)("em",{parentName:"li"},"Workshop at NeurIPS 2020")," "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://www.cmu.edu/dietrich/causality/neurips20ws/"},"workshop link"))),(0,i.kt)("h4",{id:"october-2020-cotatron-transcription-guided-speech-encoder-for-any-to-many-voice-conversion-without-parallel-data"},(0,i.kt)("strong",{parentName:"h4"},"(October 2020)")," ",(0,i.kt)("em",{parentName:"h4"},"Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Seung-won Park",(0,i.kt)("sup",null,"*")),", ",(0,i.kt)("strong",{parentName:"li"},"Doo-young Kim"),", and ",(0,i.kt)("strong",{parentName:"li"},"Myun-chul Joe")),(0,i.kt)("li",{parentName:"ul"},"Accepted to ",(0,i.kt)("em",{parentName:"li"},"Interspeech 2020")," "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2005.03295"},"arXiv:2005.03295")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://mindslab-ai.github.io/cotatron/"},"audio samples")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/mindslab-ai/cotatron"},"github"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=cotatron&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"})),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://youtu.be/lnNuL8hqoh4"},"talk"))),(0,i.kt)("h4",{id:"september-2020-3d-room-layout-estimation-beyond-the-manhattan-world-assumption"},(0,i.kt)("strong",{parentName:"h4"},"(September 2020)")," ",(0,i.kt)("em",{parentName:"h4"},"3D Room Layout Estimation Beyond the Manhattan World Assumption")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Dongho Choi",(0,i.kt)("sup",null,"*"))),(0,i.kt)("li",{parentName:"ul"},"Presented at Holistic Scene Structures for 3D Vision at ",(0,i.kt)("em",{parentName:"li"},"ECCV 2020")," "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2009.02857"},"arXiv:2009.02857")),(0,i.kt)("li",{parentName:"ul"},"3rd place at Holistic 3D Vision Challenge track 1")),(0,i.kt)("h2",{id:"open-source-activities"},"Open-Source Activities"),(0,i.kt)("h4",{id:"february-2022-pnlp-mixer"},(0,i.kt)("strong",{parentName:"h4"},"(February 2022)")," pNLP-Mixer"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of ",(0,i.kt)("em",{parentName:"li"},"pNLP-Mixer")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2202.04350"},"arXiv:2202.04350"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=pnlp-mixer&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"december-2021-hififace"},(0,i.kt)("strong",{parentName:"h4"},"(December 2021)")," HifiFace"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of ",(0,i.kt)("em",{parentName:"li"},"HifiFace")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09965"},"arXiv:2106.09965"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=hififace&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"august-2021-univnet"},(0,i.kt)("strong",{parentName:"h4"},"(August 2021)")," UnivNet"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of ",(0,i.kt)("em",{parentName:"li"},"UnivNet")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.07889"},"arXiv:2106.07889"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=univnet&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"july-2021-wavegrad2"},(0,i.kt)("strong",{parentName:"h4"},"(July 2021)")," WaveGrad2"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of ",(0,i.kt)("em",{parentName:"li"},"WaveGrad2")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2106.09660"},"arXiv:2106.09660"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=wavegrad2&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"october-2020-faceshifter"},(0,i.kt)("strong",{parentName:"h4"},"(October 2020)")," FaceShifter"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of ",(0,i.kt)("em",{parentName:"li"},"FaceShifter")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1912.13457"},"arXiv:1912.13457"),". ",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=faceshifter&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"june-2020-kotdg"},(0,i.kt)("strong",{parentName:"h4"},"(June 2020)")," KoTDG"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Korean Text Data Generator for OCR tasks.",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Diuven&repo=KoTDG&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"march-2020-data-science-for-covid-19"},(0,i.kt)("strong",{parentName:"h4"},"(March 2020)")," Data-Science-for-COVID-19"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"COVID-19 Korea Dataset with patient routes and visualizer"),(0,i.kt)("li",{parentName:"ul"},"Co-led the collaboration project."),(0,i.kt)("li",{parentName:"ul"},"News coverage: ",(0,i.kt)("a",{parentName:"li",href:"http://it.chosun.com/site/data/html_dir/2020/06/24/2020062403706.html"},"Link 1")," ",(0,i.kt)("a",{parentName:"li",href:"http://www.aitimes.kr/news/articleView.html?idxno=15685"},"Link 2"),(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=ThisIsIsaac&repo=Data-Science-for-COVID-19&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"january-2020-reformer-pytorch"},(0,i.kt)("strong",{parentName:"h4"},"(January 2020)")," Reformer-pytorch"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Implementation of ",(0,i.kt)("em",{parentName:"li"},"Reformer: The Efficient Transformer")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/2001.04451"},"arXiv:2001.04451")," in pytorch.",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Rick-McCoy&repo=Reformer-pytorch&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"october-2019-melgan"},(0,i.kt)("strong",{parentName:"h4"},"(October 2019)")," MelGAN"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Implementation of ",(0,i.kt)("em",{parentName:"li"},"MelGAN")," vocoder ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1910.06711"},"arXiv:1910.06711")," (compatible with ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/tacotron2"},"NVIDIA/tacotron2"),")",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=seungwonpark&repo=melgan&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"august-2019-melnet"},(0,i.kt)("strong",{parentName:"h4"},"(August 2019)")," MelNet"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Implementation of ",(0,i.kt)("em",{parentName:"li"},"MelNet: A Generative Model for Audio in the Frequency Domain")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1906.01083"},"arXiv:1906.01083"),"."),(0,i.kt)("li",{parentName:"ul"},"Work done with Deepest AI (SNU Deep Learning Society).",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=Deepest-Project&repo=MelNet&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"april-2019-randwirenn"},(0,i.kt)("strong",{parentName:"h4"},"(April 2019)")," RandWireNN"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Implementation of ",(0,i.kt)("em",{parentName:"li"},"Exploring Randomly Wired Neural Networks for Image Recognition")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1904.01569"},"arXiv:1904.01569"),".",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=seungwonpark&repo=RandWireNN&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"march-2019-voicefilter"},(0,i.kt)("strong",{parentName:"h4"},"(March 2019)")," VoiceFilter"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"First successful open-source implementation of Google's ",(0,i.kt)("em",{parentName:"li"},"VoiceFilter")," ",(0,i.kt)("a",{parentName:"li",href:"https://arxiv.org/abs/1810.04826"},"arXiv:1810.04826"),".",(0,i.kt)("iframe",{src:"https://ghbtns.com/github-btn.html?user=mindslab-ai&repo=voicefilter&type=star&count=true",frameborder:"0",scrolling:"0",width:"150",height:"20",title:"GitHub"}))),(0,i.kt)("h4",{id:"august-2018--august-2020-contribution-to-tensorflow-pytorch-flashlight"},(0,i.kt)("strong",{parentName:"h4"},"(August 2018 \u2013 August 2020)")," Contribution to TensorFlow, PyTorch, Flashlight"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Made numerous contribution to the most popular deep learning frameworks, primarily by ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/ThisIsIsaac"},"Isaac Lee")," (former CUDA Team leader). His name was proudly mentioned in the list of contributors at ",(0,i.kt)("em",{parentName:"li"},"TensorFlow")," release note: ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0"},"Link"))))}c.isMDXComponent=!0}}]);